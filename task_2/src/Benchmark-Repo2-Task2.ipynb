{"cells":[{"cell_type":"code","execution_count":1,"id":"QHA-yQ4cvyF-","metadata":{"id":"QHA-yQ4cvyF-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742003697804,"user_tz":-480,"elapsed":38088,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"}},"outputId":"ae32a912-69f9-4231-a84c-17ea06f93770"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Mounted at /content/drive\n"]}],"source":["import os\n","print(os.getcwd())\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive')  # Mounts Drive if not already\n","\n"]},{"cell_type":"code","execution_count":null,"id":"O9dOzGHQEskV","metadata":{"id":"O9dOzGHQEskV"},"outputs":[],"source":["import importlib\n","\n","# Import necessary libraries\n","import sqlite3\n","import pandas as pd\n","import time\n","import os\n","import sys\n","# os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"4\"\n","# if os.path.exists(file_path):\n","#     print(\"✅ File found:\", file_path)\n","# else:\n","#     print(\"❌ File not found. Check the path.\")\n","\n","sys.path.append(\"/content/drive/MyDrive/HotelNoShowPrediction/task_2/src/setup\")\n","\n","import setup as setup\n","importlib.reload(setup)  # Reload the module to reflect new changes\n","\n","\n","import duration_cal as duration_cal\n","# importlib.reload(setup)  # Reload the module to reflect new changes\n","\n","\n","sys.path.append(\"/content/drive/MyDrive/HotelNoShowPrediction/task_2/src/EDA\")\n","import eda_step as EDA\n","\n","sys.path.append(\"/content/drive/MyDrive/HotelNoShowPrediction/task_2/src/model_select\")\n","import model_select as model_select\n","\n","sys.path.append(\"/content/drive/MyDrive/HotelNoShowPrediction/task_2/src/model_eval\")\n","import model_eval as model_eval\n","\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from sklearn.neural_network import MLPClassifier\n","from xgboost import XGBClassifier\n","from typing import Dict\n","from tqdm import tqdm\n","\n"]},{"cell_type":"markdown","id":"7D-Fe2e_7kdg","metadata":{"id":"7D-Fe2e_7kdg"},"source":[]},{"cell_type":"code","execution_count":null,"id":"-CPf8i2yyOsy","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1881,"status":"ok","timestamp":1741861696660,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"},"user_tz":-480},"id":"-CPf8i2yyOsy","outputId":"2ea43d19-5729-43a8-97e3-4224900b6678"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files in setup dir: ['duration_cal.py', '__init__.py', '__pycache__', 'setup.py']\n","✅ Import successful!\n"]}],"source":["\n","# Ensure the correct folder is added to Python's path\n","setup_dir = \"/content/drive/MyDrive/HotelNoShowPrediction/task_2/src/setup\"\n","sys.path.insert(0, setup_dir)  # Use insert(0) to prioritize this path\n","\n","# Debug: Print available modules in the setup folder\n","print(\"Files in setup dir:\", os.listdir(setup_dir))\n","\n","# Try importing setup directly\n","try:\n","    import setup  # Import the setup.py file as a module\n","    print(\"✅ Import successful!\")\n","except Exception as e:\n","    print(\"❌ Import failed:\", e)\n","\n","import importlib\n","\n","importlib.reload(setup)  # Reload the module to reflect new changes\n","\n","\n","from setup import setup_stage  # Directly import function\n","\n","(\n","    db_path,\n","    target_col,\n","    num_map_dict,\n","    standard_list,\n","    one_hot_list,\n","    model_test_size,\n","    model_random_state,\n","    model_search_method,\n","    model_cv_num,\n","    model_scoring,\n","    model_num_iter,\n","    model_num_jobs,\n","    model_param_dict,\n",") = setup.setup_stage()\n"]},{"cell_type":"code","execution_count":null,"id":"7629da31","metadata":{"id":"7629da31"},"outputs":[],"source":["\n","# import EDA.eda_step as EDA\n","# import model_select.model_select as model_select\n","# import model_eval.model_eval as model_eval\n","\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from sklearn.neural_network import MLPClassifier\n","from xgboost import XGBClassifier\n","from typing import Dict\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"id":"6080166d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1741861697104,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"},"user_tz":-480},"id":"6080166d","outputId":"7175e7ca-f797-4e74-c48a-d6ccf86df678"},"outputs":[{"output_type":"stream","name":"stdout","text":["Configuration loaded successfully!\n"]}],"source":["# Load configuration and setup parameters\n","start_time = time.time()\n","\n","\n","(\n","    db_path,\n","    target_col,\n","    num_map_dict,\n","    standard_list,\n","    one_hot_list,\n","    model_test_size,\n","    model_random_state,\n","    model_search_method,\n","    model_cv_num,\n","    model_scoring,\n","    model_num_iter,\n","    model_num_jobs,\n","    model_param_dict,\n",") = setup.setup_stage()\n","\n","print(\"Configuration loaded successfully!\")"]},{"cell_type":"code","execution_count":null,"id":"baaa85a5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1283,"status":"ok","timestamp":1741861698395,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"},"user_tz":-480},"id":"baaa85a5","outputId":"01631d3c-b180-4bdb-990f-069fa717f89a"},"outputs":[{"output_type":"stream","name":"stdout","text":["1. Connecting to SQL database....\n","Connection done!\n"]}],"source":["# Create connection to SQL database\n","print(\"1. Connecting to SQL database....\")\n","db_path = \"/content/drive/MyDrive/HotelNoShowPrediction/data/noshow.db\"\n","\n","conn = sqlite3.connect(db_path)\n","print(\"Connection done!\")"]},{"cell_type":"code","execution_count":null,"id":"d75a2b91","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1741861698429,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"},"user_tz":-480},"id":"d75a2b91","outputId":"eb250cb3-9e75-41a9-9b30-3d9fb0e8b77c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Part 1 has run for 1.305 sec!\n"]}],"source":["part1_time = time.time()\n","part1_duration, part1_tag = duration_cal.duration_cal(part1_time - start_time)\n","print(f\"Part 1 has run for {part1_duration:.3f} {part1_tag}!\")"]},{"cell_type":"code","execution_count":null,"id":"b4b994bc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3657,"status":"ok","timestamp":1741861702087,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"},"user_tz":-480},"id":"b4b994bc","outputId":"80cbf40e-4858-4a1a-c9cf-5d6e337c3bd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["2. Extract SQL database table as DataFrame...\n","Extraction done!\n"]}],"source":["# Get data from 'noshow' table\n","print(\"2. Extract SQL database table as DataFrame...\")\n","\n","noshow_data_query = \"SELECT * FROM noshow;\"\n","noshow_data_df = pd.read_sql_query(noshow_data_query, conn)\n","\n","print(\"Extraction done!\")"]},{"cell_type":"code","execution_count":null,"id":"c16dd7c5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1741861702102,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"},"user_tz":-480},"id":"c16dd7c5","outputId":"46fc4938-e207-4be6-a17d-bb196b50534c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Part 2 has run for 3.710 sec!\n"]}],"source":["part2_time = time.time()\n","\n","part2_duration, part2_tag = duration_cal.duration_cal(part2_time - part1_time)\n","\n","print(f\"Part 2 has run for {part2_duration:.3f} {part2_tag}!\")"]},{"cell_type":"code","execution_count":null,"id":"202965b0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3018,"status":"ok","timestamp":1741861705121,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"},"user_tz":-480},"id":"202965b0","outputId":"0f8f99b1-7766-4103-958f-57a2b37b7290"},"outputs":[{"output_type":"stream","name":"stdout","text":["3. Performing EDA on DataFrame...\n","EDA done!\n"]}],"source":["# Using analysis from task_1 EDA, perform data preprocessing, feature data standardization and one-hot encoding\n","print(\"3. Performing EDA on DataFrame...\")\n","\n","fil_noshow_data_df, preprocessor, X_train, X_test, Y_train, Y_test = EDA.ml_eda_step(\n","    noshow_data_df,\n","    target_col,\n","    num_map_dict,\n","    standard_list,\n","    one_hot_list,\n","    model_test_size,\n","    model_random_state,\n",")\n","\n","print(\"EDA done!\")"]},{"cell_type":"code","execution_count":null,"id":"a43d31a1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1741861705125,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"},"user_tz":-480},"id":"a43d31a1","outputId":"6a8922f4-dd1f-49fb-eca9-871cf82ddf75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Part 3 has run for 3.008 sec!\n"]}],"source":["part3_time = time.time()\n","\n","part3_duration, part3_tag = duration_cal.duration_cal(part3_time - part2_time)\n","\n","print(f\"Part 3 has run for {part3_duration:.3f} {part3_tag}!\")"]},{"cell_type":"code","execution_count":null,"id":"e3a7dfdb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1741861705128,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"},"user_tz":-480},"id":"e3a7dfdb","outputId":"c7c8c667-f56c-4818-d4a0-7ae146b83981"},"outputs":[{"output_type":"stream","name":"stdout","text":["4. Training machine learning models...\n"]}],"source":["best_estimators_dict = {}\n","# Pre-select a few models and train models to get best optimized parameters\n","print(\"4. Training machine learning models...\")"]},{"cell_type":"code","execution_count":null,"id":"3oxs0PVdVE81","metadata":{"id":"3oxs0PVdVE81"},"outputs":[],"source":["# Logistic regression"]},{"cell_type":"code","execution_count":null,"id":"a4604647","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a4604647","outputId":"66e02b00-b0c0-4e4f-edc4-2ac841ca1740"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing Logistic Regression now...\n"]},{"name":"stderr","output_type":"stream","text":["\rProgress:   0%|           [ time left: ? ]"]},{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"]}],"source":["\n","import joblib\n","\n","# Train Logistic Regression\n","if \"Logistic Regression\" in model_param_dict:\n","    model_start_time = time.time()\n","    print(\"Processing Logistic Regression now...\")\n","\n","    model = LogisticRegression(random_state=model_random_state)\n","    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","    if model_search_method == \"grid\":\n","        search = GridSearchCV(\n","            pipeline,\n","            param_grid=model_param_dict[\"Logistic Regression\"],\n","            cv=model_cv_num,\n","            scoring=model_scoring,\n","            n_jobs=model_num_jobs,\n","            verbose=3\n","        )\n","    elif model_search_method == \"random\":\n","        search = RandomizedSearchCV(\n","            pipeline,\n","            param_distributions=model_param_dict[\"Logistic Regression\"],\n","            n_iter=model_num_iter,\n","            cv=model_cv_num,\n","            scoring=model_scoring,\n","            random_state=model_random_state,\n","            n_jobs=model_num_jobs,\n","        )\n","    with tqdm(total=100, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ time left: {remaining} ]\") as pbar:\n","        search.fit(X_train, Y_train)\n","        pbar.update(100)\n","\n","    # Save best model\n","    best_estimators_dict[\"Logistic Regression\"] = search.best_estimator_\n","    print(\"Best parameters for Logistic Regression:\", search.best_params_)\n","\n","\t# Save the trained model\n","    model_filename = \"Logistic_Regression.pkl\"\n","    joblib.dump(search.best_estimator_, model_filename)\n","    print(f\"Model saved as {model_filename}\")\n","\n","\n","\n","    model_end_time = time.time()\n","    model_total_time = model_end_time - model_start_time\n","    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","    print(f\"Logistic Regression has run tuning for {model_duration:.3f} {model_tag}\")\n"]},{"cell_type":"code","execution_count":null,"id":"aPd9Ota2gvi_","metadata":{"id":"aPd9Ota2gvi_"},"outputs":[],"source":["import shutil\n","ipmort os\n","\n","source_file = \"Logistic_Regression.pkl\"\n","destination_dir = \"/content/drive/MyDrive/HotelNoShowPrediction\"\n","\n","# Ensure the target directory exists\n","os.makedirs(destination_dir, exist_ok=True)\n","\n","# Move the file\n","destination_file = os.path.join(destination_dir, source_file)\n","shutil.move(source_file, destination_file)\n","\n","print(f\"Model moved to: {destination_file}\")"]},{"cell_type":"markdown","id":"VKlOW2dMjrIf","metadata":{"id":"VKlOW2dMjrIf"},"source":["To use gpu for random forest"]},{"cell_type":"code","execution_count":null,"id":"hZYwCjhkyxUz","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZYwCjhkyxUz","outputId":"178a4698-a6f7-44cf-80e4-b1fba968cd38"},"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-03-11 05:04:39,778] A new study created in memory with name: no-name-f7dba72b-dbde-434f-8e59-472a27cb94a1\n"]},{"output_type":"stream","name":"stdout","text":["Processing Logistic Regression with Optuna Optimization...\n"]},{"output_type":"stream","name":"stderr","text":["\rProgress:   0%|           [ Time Left: ? ]<ipython-input-15-fd67ca0cb112>:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)  # Regularization strength\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2025-03-11 05:06:08,917] Trial 0 finished with value: -0.2968137314038271 and parameters: {'C': 0.0013681895189378173, 'solver': 'saga', 'penalty': 'l2'}. Best is trial 0 with value: -0.2968137314038271.\n","Progress:   3%|▎          [ Time Left: 43:05 ]<ipython-input-15-fd67ca0cb112>:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)  # Regularization strength\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]}],"source":["# # Logistic regression 2\n","\n","# # optuna with log regression\n","\n","# import time\n","# import joblib\n","# import optuna\n","# from sklearn.pipeline import Pipeline\n","# from sklearn.linear_model import LogisticRegression\n","# from sklearn.model_selection import cross_val_score\n","# from tqdm import tqdm\n","\n","# # Train Logistic Regression using Optuna\n","# if \"Logistic Regression\" in model_param_dict:\n","#     model_start_time = time.time()\n","#     print(\"Processing Logistic Regression with Optuna Optimization...\")\n","\n","#     def objective(trial):\n","#         \"\"\"Objective function for Optuna Bayesian Optimization\"\"\"\n","#         C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)  # Regularization strength\n","#         solver = trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\", \"saga\"])\n","#         penalty = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]) if solver != \"lbfgs\" else \"l2\"\n","\n","#         model = LogisticRegression(C=C, solver=solver, penalty=penalty, random_state=model_random_state)\n","#         pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","#         score = cross_val_score(pipeline, X_train, Y_train, cv=model_cv_num, scoring=model_scoring).mean()\n","#         return score  # Maximize accuracy\n","\n","#     # Run Optuna optimization\n","#     study = optuna.create_study(direction=\"maximize\")\n","\n","#     with tqdm(total=30, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ Time Left: {remaining} ]\") as pbar:\n","#         def callback(study, trial):\n","#             pbar.update(1)  # Update progress bar per trial\n","\n","#         study.optimize(objective, n_trials=30, timeout=1800, callbacks=[callback])  # 30 trials, max 30 minutes\n","\n","#     # Get best parameters\n","#     best_params = study.best_params\n","#     print(\"Best Hyperparameters for Logistic Regression:\", best_params)\n","\n","#     # Train final model with best parameters\n","#     best_model = LogisticRegression(**best_params, random_state=model_random_state)\n","#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n","#     pipeline.fit(X_train, Y_train)\n","\n","#     # Save best model\n","#     best_estimators_dict[\"Logistic Regression\"] = pipeline\n","#     model_filename = \"Logistic_Regression_Optuna.pkl\"\n","#     joblib.dump(pipeline, model_filename)\n","#     print(f\"Optimized Logistic Regression model saved as {model_filename}\")\n","\n","#     # Log training duration\n","#     model_end_time = time.time()\n","#     model_total_time = model_end_time - model_start_time\n","#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","#     print(f\"Logistic Regression Optuna tuning completed in {model_duration:.3f} {model_tag}\")"]},{"cell_type":"code","source":["# Logistic Regression 2 - Optuna with Automated Timeout Calculation & Model Saving\n","\n","import time\n","import joblib\n","import optuna\n","import shutil\n","import os\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_val_score\n","from tqdm import tqdm\n","\n","# Directory to save the model\n","destination_dir = \"/content/drive/MyDrive/HotelNoShowPrediction\"\n","os.makedirs(destination_dir, exist_ok=True)  # Ensure the directory exists\n","\n","# Train Logistic Regression using Optuna\n","if \"Logistic Regression\" in model_param_dict:\n","    model_start_time = time.time()\n","    print(\"Processing Logistic Regression with Optuna Optimization...\")\n","\n","    def objective(trial):\n","        \"\"\"Objective function for Optuna Bayesian Optimization\"\"\"\n","        C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)  # Regularization strength\n","        solver = trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\", \"saga\"])\n","        penalty = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]) if solver != \"lbfgs\" else \"l2\"\n","\n","        model = LogisticRegression(C=C, solver=solver, penalty=penalty, random_state=model_random_state)\n","        pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","        start_time = time.time()\n","        score = cross_val_score(pipeline, X_train, Y_train, cv=model_cv_num, scoring=model_scoring).mean()\n","        trial_time = time.time() - start_time\n","\n","        print(f\"Trial {trial.number} took {trial_time:.2f} seconds\")\n","        return score  # Maximize accuracy\n","\n","    # Step 1: Estimate time per trial using a few test runs\n","    def estimate_trial_time(objective, n_test_trials=3):\n","        \"\"\"Runs a few dummy trials to estimate average trial time.\"\"\"\n","        start_time = time.time()\n","        for _ in range(n_test_trials):\n","            objective(optuna.trial.FixedTrial({\"C\": 1.0, \"solver\": \"liblinear\", \"penalty\": \"l2\"}))  # Dummy params\n","        return (time.time() - start_time) / n_test_trials\n","\n","    avg_trial_time = estimate_trial_time(objective)\n","    target_trials = 30\n","    n_jobs = 4  # Adjust based on available CPU cores\n","\n","    # Step 2: Compute optimal timeout\n","    optimal_timeout = (avg_trial_time * target_trials) / n_jobs\n","    print(f\"Estimated optimal timeout: {optimal_timeout:.2f} seconds (~{optimal_timeout/60:.2f} minutes)\")\n","\n","    # Run Optuna optimization with dynamic timeout\n","    study = optuna.create_study(direction=\"maximize\")\n","\n","    with tqdm(total=target_trials, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ Time Left: {remaining} ]\") as pbar:\n","        def callback(study, trial):\n","            pbar.update(1)  # Update progress bar per trial\n","\n","        study.optimize(objective, n_trials=target_trials, timeout=optimal_timeout, callbacks=[callback])\n","\n","    # Get best parameters\n","    best_params = study.best_params\n","    print(\"Best Hyperparameters for Logistic Regression:\", best_params)\n","\n","    # Train final model with best parameters\n","    best_model = LogisticRegression(**best_params, random_state=model_random_state)\n","    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n","    pipeline.fit(X_train, Y_train)\n","\n","    # Save best model\n","    best_estimators_dict[\"Logistic Regression\"] = pipeline\n","    model_filename = \"Logistic_Regression_optuna_v2.pkl\"\n","    joblib.dump(pipeline, model_filename)\n","    print(f\"Optimized Logistic Regression model saved as {model_filename}\")\n","\n","    # Move the model to the specified directory\n","    destination_file = os.path.join(destination_dir, model_filename)\n","    shutil.move(model_filename, destination_file)\n","    print(f\"Model moved to: {destination_file}\")\n","\n","    # Log training duration\n","    model_end_time = time.time()\n","    model_total_time = model_end_time - model_start_time\n","    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","    print(f\"Logistic Regression Optuna tuning completed in {model_duration:.3f} {model_tag}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hpokiY_VspJl","executionInfo":{"status":"ok","timestamp":1741806399771,"user_tz":-480,"elapsed":744518,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"}},"outputId":"d042ceb9-fef8-457a-adfe-5735f83b859e"},"id":"hpokiY_VspJl","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing Logistic Regression with Optuna Optimization...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-14-f276defa948b>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)  # Regularization strength\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 51.45 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-14-f276defa948b>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)  # Regularization strength\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 42.51 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-14-f276defa948b>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)  # Regularization strength\n","[I 2025-03-12 18:56:31,680] A new study created in memory with name: no-name-9b73672a-ab6c-4fb5-a2a6-4987d0f2884d\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 42.11 seconds\n","Estimated optimal timeout: 340.18 seconds (~5.67 minutes)\n"]},{"output_type":"stream","name":"stderr","text":["\rProgress:   0%|           [ Time Left: ? ]<ipython-input-14-f276defa948b>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)  # Regularization strength\n","[I 2025-03-12 19:04:37,273] Trial 0 finished with value: -0.2942770860435641 and parameters: {'C': 553.8102887796105, 'solver': 'liblinear', 'penalty': 'l1'}. Best is trial 0 with value: -0.2942770860435641.\n","Progress:   3%|▎          [ Time Left: 3:54:41 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 485.57 seconds\n","Best Hyperparameters for Logistic Regression: {'C': 553.8102887796105, 'solver': 'liblinear', 'penalty': 'l1'}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Optimized Logistic Regression model saved as Logistic_Regression_optuna_v2.pkl\n","Model moved to: /content/drive/MyDrive/HotelNoShowPrediction/Logistic_Regression_optuna_v2.pkl\n","Logistic Regression Optuna tuning completed in 12.401 min\n"]}]},{"cell_type":"code","source":["#############################################################################################################################################################################################################################"],"metadata":{"id":"EnU2XL6QspCy"},"id":"EnU2XL6QspCy","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Random forest"],"metadata":{"id":"hYJax6vDso7w"},"id":"hYJax6vDso7w","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"YXIawtP0yxNg","metadata":{"id":"YXIawtP0yxNg"},"outputs":[],"source":["# import time\n","# import joblib\n","# import optuna\n","# from sklearn.pipeline import Pipeline\n","# # from optuna.integration import SklearnPruningCallback\n","# from sklearn.model_selection import cross_val_score\n","# from sklearn.ensemble import RandomForestClassifier\n","\n","# # Train Random Forest using Optuna\n","# if \"Random Forest\" in model_param_dict:\n","#     model_start_time = time.time()\n","#     print(\"Processing Random Forest with Optuna Optimization...\")\n","\n","#     def objective(trial):\n","#         \"\"\"Objective function for Optuna Bayesian Optimization\"\"\"\n","#         # Suggest hyperparameters dynamically\n","#         n_estimators = trial.suggest_int(\"n_estimators\", 50, 300, step=50)\n","#         max_depth = trial.suggest_int(\"max_depth\", 3, 30, step=3)\n","#         min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n","#         min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 5)\n","#         max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n","\n","#         # Initialize Random Forest\n","#         model = RandomForestClassifier(\n","#             n_estimators=n_estimators,\n","#             max_depth=max_depth,\n","#             min_samples_split=min_samples_split,\n","#             min_samples_leaf=min_samples_leaf,\n","#             max_features=max_features,\n","#             random_state=model_random_state,\n","#             n_jobs=model_num_jobs\n","#         )\n","\n","#         # Create pipeline with preprocessor and model\n","#         pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","#         # Cross-validation score\n","#         score = cross_val_score(pipeline, X_train, Y_train, cv=model_cv_num, scoring=model_scoring)\n","\n","#         return score.mean()  # Optuna optimizes for highest score\n","\n","#     # Optimize with Optuna\n","#     study = optuna.create_study(direction=\"maximize\")\n","#     study.optimize(objective, n_trials=50, timeout=1800)  # 50 trials or max 30 minutes\n","\n","#     # Get best parameters\n","#     best_params = study.best_params\n","#     print(\"Best Hyperparameters for Random Forest:\", best_params)\n","\n","#     # Train final model with best parameters\n","#     best_model = RandomForestClassifier(**best_params, random_state=model_random_state, n_jobs=model_num_jobs)\n","#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n","#     pipeline.fit(X_train, Y_train)\n","\n","#     # Save best model\n","#     best_estimators_dict[\"Random Forest\"] = pipeline\n","#     model_filename = \"Random_Forest_Optuna.pkl\"\n","#     joblib.dump(pipeline, model_filename)\n","#     print(f\"Optimized model saved as {model_filename}\")\n","\n","#     # Log training duration\n","#     model_end_time = time.time()\n","#     model_total_time = model_end_time - model_start_time\n","#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","#     print(f\"Random Forest Optuna tuning completed in {model_duration:.3f} {model_tag}\")"]},{"cell_type":"code","source":["import time\n","import joblib\n","import optuna\n","import shutil\n","import os\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n","from tqdm import tqdm\n","\n","# Directory to save the model\n","destination_dir = \"/content/drive/MyDrive/HotelNoShowPrediction\"\n","os.makedirs(destination_dir, exist_ok=True)  # Ensure the directory exists\n","\n","# Train Random Forest using Optuna\n","if \"Random Forest\" in model_param_dict:\n","    model_start_time = time.time()\n","    print(\"Processing Random Forest with Optuna Optimization...\")\n","\n","    def objective(trial):\n","        \"\"\"Objective function for Optuna Bayesian Optimization\"\"\"\n","        # Suggest hyperparameters dynamically\n","        n_estimators = trial.suggest_int(\"n_estimators\", 50, 300, step=50)\n","        max_depth = trial.suggest_int(\"max_depth\", 3, 30, step=3)\n","        min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n","        min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 5)\n","        max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n","\n","        # Initialize Random Forest\n","        model = RandomForestClassifier(\n","            n_estimators=n_estimators,\n","            max_depth=max_depth,\n","            min_samples_split=min_samples_split,\n","            min_samples_leaf=min_samples_leaf,\n","            max_features=max_features,\n","            random_state=model_random_state,\n","            n_jobs=model_num_jobs\n","        )\n","\n","        # Create pipeline with preprocessor and model\n","        pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","        # Measure trial time\n","        start_time = time.time()\n","        score = cross_val_score(pipeline, X_train, Y_train, cv=model_cv_num, scoring=model_scoring).mean()\n","        trial_time = time.time() - start_time\n","\n","        print(f\"Trial {trial.number} took {trial_time:.2f} seconds\")\n","        return score  # Optuna optimizes for highest score\n","\n","    # Step 1: Estimate time per trial using a few test runs\n","    def estimate_trial_time(objective, n_test_trials=3):\n","        \"\"\"Runs a few dummy trials to estimate average trial time.\"\"\"\n","        start_time = time.time()\n","        for _ in range(n_test_trials):\n","            objective(optuna.trial.FixedTrial({\n","                \"n_estimators\": 100, \"max_depth\": 10,\n","                \"min_samples_split\": 2, \"min_samples_leaf\": 1,\n","                \"max_features\": \"sqrt\"\n","            }))  # Dummy params\n","        return (time.time() - start_time) / n_test_trials\n","\n","    avg_trial_time = estimate_trial_time(objective)\n","    target_trials = 50\n","    n_jobs = model_num_jobs  # Use defined number of parallel jobs\n","\n","    # Step 2: Compute optimal timeout\n","    # optimal_timeout = (avg_trial_time * target_trials) / n_jobs\n","    optimal_timeout = max((avg_trial_time * target_trials) / max(n_jobs, 1), 30)\n","    print(f\"Estimated optimal timeout: {optimal_timeout:.2f} seconds (~{optimal_timeout/60:.2f} minutes)\")\n","\n","    # Run Optuna optimization with dynamic timeout\n","    study = optuna.create_study(direction=\"maximize\")\n","\n","    with tqdm(total=target_trials, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ Time Left: {remaining} ]\") as pbar:\n","        def callback(study, trial):\n","            pbar.update(1)  # Update progress bar per trial\n","\n","        study.optimize(objective, n_trials=target_trials, timeout=optimal_timeout, callbacks=[callback])\n","\n","    # Get best parameters\n","    best_params = study.best_params\n","    print(\"Best Hyperparameters for Random Forest:\", best_params)\n","\n","    # Train final model with best parameters\n","    best_model = RandomForestClassifier(**best_params, random_state=model_random_state, n_jobs=model_num_jobs)\n","    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n","    pipeline.fit(X_train, Y_train)\n","\n","    # Save best model\n","    best_estimators_dict[\"Random Forest\"] = pipeline\n","    model_filename = \"Random_Forest_Optuna_V2.pkl\"\n","    joblib.dump(pipeline, model_filename)\n","    print(f\"Optimized Random Forest model saved as {model_filename}\")\n","\n","    # Move the model to the specified directory\n","    destination_file = os.path.join(destination_dir, model_filename)\n","    shutil.move(model_filename, destination_file)\n","    print(f\"Model moved to: {destination_file}\")\n","\n","    # Log training duration\n","    model_end_time = time.time()\n","    model_total_time = model_end_time - model_start_time\n","    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","    print(f\"Random Forest Optuna tuning completed in {model_duration:.3f} {model_tag}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tEAr1kZ5tKHL","executionInfo":{"status":"ok","timestamp":1741808302428,"user_tz":-480,"elapsed":1411172,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"}},"outputId":"9df9441e-a325-479b-e123-13e47e01664f"},"id":"tEAr1kZ5tKHL","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing Random Forest with Optuna Optimization...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/optuna/trial/_fixed.py:148: UserWarning: The value 10 of the parameter 'max_depth' is out of the range of the distribution IntDistribution(high=30, log=False, low=3, step=3).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 18.60 seconds\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/optuna/trial/_fixed.py:148: UserWarning: The value 10 of the parameter 'max_depth' is out of the range of the distribution IntDistribution(high=30, log=False, low=3, step=3).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 16.70 seconds\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/optuna/trial/_fixed.py:148: UserWarning: The value 10 of the parameter 'max_depth' is out of the range of the distribution IntDistribution(high=30, log=False, low=3, step=3).\n","  warnings.warn(\n","[I 2025-03-12 19:15:43,333] A new study created in memory with name: no-name-624aea41-d2e9-4941-a7e5-cae44bc6ab7e\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 16.82 seconds\n","Estimated optimal timeout: 868.62 seconds (~14.48 minutes)\n"]},{"output_type":"stream","name":"stderr","text":["Progress:   0%|           [ Time Left: ? ][I 2025-03-12 19:15:47,231] Trial 0 finished with value: -0.309155035971019 and parameters: {'n_estimators': 50, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 0 with value: -0.309155035971019.\n","Progress:   2%|▏          [ Time Left: 03:10 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 3.89 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-12 19:16:06,381] Trial 1 finished with value: -0.30142321220257406 and parameters: {'n_estimators': 250, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 1 with value: -0.30142321220257406.\n","Progress:   4%|▍          [ Time Left: 10:17 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 1 took 19.15 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-12 19:16:47,493] Trial 2 finished with value: -0.26289956689397853 and parameters: {'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 2 with value: -0.26289956689397853.\n","Progress:   6%|▌          [ Time Left: 20:10 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 2 took 41.11 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-12 19:18:03,442] Trial 3 finished with value: -0.26063583135219587 and parameters: {'n_estimators': 50, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 3 with value: -0.26063583135219587.\n","Progress:   8%|▊          [ Time Left: 34:56 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 3 took 75.94 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-12 19:19:19,901] Trial 4 finished with value: -0.30724628318747566 and parameters: {'n_estimators': 100, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 3 with value: -0.26063583135219587.\n","Progress:  10%|█          [ Time Left: 42:32 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 4 took 76.46 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-12 19:21:23,313] Trial 5 finished with value: -0.31624666533355783 and parameters: {'n_estimators': 300, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 3 with value: -0.26063583135219587.\n","Progress:  12%|█▏         [ Time Left: 58:13 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 5 took 123.41 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-12 19:22:06,141] Trial 6 finished with value: -0.27042709996552305 and parameters: {'n_estimators': 250, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 3 with value: -0.26063583135219587.\n","Progress:  14%|█▍         [ Time Left: 48:19 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 6 took 42.82 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-12 19:22:48,524] Trial 7 finished with value: -0.28407739874674565 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 3 with value: -0.26063583135219587.\n","Progress:  16%|█▌         [ Time Left: 41:37 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 7 took 42.38 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-12 19:29:20,539] Trial 8 finished with value: -0.23172599163589047 and parameters: {'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 8 with value: -0.23172599163589047.\n","Progress:  18%|█▊         [ Time Left: 1:51:40 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 8 took 392.01 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-12 19:36:36,431] Trial 9 finished with value: -0.24950822203552997 and parameters: {'n_estimators': 250, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 8 with value: -0.23172599163589047.\n","Progress:  20%|██         [ Time Left: 1:23:32 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 9 took 435.89 seconds\n","Best Hyperparameters for Random Forest: {'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': None}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Optimized Random Forest model saved as Random_Forest_Optuna_V2.pkl\n","Model moved to: /content/drive/MyDrive/HotelNoShowPrediction/Random_Forest_Optuna_V2.pkl\n","Random Forest Optuna tuning completed in 23.518 min\n"]}]},{"cell_type":"code","source":["## GRID SEARCH\n","import time\n","import joblib\n","import optuna\n","import shutil\n","import os\n","from tqdm import tqdm\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n","\n","# Directory to save the model\n","destination_dir = \"/content/drive/MyDrive/HotelNoShowPrediction\"\n","os.makedirs(destination_dir, exist_ok=True)  # Ensure the directory exists\n","\n","# Train Logistic Regression using Optuna + GridSearch\n","if \"Logistic Regression\" in model_param_dict:\n","    model_start_time = time.time()\n","    print(\"Processing Logistic Regression with Optuna Optimization & GridSearch...\")\n","\n","    # Define Optuna objective function\n","    def objective(trial):\n","        \"\"\"Objective function for Optuna Bayesian Optimization\"\"\"\n","        C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","        solver = trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\", \"saga\"])\n","        penalty = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]) if solver != \"lbfgs\" else \"l2\"\n","\n","        model = LogisticRegression(C=C, solver=solver, penalty=penalty, random_state=model_random_state)\n","        pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","        # Measure trial time\n","        start_time = time.time()\n","        score = cross_val_score(pipeline, X_train, Y_train, cv=model_cv_num, scoring=model_scoring).mean()\n","        trial_time = time.time() - start_time\n","\n","        print(f\"Trial {trial.number} took {trial_time:.2f} seconds\")\n","        return score  # Optuna optimizes for highest accuracy\n","\n","    # Step 1: Estimate time per trial using a few test runs\n","    def estimate_trial_time(objective, n_test_trials=3):\n","        \"\"\"Runs a few dummy trials to estimate average trial time.\"\"\"\n","        start_time = time.time()\n","        for _ in range(n_test_trials):\n","            objective(optuna.trial.FixedTrial({\n","                \"C\": 1.0, \"solver\": \"liblinear\", \"penalty\": \"l2\"\n","            }))  # Dummy params\n","        return (time.time() - start_time) / n_test_trials\n","\n","    avg_trial_time = estimate_trial_time(objective)\n","    target_trials = 30\n","    n_jobs = max(model_num_jobs, 1)  # Prevent division by zero\n","\n","    # Step 2: Compute optimal timeout\n","    optimal_timeout = max((avg_trial_time * target_trials) / n_jobs, 30)  # Ensure timeout is positive\n","    print(f\"Estimated optimal timeout: {optimal_timeout:.2f} seconds (~{optimal_timeout/60:.2f} minutes)\")\n","\n","    # Run Optuna optimization with dynamic timeout\n","    study = optuna.create_study(direction=\"maximize\")\n","\n","    with tqdm(total=target_trials, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ Time Left: {remaining} ]\") as pbar:\n","        def callback(study, trial):\n","            pbar.update(1)  # Update progress bar per trial\n","\n","        study.optimize(objective, n_trials=target_trials, timeout=optimal_timeout, callbacks=[callback])\n","\n","    # Get best hyperparameters from Optuna\n","    best_params_optuna = study.best_params if len(study.trials) > 0 else None\n","\n","    if best_params_optuna:\n","        print(\"Best Optuna Hyperparameters for Logistic Regression:\", best_params_optuna)\n","\n","        # Define model with Optuna best parameters\n","        best_model = LogisticRegression(**best_params_optuna, random_state=model_random_state)\n","        pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n","\n","        # **GRID SEARCH with Optuna Best Parameters**\n","        search = GridSearchCV(\n","            pipeline,\n","            param_grid=model_param_dict[\"Logistic Regression\"],\n","            cv=model_cv_num,\n","            scoring=model_scoring,\n","            n_jobs=model_num_jobs,\n","            verbose=3\n","        )\n","\n","        # Progress tracking\n","        with tqdm(total=100, desc=\"GridSearch Progress\", bar_format=\"{l_bar}{bar} [ time left: {remaining} ]\") as pbar:\n","            search.fit(X_train, Y_train)\n","            pbar.update(100)\n","\n","        # Save best model\n","        best_estimators_dict[\"Logistic Regression\"] = search.best_estimator_\n","        print(\"Best parameters for Logistic Regression (GridSearch):\", search.best_params_)\n","\n","        # Save the trained model\n","        model_filename = \"Logistic_Regression_Optuna_Grid_V2.pkl\"\n","        joblib.dump(search.best_estimator_, model_filename)\n","        print(f\"Model saved as {model_filename}\")\n","\n","        # Move the model to the specified directory\n","        destination_file = os.path.join(destination_dir, model_filename)\n","        shutil.move(model_filename, destination_file)\n","        print(f\"Model moved to: {destination_file}\")\n","\n","    else:\n","        print(\"Optuna did not complete any successful trials. Skipping GridSearch.\")\n","\n","    # Log training duration\n","    model_end_time = time.time()\n","    model_total_time = model_end_time - model_start_time\n","    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","    print(f\"Logistic Regression tuning completed in {model_duration:.3f} {model_tag}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sB3UhyQbxpH7","executionInfo":{"status":"ok","timestamp":1741815011296,"user_tz":-480,"elapsed":6708761,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"}},"outputId":"9508b90d-727b-4c62-f49e-a7dd684c8e9d"},"id":"sB3UhyQbxpH7","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing Logistic Regression with Optuna Optimization & GridSearch...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 37.44 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 37.69 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-12 19:40:14,894] A new study created in memory with name: no-name-bd643eb4-cd4c-42f1-b38f-8e5d0c64731c\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 37.39 seconds\n","Estimated optimal timeout: 1125.27 seconds (~18.75 minutes)\n"]},{"output_type":"stream","name":"stderr","text":["\rProgress:   0%|           [ Time Left: ? ]<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2025-03-12 19:41:46,668] Trial 0 finished with value: -0.29528624327751896 and parameters: {'C': 0.22473874728957174, 'solver': 'saga', 'penalty': 'l1'}. Best is trial 0 with value: -0.29528624327751896.\n","Progress:   3%|▎          [ Time Left: 44:21 ]<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 91.77 seconds\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2025-03-12 19:42:57,191] Trial 1 finished with value: -0.29501349338002875 and parameters: {'C': 12.042207947820847, 'solver': 'saga', 'penalty': 'l2'}. Best is trial 1 with value: -0.29501349338002875.\n","Progress:   7%|▋          [ Time Left: 36:59 ]<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n"]},{"output_type":"stream","name":"stdout","text":["Trial 1 took 70.52 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-12 19:43:21,786] Trial 2 finished with value: -0.29401799544412993 and parameters: {'C': 0.14386473961600174, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 2 with value: -0.29401799544412993.\n","Progress:  10%|█          [ Time Left: 24:26 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 2 took 24.59 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2025-03-12 19:44:32,600] Trial 3 finished with value: -0.29501349338002875 and parameters: {'C': 1.815293063399909, 'solver': 'saga', 'penalty': 'l2'}. Best is trial 2 with value: -0.29401799544412993.\n","Progress:  13%|█▎         [ Time Left: 26:21 ]<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n"]},{"output_type":"stream","name":"stdout","text":["Trial 3 took 70.81 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-12 19:44:38,937] Trial 4 finished with value: -0.29433163955620023 and parameters: {'C': 513.3285430753135, 'solver': 'lbfgs'}. Best is trial 2 with value: -0.29401799544412993.\n","Progress:  17%|█▋         [ Time Left: 17:09 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 4 took 6.33 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-12 19:44:41,652] Trial 5 finished with value: -0.29576366414914773 and parameters: {'C': 0.0017888583388765622, 'solver': 'lbfgs'}. Best is trial 2 with value: -0.29401799544412993.\n","Progress:  20%|██         [ Time Left: 11:14 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 5 took 2.71 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-12 19:44:49,079] Trial 6 finished with value: -0.29433163955620023 and parameters: {'C': 666.1510331868818, 'solver': 'lbfgs'}. Best is trial 2 with value: -0.29401799544412993.\n","Progress:  23%|██▎        [ Time Left: 08:10 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 6 took 7.42 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-12 19:45:26,479] Trial 7 finished with value: -0.2942498148658852 and parameters: {'C': 1.727441566576924, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 2 with value: -0.29401799544412993.\n","Progress:  27%|██▋        [ Time Left: 09:41 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 7 took 37.39 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n","[I 2025-03-12 19:46:51,925] Trial 8 finished with value: -0.29845010340984 and parameters: {'C': 0.012701171745183681, 'solver': 'saga', 'penalty': 'l1'}. Best is trial 2 with value: -0.29401799544412993.\n","Progress:  30%|███        [ Time Left: 15:42 ]<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n"]},{"output_type":"stream","name":"stdout","text":["Trial 8 took 85.44 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-12 19:47:01,616] Trial 9 finished with value: -0.29580455464463506 and parameters: {'C': 0.0019761145580096777, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 2 with value: -0.29401799544412993.\n","Progress:  33%|███▎       [ Time Left: 11:20 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 9 took 9.69 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-12 19:47:23,793] Trial 10 finished with value: -0.29400435753085746 and parameters: {'C': 0.06552305696822575, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 10 with value: -0.29400435753085746.\n","Progress:  37%|███▋       [ Time Left: 09:37 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 10 took 22.17 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-12 19:47:44,629] Trial 11 finished with value: -0.2940316324276292 and parameters: {'C': 0.05377276476367984, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 10 with value: -0.29400435753085746.\n","Progress:  40%|████       [ Time Left: 08:14 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 11 took 20.83 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-12 19:48:07,344] Trial 12 finished with value: -0.29401799451435673 and parameters: {'C': 0.0754536377800365, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 10 with value: -0.29400435753085746.\n","Progress:  43%|████▎      [ Time Left: 07:22 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 12 took 22.70 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-12 19:48:26,293] Trial 13 finished with value: -0.2943589256102504 and parameters: {'C': 0.02558174075935203, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 10 with value: -0.29400435753085746.\n","Progress:  47%|████▋      [ Time Left: 06:22 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 13 took 18.94 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-12 19:55:52,823] Trial 14 finished with value: -0.29426345091961126 and parameters: {'C': 12.693626095133501, 'solver': 'liblinear', 'penalty': 'l1'}. Best is trial 10 with value: -0.29400435753085746.\n","Progress:  50%|█████      [ Time Left: 37:49 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 14 took 446.51 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-12 19:56:26,271] Trial 15 finished with value: -0.29420890019629464 and parameters: {'C': 0.45727256780703535, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 10 with value: -0.29400435753085746.\n","Progress:  53%|█████▎     [ Time Left: 27:01 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 15 took 33.43 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-12 19:56:38,858] Trial 16 finished with value: -0.29482260722332804 and parameters: {'C': 0.007522279305134867, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 10 with value: -0.29400435753085746.\n","Progress:  57%|█████▋     [ Time Left: 18:22 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 16 took 12.58 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-12 19:57:16,980] Trial 17 finished with value: -0.2942498130063388 and parameters: {'C': 18.61743759714379, 'solver': 'liblinear', 'penalty': 'l2'}. Best is trial 10 with value: -0.29400435753085746.\n","Progress:  60%|██████     [ Time Left: 14:09 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 17 took 38.11 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-18-8f9d5c09388f>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-12 19:59:10,034] Trial 18 finished with value: -0.29471349833850924 and parameters: {'C': 0.08857066020851516, 'solver': 'liblinear', 'penalty': 'l1'}. Best is trial 10 with value: -0.29400435753085746.\n","Progress:  63%|██████▎    [ Time Left: 10:57 ]\n"]},{"output_type":"stream","name":"stdout","text":["Trial 18 took 113.04 seconds\n","Best Optuna Hyperparameters for Logistic Regression: {'C': 0.06552305696822575, 'solver': 'liblinear', 'penalty': 'l2'}\n"]},{"output_type":"stream","name":"stderr","text":["\rGridSearch Progress:   0%|           [ time left: ? ]"]},{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n"]},{"output_type":"stream","name":"stderr","text":["GridSearch Progress: 100%|██████████ [ time left: 00:00 ]"]},{"output_type":"stream","name":"stdout","text":["Best parameters for Logistic Regression (GridSearch): {'model__C': 0.1, 'model__class_weight': 'balanced', 'model__max_iter': 100, 'model__solver': 'lbfgs'}\n","Model saved as Logistic_Regression_Optuna_Grid_V2.pkl\n","Model moved to: /content/drive/MyDrive/HotelNoShowPrediction/Logistic_Regression_Optuna_Grid_V2.pkl\n","Logistic Regression tuning completed in 1.864 hr\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# import time\n","# import joblib\n","# import optuna\n","# import shutil\n","# import os\n","# import numpy as np\n","# from tqdm import tqdm\n","# from sklearn.pipeline import Pipeline\n","# from sklearn.linear_model import LogisticRegression\n","# from sklearn.model_selection import GridSearchCV, cross_val_score\n","\n","# # Directory to save the model\n","# destination_dir = \"/content/drive/MyDrive/HotelNoShowPrediction\"\n","# os.makedirs(destination_dir, exist_ok=True)  # Ensure the directory exists\n","\n","# # Train Logistic Regression using Optuna + GridSearch\n","# if \"Logistic Regression\" in model_param_dict:\n","#     model_start_time = time.time()\n","#     print(\"Processing Logistic Regression with Optuna Optimization & GridSearch...\")\n","\n","#     # Define Optuna objective function\n","#     def objective(trial):\n","#         \"\"\"Objective function for Optuna Bayesian Optimization\"\"\"\n","#         C = trial.suggest_float(\"C\", 1e-3, 1e3, log=True)  # ✅ Updated to use suggest_float\n","#         solver = trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\", \"saga\"])\n","#         penalty = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]) if solver != \"lbfgs\" else \"l2\"\n","\n","#         model = LogisticRegression(C=C, solver=solver, penalty=penalty, random_state=model_random_state)\n","#         pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","#         # Measure trial time\n","#         start_time = time.time()\n","#         score = cross_val_score(pipeline, X_train, Y_train, cv=model_cv_num, scoring=model_scoring).mean()\n","#         trial_time = time.time() - start_time\n","\n","#         print(f\"Trial {trial.number} took {trial_time:.2f} seconds\")\n","#         return score  # Optuna optimizes for highest accuracy\n","\n","#     # Step 1: Estimate time per trial using a few test runs\n","#     def estimate_trial_time(objective, n_test_trials=3):\n","#         \"\"\"Runs a few dummy trials to estimate average trial time.\"\"\"\n","#         start_time = time.time()\n","#         for _ in range(n_test_trials):\n","#             objective(optuna.trial.FixedTrial({\n","#                 \"C\": 1.0, \"solver\": \"liblinear\", \"penalty\": \"l2\"\n","#             }))  # Dummy params\n","#         return (time.time() - start_time) / n_test_trials\n","\n","#     avg_trial_time = estimate_trial_time(objective)\n","#     target_trials = 30\n","#     n_jobs = max(model_num_jobs, 1)  # Prevent division by zero\n","\n","#     # Step 2: Compute optimal timeout\n","#     optimal_timeout = max((avg_trial_time * target_trials) / n_jobs, 30)  # At least 30 seconds\n","#     print(f\"Estimated Optuna timeout: {optimal_timeout:.2f} seconds (~{optimal_timeout/60:.2f} minutes)\")\n","\n","#     # Run Optuna optimization with dynamic timeout\n","#     study = optuna.create_study(direction=\"maximize\")\n","\n","#     with tqdm(total=target_trials, desc=\"Optuna Progress\", bar_format=\"{l_bar}{bar} [ Time Left: {remaining} ]\") as pbar:\n","#         def callback(study, trial):\n","#             pbar.update(1)  # Update progress bar per trial\n","\n","#         study.optimize(objective, n_trials=target_trials, timeout=optimal_timeout, callbacks=[callback])\n","\n","#     # Get best hyperparameters from Optuna\n","#     best_params_optuna = study.best_params if len(study.trials) > 0 else None\n","\n","#     if best_params_optuna:\n","#         print(\"Best Optuna Hyperparameters for Logistic Regression:\", best_params_optuna)\n","\n","#         # Define model with Optuna best parameters\n","#         best_model = LogisticRegression(**best_params_optuna, random_state=model_random_state)\n","#         pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n","\n","#         # ✅ Step 3: Estimate GridSearch Execution Time\n","#         def estimate_grid_search_time(search, X_train, Y_train, n_test_runs=3):\n","#             \"\"\"Runs a few dummy GridSearchCV fits to estimate average iteration time.\"\"\"\n","#             times = []\n","#             for _ in range(n_test_runs):\n","#                 start_time = time.time()\n","#                 search.fit(X_train[:100], Y_train[:100])  # Use a subset for quick estimation\n","#                 times.append(time.time() - start_time)\n","#             return np.mean(times)  # Return average time per run\n","\n","#         # Use the same parameters as the actual GridSearch\n","#         grid_search_test = GridSearchCV(\n","#             pipeline,\n","#             param_grid=model_param_dict[\"Logistic Regression\"],\n","#             cv=model_cv_num,\n","#             scoring=model_scoring,\n","#             n_jobs=model_num_jobs,\n","#             verbose=0  # No logs for test runs\n","#         )\n","\n","#         # Get estimated time per iteration\n","#         avg_grid_search_time = estimate_grid_search_time(grid_search_test, X_train, Y_train)\n","\n","#         # Compute optimal timeout (ensure it's positive)\n","#         grid_search_timeout = max(avg_grid_search_time * len(model_param_dict[\"Logistic Regression\"]), 60)  # At least 60s\n","#         print(f\"Estimated GridSearch timeout: {grid_search_timeout:.2f} seconds (~{grid_search_timeout/60:.2f} minutes)\")\n","\n","#         # ✅ Step 4: Run GridSearch with a Time Tracker\n","#         grid_start_time = time.time()\n","#         search = GridSearchCV(\n","#             pipeline,\n","#             param_grid=model_param_dict[\"Logistic Regression\"],\n","#             cv=model_cv_num,\n","#             scoring=model_scoring,\n","#             n_jobs=model_num_jobs,\n","#             verbose=3\n","#         )\n","\n","#         with tqdm(total=100, desc=\"GridSearch Progress\", bar_format=\"{l_bar}{bar} [ time left: {remaining} ]\") as pbar:\n","#             search.fit(X_train, Y_train)\n","#             pbar.update(100)\n","\n","#         grid_duration = time.time() - grid_start_time\n","#         print(f\"GridSearch took {grid_duration:.2f} seconds (~{grid_duration/60:.2f} minutes)\")\n","\n","#         # Save best model\n","#         best_estimators_dict[\"Logistic Regression\"] = search.best_estimator_\n","#         print(\"Best parameters for Logistic Regression (GridSearch):\", search.best_params_)\n","\n","#         # Save the trained model\n","#         model_filename = \"Logistic_Regression_Optuna_Grid_V2.pkl\"\n","#         joblib.dump(search.best_estimator_, model_filename)\n","#         print(f\"Model saved as {model_filename}\")\n","\n","#         # Move the model to the specified directory\n","#         destination_file = os.path.join(destination_dir, model_filename)\n","#         shutil.move(model_filename, destination_file)\n","#         print(f\"Model moved to: {destination_file}\")\n","\n","#     else:\n","#         print(\"Optuna did not complete any successful trials. Skipping GridSearch.\")\n","\n","#     # Log training duration\n","#     model_end_time = time.time()\n","#     model_total_time = model_end_time - model_start_time\n","#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","#     print(f\"Logistic Regression tuning completed in {model_duration:.3f} {model_tag}\")"],"metadata":{"id":"sXfAodNoRNH3"},"id":"sXfAodNoRNH3","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#############################################################################################################################################################################################################################"],"metadata":{"id":"zsj2ZnHKtITa"},"id":"zsj2ZnHKtITa","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#SVC"],"metadata":{"id":"Cw31AvY-tIE5"},"id":"Cw31AvY-tIE5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import optuna\n","# from sklearn.svm import SVC\n","# from sklearn.model_selection import cross_val_score\n","\n","# def objective(trial):\n","#     \"\"\"Objective function for Optuna Bayesian Optimization\"\"\"\n","#     C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","#     kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\", \"poly\", \"sigmoid\"])\n","#     gamma = trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"])\n","\n","#     model = SVC(C=C, kernel=kernel, gamma=gamma)\n","#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","#     score = cross_val_score(pipeline, X_train, Y_train, cv=3, scoring=model_scoring)\n","\n","#     return score.mean()\n","\n","# # Run Optuna Optimization\n","# study = optuna.create_study(direction=\"maximize\")\n","# study.optimize(objective, n_trials=30, timeout=1800)  # 30 trials or max 30 mins\n","\n","# # Train the best model found\n","# best_params = study.best_params\n","# print(\"Best Hyperparameters for SVC:\", best_params)\n","\n","# best_model = SVC(**best_params)\n","# pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n","# pipeline.fit(X_train, Y_train)\n","\n","# # Save best model\n","# best_estimators_dict[\"SVC\"] = pipeline\n","# model_filename = \"SVC_Optuna.pkl\"\n","# joblib.dump(pipeline, model_filename)\n","# print(f\"Optimized SVC model saved as {model_filename}\")\n"],"metadata":{"id":"KzC0HCUnttSo"},"id":"KzC0HCUnttSo","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","import joblib\n","import optuna\n","import shutil\n","import os\n","from sklearn.pipeline import Pipeline\n","from sklearn.svm import SVC\n","from sklearn.model_selection import cross_val_score\n","from tqdm import tqdm\n","\n","# Directory to save the model\n","destination_dir = \"/content/drive/MyDrive/HotelNoShowPrediction\"\n","os.makedirs(destination_dir, exist_ok=True)  # Ensure the directory exists\n","\n","# Train SVC using Optuna\n","print(\"Processing SVC with Optuna Optimization...\")\n","\n","def objective(trial):\n","    \"\"\"Objective function for Optuna Bayesian Optimization\"\"\"\n","    C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","    kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\", \"poly\", \"sigmoid\"])\n","    gamma = trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"])\n","\n","    model = SVC(C=C, kernel=kernel, gamma=gamma)\n","    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","    # Measure trial time\n","    start_time = time.time()\n","    score = cross_val_score(pipeline, X_train, Y_train, cv=3, scoring=model_scoring).mean()\n","    trial_time = time.time() - start_time\n","\n","    print(f\"Trial {trial.number} took {trial_time:.2f} seconds\")\n","    return score  # Optuna optimizes for highest score\n","\n","# Step 1: Estimate time per trial using a few test runs\n","def estimate_trial_time(objective, n_test_trials=3):\n","    \"\"\"Runs a few dummy trials to estimate average trial time.\"\"\"\n","    start_time = time.time()\n","    for _ in range(n_test_trials):\n","        objective(optuna.trial.FixedTrial({\n","            \"C\": 1.0, \"kernel\": \"rbf\", \"gamma\": \"scale\"\n","        }))  # Dummy params\n","    return (time.time() - start_time) / n_test_trials\n","\n","avg_trial_time = estimate_trial_time(objective)\n","target_trials = 30\n","n_jobs = 4  # Adjust based on available CPU cores\n","\n","# Step 2: Compute optimal timeout\n","optimal_timeout = (avg_trial_time * target_trials) / n_jobs\n","print(f\"Estimated optimal timeout: {optimal_timeout:.2f} seconds (~{optimal_timeout/60:.2f} minutes)\")\n","\n","# Run Optuna optimization with dynamic timeout\n","study = optuna.create_study(direction=\"maximize\")\n","\n","with tqdm(total=target_trials, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ Time Left: {remaining} ]\") as pbar:\n","    def callback(study, trial):\n","        pbar.update(1)  # Update progress bar per trial\n","\n","    study.optimize(objective, n_trials=target_trials, timeout=optimal_timeout, callbacks=[callback])\n","\n","# Get best parameters\n","best_params = study.best_params\n","print(\"Best Hyperparameters for SVC:\", best_params)\n","\n","# Train final model with best parameters\n","best_model = SVC(**best_params)\n","pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n","pipeline.fit(X_train, Y_train)\n","\n","\n","best_estimators_dict[\"SVC\"] = pipeline\n","model_filename = \"SVC_Optuna_V2.pkl\"\n","joblib.dump(pipeline, model_filename)\n","print(f\"Optimized SVC model saved as {model_filename}\")\n","\n","# Move the model to the specified directory\n","destination_file = os.path.join(destination_dir, model_filename)\n","shutil.move(model_filename, destination_file)\n","print(f\"Model moved to: {destination_file}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"686qmv-vtYNp","outputId":"a80d0907-d38d-41bd-ca17-27b8cc649abb"},"id":"686qmv-vtYNp","execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Processing SVC with Optuna Optimization...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-14-7f6a75d9421d>:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trial 0 took 1229.90 seconds\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-14-7f6a75d9421d>:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trial 0 took 1201.66 seconds\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-14-7f6a75d9421d>:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-12 23:31:42,093] A new study created in memory with name: no-name-7f362b7c-695f-405d-bf22-1a0fdd1adc58\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trial 0 took 1199.90 seconds\n","Estimated optimal timeout: 9078.68 seconds (~151.31 minutes)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Progress:   0%|           [ Time Left: ? ]<ipython-input-14-7f6a75d9421d>:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-12 23:51:05,133] Trial 0 finished with value: -0.3076828669612175 and parameters: {'C': 0.7769626443215099, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: -0.3076828669612175.\n","Progress:   3%|▎          [ Time Left: 9:22:08 ]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trial 0 took 1163.04 seconds\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-14-7f6a75d9421d>:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-13 00:07:15,408] Trial 1 finished with value: -0.3177739595265368 and parameters: {'C': 0.14302711286620115, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 0 with value: -0.3076828669612175.\n","Progress:   7%|▋          [ Time Left: 8:09:50 ]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trial 1 took 970.27 seconds\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-14-7f6a75d9421d>:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n","[I 2025-03-13 00:23:05,548] Trial 2 finished with value: -0.4307669230349643 and parameters: {'C': 910.0518611893375, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 0 with value: -0.3076828669612175.\n","Progress:  10%|█          [ Time Left: 7:31:53 ]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trial 2 took 950.14 seconds\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-14-7f6a75d9421d>:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  C = trial.suggest_loguniform(\"C\", 1e-3, 1e3)\n"]}]},{"cell_type":"code","source":["import time\n","import joblib\n","import optuna\n","import shutil\n","import os\n","from tqdm import tqdm\n","from sklearn.pipeline import Pipeline\n","from sklearn.svm import SVC\n","from sklearn.model_selection import cross_val_score\n","\n","# Directory to save the model\n","destination_dir = \"/content/drive/MyDrive/HotelNoShowPrediction\"\n","os.makedirs(destination_dir, exist_ok=True)  # Ensure the directory exists\n","\n","# Print an update\n","print(\"Processing SVC with Optuna Optimization (Reduced Parameter Space)...\")\n","\n","def objective(trial):\n","    \"\"\"Objective function for Optuna Bayesian Optimization\"\"\"\n","    # 1) Use suggest_float(..., log=True) to replace suggest_loguniform\n","    #    Keep a smaller range for C\n","    C = trial.suggest_float(\"C\", 1e-2, 1e2, log=True)\n","\n","    # 2) Fewer kernel choices for speed\n","    kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"])\n","\n","    # 3) gamma = only \"scale\" or \"auto\", or fix it to \"scale\" if you want even less search\n","    gamma = trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"])\n","\n","    # Create the SVC\n","    model = SVC(C=C, kernel=kernel, gamma=gamma, random_state=model_random_state)\n","\n","    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","    # Measure trial time\n","    start_time = time.time()\n","    score = cross_val_score(pipeline, X_train, Y_train, cv=3, scoring=model_scoring).mean()\n","    trial_time = time.time() - start_time\n","\n","    print(f\"Trial {trial.number} took {trial_time:.2f} seconds\")\n","    return score  # Optuna optimizes for highest score\n","\n","def estimate_trial_time(objective, n_test_trials=3):\n","    \"\"\"Runs a few dummy trials to estimate average trial time.\"\"\"\n","    start_time = time.time()\n","    for _ in range(n_test_trials):\n","        # Dummy params for smaller range\n","        objective(optuna.trial.FixedTrial({\n","            \"C\": 1.0,\n","            \"kernel\": \"rbf\",\n","            \"gamma\": \"scale\",\n","        }))\n","    return (time.time() - start_time) / n_test_trials\n","\n","avg_trial_time = estimate_trial_time(objective)\n","target_trials = 30\n","n_jobs = 4  # Adjust based on available CPU cores\n","\n","optimal_timeout = (avg_trial_time * target_trials) / n_jobs\n","print(f\"Estimated optimal timeout: {optimal_timeout:.2f} seconds (~{optimal_timeout/60:.2f} minutes)\")\n","\n","study = optuna.create_study(direction=\"maximize\")\n","\n","with tqdm(total=target_trials, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ Time Left: {remaining} ]\") as pbar:\n","    def callback(study, trial):\n","        pbar.update(1)\n","\n","    study.optimize(objective, n_trials=target_trials, timeout=optimal_timeout, callbacks=[callback])\n","\n","best_params = study.best_params\n","print(\"Best Hyperparameters for SVC:\", best_params)\n","\n","# Create final model with best parameters\n","best_model = SVC(**best_params, random_state=model_random_state)\n","pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n","pipeline.fit(X_train, Y_train)\n","\n","# Save best model\n","best_estimators_dict[\"SVC\"] = pipeline\n","model_filename = \"SVC_Optuna_ReducedParams.pkl\"\n","joblib.dump(pipeline, model_filename)\n","print(f\"Optimized SVC model saved as {model_filename}\")\n","\n","# Move the model to the specified directory\n","destination_file = os.path.join(destination_dir, model_filename)\n","shutil.move(model_filename, destination_file)\n","print(f\"Model moved to: {destination_file}\")\n","\n","# Log training duration\n","model_end_time = time.time()\n","model_total_time = model_end_time - model_start_time\n","model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","print(f\"SVC Optuna tuning completed in {model_duration:.3f} {model_tag}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wt4UssYEo9zG","outputId":"0562b9ee-2cbf-40f4-b9f1-4eaec9097665"},"id":"wt4UssYEo9zG","execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Processing SVC with Optuna Optimization (Reduced Parameter Space)...\n","Trial 0 took 1190.96 seconds\n","Trial 0 took 1197.47 seconds\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["[I 2025-03-13 14:19:03,503] A new study created in memory with name: no-name-dd5a61b7-d117-433c-b44b-ce967ccf8d32\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trial 0 took 1198.19 seconds\n","Estimated optimal timeout: 8966.57 seconds (~149.44 minutes)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rProgress:   0%|           [ Time Left: ? ]"]}]},{"cell_type":"markdown","source":["What Changed Compared to Your Original Code?\n","\t1.\tReplaced suggest_loguniform(\"C\", 1e-3, 1e3) with suggest_float(\"C\", 1e-2, 1e2, log=True).\n","\t•\tSmaller range: from 1e-2 to 1e2. This drastically reduces the search space for C.\n","\t2.\tReduced kernel choices to [\"linear\", \"rbf\"] instead of 4.\n","\t•\tFewer combos means faster overall search.\n","\t3.\tKept gamma as [\"scale\", \"auto\"]. If you want to fix it to just \"scale\", you can do so for even faster runs.\n","\t4.\tNo more FutureWarning since we used suggest_float(..., log=True).\n","\t5.\tRetains the time estimation logic, dynamic timeout, and tqdm progress bar."],"metadata":{"id":"HckYJp3AqLvD"},"id":"HckYJp3AqLvD"},{"cell_type":"code","source":["#### MLP"],"metadata":{"id":"QgXgNgwgtYIx"},"id":"QgXgNgwgtYIx","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"5G9ODgW7zbv-","metadata":{"id":"5G9ODgW7zbv-"},"outputs":[],"source":["# import time\n","# import joblib\n","# import optuna\n","# from tqdm import tqdm\n","# from sklearn.pipeline import Pipeline\n","# from sklearn.neural_network import MLPClassifier\n","# from sklearn.model_selection import cross_val_score\n","\n","# # Train MLP using Optuna\n","# if \"MLP\" in model_param_dict:\n","#     model_start_time = time.time()\n","#     print(\"Processing MLP with Optuna Optimization...\")\n","\n","#     def objective(trial):\n","#         \"\"\"Objective function for Optuna Bayesian Optimization\"\"\"\n","#         hidden_layer_sizes = trial.suggest_categorical(\"hidden_layer_sizes\", [(50,), (100,), (50, 50), (100, 100)])\n","#         activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\", \"logistic\"])\n","#         solver = trial.suggest_categorical(\"solver\", [\"adam\", \"sgd\"])\n","#         alpha = trial.suggest_loguniform(\"alpha\", 1e-4, 1e-1)\n","#         learning_rate_init = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-2)\n","\n","#         model = MLPClassifier(\n","#             hidden_layer_sizes=hidden_layer_sizes,\n","#             activation=activation,\n","#             solver=solver,\n","#             alpha=alpha,\n","#             learning_rate_init=learning_rate_init,\n","#             max_iter=200,  # Initial limit (can be increased later)\n","#             random_state=model_random_state\n","#         )\n","\n","#         pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","#         score = cross_val_score(pipeline, X_train, Y_train, cv=model_cv_num, scoring=model_scoring).mean()\n","\n","#         return score  # Maximizing accuracy\n","\n","#     # Run Optuna optimization\n","#     study = optuna.create_study(direction=\"maximize\")\n","\n","#     with tqdm(total=30, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ Time Left: {remaining} ]\") as pbar:\n","#         def callback(study, trial):\n","#             pbar.update(1)  # Update progress bar per trial\n","\n","#         study.optimize(objective, n_trials=30, timeout=1800, callbacks=[callback])  # 30 trials, max 30 mins\n","\n","#     # Get best parameters\n","#     best_params = study.best_params\n","#     print(\"Best Hyperparameters for MLP:\", best_params)\n","\n","#     # Train final model with best parameters\n","#     best_model = MLPClassifier(**best_params, max_iter=500, random_state=model_random_state)\n","#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n","#     pipeline.fit(X_train, Y_train)\n","\n","#     # Save best model\n","#     best_estimators_dict[\"MLP\"] = pipeline\n","#     model_filename = \"MLP_Optuna.pkl\"\n","#     joblib.dump(pipeline, model_filename)\n","#     print(f\"Optimized MLP model saved as {model_filename}\")\n","\n","#     # Log training duration\n","#     model_end_time = time.time()\n","#     model_total_time = model_end_time - model_start_time\n","#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","#     print(f\"MLP Optuna tuning completed in {model_duration:.3f} {model_tag}\")"]},{"cell_type":"code","source":["import time\n","import joblib\n","import optuna\n","import shutil\n","import os\n","from tqdm import tqdm\n","from sklearn.pipeline import Pipeline\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import cross_val_score\n","\n","# Directory to save the model\n","destination_dir = \"/content/drive/MyDrive/HotelNoShowPrediction\"\n","os.makedirs(destination_dir, exist_ok=True)  # Ensure the directory exists\n","\n","# Train MLP using Optuna\n","if \"MLP\" in model_param_dict:\n","    model_start_time = time.time()\n","    print(\"Processing MLP with Optuna Optimization...\")\n","\n","    def objective(trial):\n","        \"\"\"Objective function for Optuna Bayesian Optimization\"\"\"\n","        hidden_layer_sizes = trial.suggest_categorical(\"hidden_layer_sizes\", [(50,), (100,), (50, 50), (100, 100)])\n","        activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\", \"logistic\"])\n","        solver = trial.suggest_categorical(\"solver\", [\"adam\", \"sgd\"])\n","        alpha = trial.suggest_loguniform(\"alpha\", 1e-4, 1e-1)\n","        learning_rate_init = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-2)\n","\n","        model = MLPClassifier(\n","            hidden_layer_sizes=hidden_layer_sizes,\n","            activation=activation,\n","            solver=solver,\n","            alpha=alpha,\n","            learning_rate_init=learning_rate_init,\n","            max_iter=200,  # Initial limit (can be increased later)\n","            random_state=model_random_state\n","        )\n","\n","        pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","        # Measure trial time\n","        start_time = time.time()\n","        score = cross_val_score(pipeline, X_train, Y_train, cv=model_cv_num, scoring=model_scoring).mean()\n","        trial_time = time.time() - start_time\n","\n","        print(f\"Trial {trial.number} took {trial_time:.2f} seconds\")\n","        return score  # Maximizing accuracy\n","\n","    # Step 1: Estimate time per trial using a few test runs\n","    def estimate_trial_time(objective, n_test_trials=3):\n","        \"\"\"Runs a few dummy trials to estimate average trial time.\"\"\"\n","        start_time = time.time()\n","        for _ in range(n_test_trials):\n","            objective(optuna.trial.FixedTrial({\n","                \"hidden_layer_sizes\": (100,),\n","                \"activation\": \"relu\",\n","                \"solver\": \"adam\",\n","                \"alpha\": 1e-4,\n","                \"learning_rate_init\": 1e-3\n","            }))  # Dummy params\n","        return (time.time() - start_time) / n_test_trials\n","\n","    avg_trial_time = estimate_trial_time(objective)\n","    target_trials = 30\n","    n_jobs = 4  # Adjust based on available CPU cores\n","\n","    # Step 2: Compute optimal timeout\n","    optimal_timeout = (avg_trial_time * target_trials) / n_jobs\n","    print(f\"Estimated optimal timeout: {optimal_timeout:.2f} seconds (~{optimal_timeout/60:.2f} minutes)\")\n","\n","    # Run Optuna optimization with dynamic timeout\n","    study = optuna.create_study(direction=\"maximize\")\n","\n","    with tqdm(total=target_trials, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ Time Left: {remaining} ]\") as pbar:\n","        def callback(study, trial):\n","            pbar.update(1)  # Update progress bar per trial\n","\n","        study.optimize(objective, n_trials=target_trials, timeout=optimal_timeout, callbacks=[callback])\n","\n","    # Get best parameters\n","    best_params = study.best_params\n","    print(\"Best Hyperparameters for MLP:\", best_params)\n","\n","    # Train final model with best parameters\n","    best_model = MLPClassifier(**best_params, max_iter=500, random_state=model_random_state)\n","    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n","    pipeline.fit(X_train, Y_train)\n","\n","    # Save best model\n","    best_estimators_dict[\"MLP\"] = pipeline\n","    model_filename = \"MLP_Optuna_V2.pkl\"\n","    joblib.dump(pipeline, model_filename)\n","    print(f\"Optimized MLP model saved as {model_filename}\")\n","\n","    # Move the model to the specified directory\n","    destination_file = os.path.join(destination_dir, model_filename)\n","    shutil.move(model_filename, destination_file)\n","    print(f\"Model moved to: {destination_file}\")\n","\n","    # Log training duration\n","    model_end_time = time.time()\n","    model_total_time = model_end_time - model_start_time\n","    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","    print(f\"MLP Optuna tuning completed in {model_duration:.3f} {model_tag}\")"],"metadata":{"id":"sj4EjKKftyPZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"27680c20-e1a1-4289-cc93-801f440f878a"},"id":"sj4EjKKftyPZ","execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Processing MLP with Optuna Optimization...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100) which is of type tuple.\n","  warnings.warn(message)\n","<ipython-input-14-1b520996b14a>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-4, 1e-1)\n","<ipython-input-14-1b520996b14a>:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate_init = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-2)\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trial 0 took 446.43 seconds\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100) which is of type tuple.\n","  warnings.warn(message)\n","<ipython-input-14-1b520996b14a>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-4, 1e-1)\n","<ipython-input-14-1b520996b14a>:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate_init = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-2)\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trial 0 took 436.30 seconds\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100) which is of type tuple.\n","  warnings.warn(message)\n","<ipython-input-14-1b520996b14a>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-4, 1e-1)\n","<ipython-input-14-1b520996b14a>:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate_init = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-2)\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","[I 2025-03-13 07:41:46,398] A new study created in memory with name: no-name-a888bc25-a746-49c0-a998-19b439695415\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trial 0 took 427.06 seconds\n","Estimated optimal timeout: 3274.47 seconds (~54.57 minutes)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Progress:   0%|           [ Time Left: ? ]/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100) which is of type tuple.\n","  warnings.warn(message)\n","<ipython-input-14-1b520996b14a>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-4, 1e-1)\n","<ipython-input-14-1b520996b14a>:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate_init = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-2)\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","[I 2025-03-13 07:52:22,573] Trial 0 finished with value: -0.28691338086910384 and parameters: {'hidden_layer_sizes': (100, 100), 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.01248174798720417, 'learning_rate_init': 0.00011971920007880027}. Best is trial 0 with value: -0.28691338086910384.\n","Progress:   3%|▎          [ Time Left: 5:07:29 ]/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100) which is of type tuple.\n","  warnings.warn(message)\n","<ipython-input-14-1b520996b14a>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-4, 1e-1)\n","<ipython-input-14-1b520996b14a>:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate_init = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-2)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trial 0 took 636.17 seconds\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","[I 2025-03-13 08:13:10,169] Trial 1 finished with value: -0.2791403653586552 and parameters: {'hidden_layer_sizes': (100, 100), 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.0002542518928707305, 'learning_rate_init': 0.009379874090558557}. Best is trial 1 with value: -0.2791403653586552.\n","Progress:   7%|▋          [ Time Left: 7:44:43 ]/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n","  warnings.warn(message)\n","/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 100) which is of type tuple.\n","  warnings.warn(message)\n","<ipython-input-14-1b520996b14a>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-4, 1e-1)\n","<ipython-input-14-1b520996b14a>:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate_init = trial.suggest_loguniform(\"learning_rate_init\", 1e-4, 1e-2)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Trial 1 took 1247.59 seconds\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["## Revision of the above\n","import time\n","import joblib\n","import optuna\n","import shutil\n","import os\n","from tqdm import tqdm\n","from sklearn.pipeline import Pipeline\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import cross_val_score\n","\n","# Directory to save the model\n","destination_dir = \"/content/drive/MyDrive/HotelNoShowPrediction\"\n","os.makedirs(destination_dir, exist_ok=True)  # Ensure the directory exists\n","\n","# Map friendly labels (strings) to actual tuples\n","HIDDEN_LAYER_MAP = {\n","    \"50\": (50,),\n","    \"100\": (100,),\n","    \"50-50\": (50, 50),\n","    \"100-100\": (100, 100)\n","}\n","\n","# Train MLP using Optuna\n","if \"MLP\" in model_param_dict:\n","    model_start_time = time.time()\n","    print(\"Processing MLP with Optuna Optimization...\")\n","\n","    def objective(trial):\n","        \"\"\"Objective function for Optuna Bayesian Optimization\"\"\"\n","\n","        # 1) Suggest hidden_layer_sizes as string label\n","        hidden_str = trial.suggest_categorical(\"hidden_layer_sizes\", [\"50\", \"100\", \"50-50\", \"100-100\"])\n","        hidden_layer_sizes = HIDDEN_LAYER_MAP[hidden_str]  # Convert label to tuple\n","\n","        # 2) Suggest activation and solver\n","        activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\", \"logistic\"])\n","        solver = trial.suggest_categorical(\"solver\", [\"adam\", \"sgd\"])\n","\n","        # 3) Use `suggest_float(..., log=True)` for alpha & learning_rate_init\n","        alpha = trial.suggest_float(\"alpha\", 1e-4, 1e-1, log=True)\n","        learning_rate_init = trial.suggest_float(\"learning_rate_init\", 1e-4, 1e-2, log=True)\n","\n","        # 4) Optionally increase max_iter to reduce ConvergenceWarning\n","        model = MLPClassifier(\n","            hidden_layer_sizes=hidden_layer_sizes,\n","            activation=activation,\n","            solver=solver,\n","            alpha=alpha,\n","            learning_rate_init=learning_rate_init,\n","            max_iter=300,  # Increased from 200 to 300\n","            random_state=model_random_state\n","        )\n","\n","        pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","        # Measure trial time\n","        start_time = time.time()\n","        score = cross_val_score(pipeline, X_train, Y_train, cv=model_cv_num, scoring=model_scoring).mean()\n","        trial_time = time.time() - start_time\n","\n","        print(f\"Trial {trial.number} took {trial_time:.2f} seconds\")\n","        return score  # Maximizing accuracy\n","\n","    # Step 1: Estimate time per trial using a few test runs\n","    def estimate_trial_time(objective, n_test_trials=3):\n","        \"\"\"Runs a few dummy trials to estimate average trial time.\"\"\"\n","        start_time = time.time()\n","        for _ in range(n_test_trials):\n","            objective(optuna.trial.FixedTrial({\n","                \"hidden_layer_sizes\": \"100\",   # or any valid label\n","                \"activation\": \"relu\",\n","                \"solver\": \"adam\",\n","                \"alpha\": 1e-4,\n","                \"learning_rate_init\": 1e-3\n","            }))\n","        return (time.time() - start_time) / n_test_trials\n","\n","    avg_trial_time = estimate_trial_time(objective)\n","    target_trials = 30\n","    n_jobs = 4  # Adjust based on available CPU cores\n","\n","    # Step 2: Compute optimal timeout\n","    optimal_timeout = (avg_trial_time * target_trials) / n_jobs\n","    print(f\"Estimated optimal timeout: {optimal_timeout:.2f} seconds (~{optimal_timeout/60:.2f} minutes)\")\n","\n","    # Run Optuna optimization with dynamic timeout\n","    study = optuna.create_study(direction=\"maximize\")\n","\n","    with tqdm(total=target_trials, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ Time Left: {remaining} ]\") as pbar:\n","        def callback(study, trial):\n","            pbar.update(1)  # Update progress bar per trial\n","\n","        study.optimize(objective, n_trials=target_trials, timeout=optimal_timeout, callbacks=[callback])\n","\n","    # Get best parameters\n","    best_params = study.best_params\n","    print(\"Best Hyperparameters for MLP:\", best_params)\n","\n","    # Convert best_params hidden_layer_sizes from string to tuple\n","    best_params[\"hidden_layer_sizes\"] = HIDDEN_LAYER_MAP[best_params[\"hidden_layer_sizes\"]]\n","\n","    # Train final model with best parameters\n","    # Increase max_iter further if needed\n","    best_model = MLPClassifier(**best_params, max_iter=500, random_state=model_random_state)\n","    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n","    pipeline.fit(X_train, Y_train)\n","\n","    # Save best model\n","    best_estimators_dict[\"MLP\"] = pipeline\n","    model_filename = \"MLP_Optuna_V2.pkl\"\n","    joblib.dump(pipeline, model_filename)\n","    print(f\"Optimized MLP model saved as {model_filename}\")\n","\n","    # Move the model to the specified directory\n","    destination_file = os.path.join(destination_dir, model_filename)\n","    shutil.move(model_filename, destination_file)\n","    print(f\"Model moved to: {destination_file}\")\n","\n","    # Log training duration\n","    model_end_time = time.time()\n","    model_total_time = model_end_time - model_start_time\n","    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","    print(f\"MLP Optuna tuning completed in {model_duration:.3f} {model_tag}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jEMDkCc_Lnkd","executionInfo":{"status":"ok","timestamp":1741871554307,"user_tz":-480,"elapsed":7554766,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"}},"outputId":"662ff01d-3926-4425-c46a-600c207ba20e"},"id":"jEMDkCc_Lnkd","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing MLP with Optuna Optimization...\n","Trial 0 took 535.10 seconds\n","Trial 0 took 526.91 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-13 11:33:11,104] A new study created in memory with name: no-name-d68694e2-5510-4aa0-b2d9-37d514c00c2e\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 529.42 seconds\n","Estimated optimal timeout: 3978.57 seconds (~66.31 minutes)\n"]},{"output_type":"stream","name":"stderr","text":["Progress:   0%|           [ Time Left: ? ][I 2025-03-13 11:39:19,414] Trial 0 finished with value: -0.3017092718033977 and parameters: {'hidden_layer_sizes': '50-50', 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0219212820786412, 'learning_rate_init': 0.0007746234227637439}. Best is trial 0 with value: -0.3017092718033977.\n","Progress:   3%|▎          [ Time Left: 2:58:00 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 368.30 seconds\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-03-13 11:44:15,005] Trial 1 finished with value: -0.30320950641771766 and parameters: {'hidden_layer_sizes': '50', 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.0011922654951192423, 'learning_rate_init': 0.00020190648244766178}. Best is trial 0 with value: -0.3017092718033977.\n","Progress:   7%|▋          [ Time Left: 2:31:54 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 1 took 295.59 seconds\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","[I 2025-03-13 12:20:16,678] Trial 2 finished with value: -0.27037203135853505 and parameters: {'hidden_layer_sizes': '100-100', 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.0012315146938972597, 'learning_rate_init': 0.0032489524379883893}. Best is trial 2 with value: -0.27037203135853505.\n","Progress:  10%|█          [ Time Left: 8:43:46 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 2 took 2161.67 seconds\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","[I 2025-03-13 12:34:04,795] Trial 3 finished with value: -0.2715175203067813 and parameters: {'hidden_layer_sizes': '50', 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.06225342350770968, 'learning_rate_init': 0.0025788196512302316}. Best is trial 2 with value: -0.27037203135853505.\n","Progress:  13%|█▎         [ Time Left: 7:26:55 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 3 took 828.11 seconds\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n","[I 2025-03-13 12:57:27,152] Trial 4 finished with value: -0.2713129953070349 and parameters: {'hidden_layer_sizes': '50-50', 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.002024262239268133, 'learning_rate_init': 0.00033141064845032607}. Best is trial 2 with value: -0.27037203135853505.\n","Progress:  17%|█▋         [ Time Left: 7:01:20 ]\n"]},{"output_type":"stream","name":"stdout","text":["Trial 4 took 1402.35 seconds\n","Best Hyperparameters for MLP: {'hidden_layer_sizes': '100-100', 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.0012315146938972597, 'learning_rate_init': 0.0032489524379883893}\n","Optimized MLP model saved as MLP_Optuna_V2.pkl\n","Model moved to: /content/drive/MyDrive/HotelNoShowPrediction/MLP_Optuna_V2.pkl\n","MLP Optuna tuning completed in 2.099 hr\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["###################################################################################################################################################################################################"],"metadata":{"id":"P1ZZEfqTtyIh"},"id":"P1ZZEfqTtyIh","execution_count":null,"outputs":[]},{"cell_type":"code","source":["## NAIVE"],"metadata":{"id":"HCOWjP1A2Dpi"},"id":"HCOWjP1A2Dpi","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","import joblib\n","import optuna\n","import shutil\n","import os\n","from tqdm import tqdm\n","from sklearn.pipeline import Pipeline\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n","\n","# Directory to save the model\n","destination_dir = \"/content/drive/MyDrive/HotelNoShowPrediction\"\n","os.makedirs(destination_dir, exist_ok=True)  # Ensure the directory exists\n","\n","# Train Naive Bayes using Optuna + Grid/Random Search\n","if \"Naive Bayes\" in model_param_dict:\n","    model_start_time = time.time()\n","    print(\"Processing Naive Bayes with Optuna Optimization & Grid/Random Search...\")\n","\n","    # Define Optuna objective function\n","    def objective(trial):\n","        \"\"\"Objective function for Optuna Bayesian Optimization\"\"\"\n","        alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","        binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","\n","        model = BernoulliNB(alpha=alpha, binarize=binarize)\n","        pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","        # Measure trial time\n","        start_time = time.time()\n","        score = cross_val_score(pipeline, X_train, Y_train, cv=model_cv_num, scoring=model_scoring).mean()\n","        trial_time = time.time() - start_time\n","\n","        print(f\"Trial {trial.number} took {trial_time:.2f} seconds\")\n","        return score  # Optuna optimizes for highest accuracy\n","\n","    # Step 1: Estimate time per trial using a few test runs\n","    def estimate_trial_time(objective, n_test_trials=3):\n","        \"\"\"Runs a few dummy trials to estimate average trial time.\"\"\"\n","        start_time = time.time()\n","        for _ in range(n_test_trials):\n","            objective(optuna.trial.FixedTrial({\n","                \"alpha\": 0.1,\n","                \"binarize\": 0.5\n","            }))  # Dummy params\n","        return (time.time() - start_time) / n_test_trials\n","\n","    avg_trial_time = estimate_trial_time(objective)\n","    target_trials = 30\n","    n_jobs = max(model_num_jobs, 1)  # Prevent division by zero\n","\n","    # Step 2: Compute optimal timeout\n","    optimal_timeout = max((avg_trial_time * target_trials) / n_jobs, 30)  # Ensure timeout is positive\n","    print(f\"Estimated optimal timeout: {optimal_timeout:.2f} seconds (~{optimal_timeout/60:.2f} minutes)\")\n","\n","    # Run Optuna optimization with dynamic timeout\n","    study = optuna.create_study(direction=\"maximize\")\n","\n","    with tqdm(total=target_trials, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ Time Left: {remaining} ]\") as pbar:\n","        def callback(study, trial):\n","            pbar.update(1)  # Update progress bar per trial\n","\n","        study.optimize(objective, n_trials=target_trials, timeout=optimal_timeout, callbacks=[callback])\n","\n","    # Get best hyperparameters from Optuna\n","    best_params_optuna = study.best_params if len(study.trials) > 0 else None\n","\n","    if best_params_optuna:\n","        print(\"Best Optuna Hyperparameters for Naive Bayes:\", best_params_optuna)\n","\n","        # Define model with Optuna best parameters\n","        best_model = BernoulliNB(**best_params_optuna)\n","        pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n","\n","        # **GRID or RANDOM SEARCH with Optuna Best Parameters**\n","        if model_search_method == \"grid\":\n","            search = GridSearchCV(\n","                pipeline,\n","                param_grid=model_param_dict[\"Naive Bayes\"],\n","                cv=model_cv_num,\n","                scoring=model_scoring,\n","                n_jobs=model_num_jobs,\n","                verbose=3\n","            )\n","        elif model_search_method == \"random\":\n","            search = RandomizedSearchCV(\n","                pipeline,\n","                param_distributions=model_param_dict[\"Naive Bayes\"],\n","                n_iter=model_num_iter,\n","                cv=model_cv_num,\n","                scoring=model_scoring,\n","                random_state=model_random_state,\n","                n_jobs=model_num_jobs,\n","            )\n","\n","        # Progress tracking\n","        with tqdm(total=100, desc=\"GridSearch Progress\", bar_format=\"{l_bar}{bar} [ time left: {remaining} ]\") as pbar:\n","            search.fit(X_train, Y_train)\n","            pbar.update(100)\n","\n","        # Save best model\n","        best_estimators_dict[\"Naive Bayes\"] = search.best_estimator_\n","        print(\"Best parameters for Naive Bayes (Grid/Random Search):\", search.best_params_)\n","\n","        # Save the trained model\n","        model_filename = \"Naive_Bayes_Optuna_Grid_V2.pkl\"\n","        joblib.dump(search.best_estimator_, model_filename)\n","        print(f\"Model saved as {model_filename}\")\n","\n","        # Move the model to the specified directory\n","        destination_file = os.path.join(destination_dir, model_filename)\n","        shutil.move(model_filename, destination_file)\n","        print(f\"Model moved to: {destination_file}\")\n","\n","    else:\n","        print(\"Optuna did not complete any successful trials. Skipping GridSearch.\")\n","\n","    # Log training duration\n","    model_end_time = time.time()\n","    model_total_time = model_end_time - model_start_time\n","    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","    print(f\"Naive Bayes tuning completed in {model_duration:.3f} {model_tag}\")"],"metadata":{"id":"80XA6wrI2Dgc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741861829487,"user_tz":-480,"elapsed":80056,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"}},"outputId":"e3f9c452-56e0-44ed-bd50-99f8b3bf3738"},"id":"80XA6wrI2Dgc","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing Naive Bayes with Optuna Optimization & Grid/Random Search...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 2.08 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 2.25 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:16,229] A new study created in memory with name: no-name-57ebffb6-e1be-4714-a38b-d44b8bb375f2\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 2.34 seconds\n","Estimated optimal timeout: 66.63 seconds (~1.11 minutes)\n"]},{"output_type":"stream","name":"stderr","text":["\rProgress:   0%|           [ Time Left: ? ]<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:18,419] Trial 0 finished with value: -0.308746168207073 and parameters: {'alpha': 0.17423614942432902, 'binarize': 0.06439998373012247}. Best is trial 0 with value: -0.308746168207073.\n","Progress:   3%|▎          [ Time Left: 01:03 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 2.19 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:20,530] Trial 1 finished with value: -0.3089780118029315 and parameters: {'alpha': 0.11174783683545861, 'binarize': 0.0018457293689717897}. Best is trial 0 with value: -0.308746168207073.\n","Progress:   7%|▋          [ Time Left: 00:59 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 1 took 2.11 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:22,657] Trial 2 finished with value: -0.307477952915746 and parameters: {'alpha': 0.2332517718573043, 'binarize': 0.11857704557342007}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  10%|█          [ Time Left: 00:57 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 2 took 2.12 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:24,788] Trial 3 finished with value: -0.3088416382488462 and parameters: {'alpha': 0.41957349628943863, 'binarize': 0.012410235615344167}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  13%|█▎         [ Time Left: 00:55 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 3 took 2.13 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:26,915] Trial 4 finished with value: -0.3140098708999687 and parameters: {'alpha': 0.5849867610053929, 'binarize': 0.644848525402988}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  17%|█▋         [ Time Left: 00:53 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 4 took 2.12 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:29,073] Trial 5 finished with value: -0.3089370999226605 and parameters: {'alpha': 0.001412321839013357, 'binarize': 0.007835845042068017}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  20%|██         [ Time Left: 00:51 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 5 took 2.16 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:31,264] Trial 6 finished with value: -0.30897801087315824 and parameters: {'alpha': 0.05242329824583967, 'binarize': 0.0014055376140371407}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  23%|██▎        [ Time Left: 00:49 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 6 took 2.19 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:33,371] Trial 7 finished with value: -0.3087461765750319 and parameters: {'alpha': 0.0037042491045339685, 'binarize': 0.017156361208120453}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  27%|██▋        [ Time Left: 00:47 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 7 took 2.10 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:35,673] Trial 8 finished with value: -0.3088552798812115 and parameters: {'alpha': 0.03648031242184737, 'binarize': 0.004744644524515562}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  30%|███        [ Time Left: 00:46 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 8 took 2.30 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:37,994] Trial 9 finished with value: -0.31406441325532647 and parameters: {'alpha': 0.004262205983661091, 'binarize': 0.9540148644263694}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  33%|███▎       [ Time Left: 00:44 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 9 took 2.32 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:40,284] Trial 10 finished with value: -0.30822797027228716 and parameters: {'alpha': 0.011154693987725001, 'binarize': 0.09614367420726681}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  37%|███▋       [ Time Left: 00:42 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 10 took 2.28 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:42,576] Trial 11 finished with value: -0.30833706428073476 and parameters: {'alpha': 0.008659927465988128, 'binarize': 0.09157348063291981}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  40%|████       [ Time Left: 00:40 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 11 took 2.27 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:44,712] Trial 12 finished with value: -0.3080097580812888 and parameters: {'alpha': 0.015200410679362933, 'binarize': 0.161723571734966}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  43%|████▎      [ Time Left: 00:37 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 12 took 2.11 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:46,799] Trial 13 finished with value: -0.3143371408382599 and parameters: {'alpha': 0.018538510008256983, 'binarize': 0.23065690447472337}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  47%|████▋      [ Time Left: 00:34 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 13 took 2.07 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:48,907] Trial 14 finished with value: -0.3144735050946132 and parameters: {'alpha': 0.13786657563322008, 'binarize': 0.2968897886724144}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  50%|█████      [ Time Left: 00:32 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 14 took 2.09 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:51,005] Trial 15 finished with value: -0.3088143531245693 and parameters: {'alpha': 0.9709696940225162, 'binarize': 0.03484552846312901}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  53%|█████▎     [ Time Left: 00:29 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 15 took 2.08 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:53,112] Trial 16 finished with value: -0.3145689611897884 and parameters: {'alpha': 0.059583681899740164, 'binarize': 0.22455781760860616}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  57%|█████▋     [ Time Left: 00:27 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 16 took 2.09 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:55,381] Trial 17 finished with value: -0.3088279835996562 and parameters: {'alpha': 0.3119397808948479, 'binarize': 0.052096813916927984}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  60%|██████     [ Time Left: 00:26 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 17 took 2.25 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:57,486] Trial 18 finished with value: -0.30760066531222885 and parameters: {'alpha': 0.021594246871129645, 'binarize': 0.1463831361843546}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  63%|██████▎    [ Time Left: 00:23 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 18 took 2.09 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:29:59,581] Trial 19 finished with value: -0.3144325997227546 and parameters: {'alpha': 0.0806945396740655, 'binarize': 0.45197418154995794}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  67%|██████▋    [ Time Left: 00:21 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 19 took 2.08 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:30:01,700] Trial 20 finished with value: -0.30886889826924674 and parameters: {'alpha': 0.2282546014710788, 'binarize': 0.0302451081983644}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  70%|███████    [ Time Left: 00:19 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 20 took 2.10 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:30:03,819] Trial 21 finished with value: -0.3077506712009474 and parameters: {'alpha': 0.02215980703850556, 'binarize': 0.15020216868167424}. Best is trial 2 with value: -0.307477952915746.\n","Progress:  73%|███████▎   [ Time Left: 00:17 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 21 took 2.10 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:30:05,971] Trial 22 finished with value: -0.3072597602499848 and parameters: {'alpha': 0.02714655939236146, 'binarize': 0.1367598688221496}. Best is trial 22 with value: -0.3072597602499848.\n","Progress:  77%|███████▋   [ Time Left: 00:14 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 22 took 2.14 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:30:08,118] Trial 23 finished with value: -0.30800978876380436 and parameters: {'alpha': 0.007083778017561234, 'binarize': 0.10328520296498579}. Best is trial 22 with value: -0.3072597602499848.\n","Progress:  80%|████████   [ Time Left: 00:12 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 23 took 2.13 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:30:10,236] Trial 24 finished with value: -0.314528056747703 and parameters: {'alpha': 0.0338954850027353, 'binarize': 0.4607212479632054}. Best is trial 22 with value: -0.3072597602499848.\n","Progress:  83%|████████▎  [ Time Left: 00:10 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 24 took 2.10 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:30:12,343] Trial 25 finished with value: -0.3089098017815589 and parameters: {'alpha': 0.03107571814567645, 'binarize': 0.043683894691114486}. Best is trial 22 with value: -0.3072597602499848.\n","Progress:  87%|████████▋  [ Time Left: 00:08 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 25 took 2.09 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:30:14,455] Trial 26 finished with value: -0.30881435312456934 and parameters: {'alpha': 0.07551955824377467, 'binarize': 0.024428921256352407}. Best is trial 22 with value: -0.3072597602499848.\n","Progress:  90%|█████████  [ Time Left: 00:06 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 26 took 2.10 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:30:16,544] Trial 27 finished with value: -0.31465078123123746 and parameters: {'alpha': 0.005590202065198452, 'binarize': 0.3436849712560701}. Best is trial 22 with value: -0.3072597602499848.\n","Progress:  93%|█████████▎ [ Time Left: 00:04 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 27 took 2.07 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:30:18,684] Trial 28 finished with value: -0.3076143041552745 and parameters: {'alpha': 0.002306640546114429, 'binarize': 0.1458938947190707}. Best is trial 22 with value: -0.3072597602499848.\n","Progress:  97%|█████████▋ [ Time Left: 00:02 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 28 took 2.13 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-ef8939255931>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  alpha = trial.suggest_loguniform(\"alpha\", 1e-3, 1.0)\n","<ipython-input-13-ef8939255931>:24: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  binarize = trial.suggest_loguniform(\"binarize\", 1e-3, 1.0)\n","[I 2025-03-13 10:30:20,936] Trial 29 finished with value: -0.3081597890738837 and parameters: {'alpha': 0.14886595174707853, 'binarize': 0.092449678250822}. Best is trial 22 with value: -0.3072597602499848.\n","Progress: 100%|██████████ [ Time Left: 00:00 ]\n"]},{"output_type":"stream","name":"stdout","text":["Trial 29 took 2.24 seconds\n","Best Optuna Hyperparameters for Naive Bayes: {'alpha': 0.02714655939236146, 'binarize': 0.1367598688221496}\n"]},{"output_type":"stream","name":"stderr","text":["\rGridSearch Progress:   0%|           [ time left: ? ]"]},{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"]},{"output_type":"stream","name":"stderr","text":["GridSearch Progress: 100%|██████████ [ time left: 00:00 ]"]},{"output_type":"stream","name":"stdout","text":["Best parameters for Naive Bayes (Grid/Random Search): {'model__alpha': 1.0}\n","Model saved as Naive_Bayes_Optuna_Grid_V2.pkl\n","Model moved to: /content/drive/MyDrive/HotelNoShowPrediction/Naive_Bayes_Optuna_Grid_V2.pkl\n","Naive Bayes tuning completed in 1.331 min\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["#XGB"],"metadata":{"id":"cCTpIiebuEZa"},"id":"cCTpIiebuEZa","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"NehEh47jzfwV","metadata":{"id":"NehEh47jzfwV"},"outputs":[],"source":["# import time\n","# import joblib\n","# import optuna\n","# from tqdm import tqdm\n","# from sklearn.pipeline import Pipeline\n","# from xgboost import XGBClassifier\n","# from sklearn.model_selection import cross_val_score\n","\n","# # Train XGBoost using Optuna\n","# if \"XG Boost\" in model_param_dict:\n","#     model_start_time = time.time()\n","#     print(\"Processing XGBoost with Optuna Optimization...\")\n","\n","#     def objective(trial):\n","#         \"\"\"Objective function for Optuna Bayesian Optimization\"\"\"\n","#         param = {\n","#             \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n","#             \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15, step=2),\n","#             \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n","#             \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n","#             \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n","#             \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-3, 1),\n","#             \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-3, 1),\n","#             \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-3, 1),\n","#         }\n","\n","#         model = XGBClassifier(objective=\"reg:squarederror\", random_state=model_random_state, **param)\n","#         pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","#         score = cross_val_score(pipeline, X_train, Y_train, cv=model_cv_num, scoring=model_scoring).mean()\n","\n","#         return score  # Maximizing accuracy\n","\n","#     # Run Optuna optimization\n","#     study = optuna.create_study(direction=\"maximize\")\n","\n","#     with tqdm(total=30, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ Time Left: {remaining} ]\") as pbar:\n","#         def callback(study, trial):\n","#             pbar.update(1)  # Update progress bar per trial\n","\n","#         study.optimize(objective, n_trials=30, timeout=1800, callbacks=[callback])  # 30 trials, max 30 mins\n","\n","#     # Get best parameters\n","#     best_params = study.best_params\n","#     print(\"Best Hyperparameters for XGBoost:\", best_params)\n","\n","#     # Train final model with best parameters\n","#     best_model = XGBClassifier(objective=\"reg:squarederror\", random_state=model_random_state, **best_params)\n","#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n","#     pipeline.fit(X_train, Y_train)\n","\n","#     # Save best model\n","#     best_estimators_dict[\"XG Boost\"] = pipeline\n","#     model_filename = \"XGBoost_Optuna.pkl\"\n","#     joblib.dump(pipeline, model_filename)\n","#     print(f\"Optimized XGBoost model saved as {model_filename}\")\n","\n","#     # Log training duration\n","#     model_end_time = time.time()\n","#     model_total_time = model_end_time - model_start_time\n","#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","#     print(f\"XGBoost Optuna tuning completed in {model_duration:.3f} {model_tag}\")"]},{"cell_type":"code","execution_count":null,"id":"ZkdrejWIzfp8","metadata":{"id":"ZkdrejWIzfp8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741861919711,"user_tz":-480,"elapsed":90239,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"}},"outputId":"c0480b55-c27e-4f72-8907-21c98bfed442"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/optuna/trial/_fixed.py:148: UserWarning: The value 6 of the parameter 'max_depth' is out of the range of the distribution IntDistribution(high=15, log=False, low=3, step=2).\n","  warnings.warn(\n","<ipython-input-14-af63ec8d1e9a>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n","<ipython-input-14-af63ec8d1e9a>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:27: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-3, 1),\n"]},{"output_type":"stream","name":"stdout","text":["Processing XGBoost with Optuna Optimization...\n","Trial 0 took 8.51 seconds\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/optuna/trial/_fixed.py:148: UserWarning: The value 6 of the parameter 'max_depth' is out of the range of the distribution IntDistribution(high=15, log=False, low=3, step=2).\n","  warnings.warn(\n","<ipython-input-14-af63ec8d1e9a>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n","<ipython-input-14-af63ec8d1e9a>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:27: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-3, 1),\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 5.90 seconds\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/optuna/trial/_fixed.py:148: UserWarning: The value 6 of the parameter 'max_depth' is out of the range of the distribution IntDistribution(high=15, log=False, low=3, step=2).\n","  warnings.warn(\n","<ipython-input-14-af63ec8d1e9a>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n","<ipython-input-14-af63ec8d1e9a>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:27: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-3, 1),\n","[I 2025-03-13 10:30:51,763] A new study created in memory with name: no-name-f04e1794-426d-4820-844c-20f16c6354ba\n"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 7.90 seconds\n","Estimated optimal timeout: 55.77 seconds (~0.93 minutes)\n"]},{"output_type":"stream","name":"stderr","text":["\rProgress:   0%|           [ Time Left: ? ]<ipython-input-14-af63ec8d1e9a>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n","<ipython-input-14-af63ec8d1e9a>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:27: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-3, 1),\n","[I 2025-03-13 10:30:55,784] Trial 0 finished with value: -0.3037281292588552 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.013362389823278644, 'subsample': 0.8001167772602507, 'colsample_bytree': 0.7151698644262752, 'gamma': 0.4323996927751903, 'reg_alpha': 0.0013540154735356474, 'reg_lambda': 0.02386881652353374}. Best is trial 0 with value: -0.3037281292588552.\n","Progress:   3%|▎          [ Time Left: 01:56 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 0 took 4.02 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-14-af63ec8d1e9a>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n","<ipython-input-14-af63ec8d1e9a>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:27: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-3, 1),\n","[I 2025-03-13 10:31:06,082] Trial 1 finished with value: -0.27536343137484887 and parameters: {'n_estimators': 350, 'max_depth': 5, 'learning_rate': 0.02931878996661425, 'subsample': 0.784668536743579, 'colsample_bytree': 0.6780673025407161, 'gamma': 0.1320554551271896, 'reg_alpha': 0.0022739524625133927, 'reg_lambda': 0.0034430455132971006}. Best is trial 1 with value: -0.27536343137484887.\n","Progress:   7%|▋          [ Time Left: 03:35 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 1 took 10.29 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-14-af63ec8d1e9a>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n","<ipython-input-14-af63ec8d1e9a>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:27: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-3, 1),\n","[I 2025-03-13 10:31:10,910] Trial 2 finished with value: -0.23344400702644483 and parameters: {'n_estimators': 50, 'max_depth': 11, 'learning_rate': 0.10924079067381579, 'subsample': 0.7317488779261725, 'colsample_bytree': 0.5425644256127131, 'gamma': 0.012598926369536795, 'reg_alpha': 0.04769482474814699, 'reg_lambda': 0.005788237356959753}. Best is trial 2 with value: -0.23344400702644483.\n","Progress:  10%|█          [ Time Left: 02:52 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 2 took 4.82 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-14-af63ec8d1e9a>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n","<ipython-input-14-af63ec8d1e9a>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:27: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-3, 1),\n","[I 2025-03-13 10:31:17,349] Trial 3 finished with value: -0.2362526231342578 and parameters: {'n_estimators': 150, 'max_depth': 5, 'learning_rate': 0.18848775242191448, 'subsample': 0.651174528052977, 'colsample_bytree': 0.6202552608190788, 'gamma': 0.001544000369562429, 'reg_alpha': 0.35269522253088254, 'reg_lambda': 0.5061529906271197}. Best is trial 2 with value: -0.23344400702644483.\n","Progress:  13%|█▎         [ Time Left: 02:46 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 3 took 6.43 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-14-af63ec8d1e9a>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n","<ipython-input-14-af63ec8d1e9a>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:27: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-3, 1),\n","[I 2025-03-13 10:31:46,700] Trial 4 finished with value: -0.1999519548997518 and parameters: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.052390828902286544, 'subsample': 0.8659558209301788, 'colsample_bytree': 0.9483499698102509, 'gamma': 0.0011383586828569042, 'reg_alpha': 0.005153751548230152, 'reg_lambda': 0.013619768905152133}. Best is trial 4 with value: -0.1999519548997518.\n","Progress:  17%|█▋         [ Time Left: 06:07 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 4 took 29.35 seconds\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-14-af63ec8d1e9a>:25: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n","<ipython-input-14-af63ec8d1e9a>:26: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:27: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n","  \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n","<ipython-input-14-af63ec8d1e9a>:28: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-3, 1),\n","<ipython-input-14-af63ec8d1e9a>:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-3, 1),\n","[I 2025-03-13 10:31:51,996] Trial 5 finished with value: -0.22187956701689454 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.18558689598551326, 'subsample': 0.8028611442269051, 'colsample_bytree': 0.6422465991857828, 'gamma': 0.0020731519647866044, 'reg_alpha': 0.06523531023283133, 'reg_lambda': 0.048239052283832566}. Best is trial 4 with value: -0.1999519548997518.\n","Progress:  20%|██         [ Time Left: 04:00 ]"]},{"output_type":"stream","name":"stdout","text":["Trial 5 took 5.29 seconds\n","Best Hyperparameters for XGBoost: {'n_estimators': 450, 'max_depth': 11, 'learning_rate': 0.052390828902286544, 'subsample': 0.8659558209301788, 'colsample_bytree': 0.9483499698102509, 'gamma': 0.0011383586828569042, 'reg_alpha': 0.005153751548230152, 'reg_lambda': 0.013619768905152133}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Optimized XGBoost model saved as XGBoost_Optuna_V2.pkl\n","Model moved to: /content/drive/MyDrive/HotelNoShowPrediction/XGBoost_Optuna_V2.pkl\n","XGBoost Optuna tuning completed in 1.503 min\n"]}],"source":["import time\n","import joblib\n","import optuna\n","import shutil\n","import os\n","from tqdm import tqdm\n","from sklearn.pipeline import Pipeline\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import cross_val_score\n","\n","# Directory to save the model\n","destination_dir = \"/content/drive/MyDrive/HotelNoShowPrediction\"\n","os.makedirs(destination_dir, exist_ok=True)  # Ensure the directory exists\n","\n","# Train XGBoost using Optuna\n","if \"XG Boost\" in model_param_dict:\n","    model_start_time = time.time()\n","    print(\"Processing XGBoost with Optuna Optimization...\")\n","\n","    def objective(trial):\n","        \"\"\"Objective function for Optuna Bayesian Optimization\"\"\"\n","        param = {\n","            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, step=50),\n","            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15, step=2),\n","            \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n","            \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n","            \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n","            \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-3, 1),\n","            \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-3, 1),\n","            \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-3, 1),\n","        }\n","\n","        model = XGBClassifier(objective=\"reg:squarederror\", random_state=model_random_state, **param)\n","        pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","        # Measure trial time\n","        start_time = time.time()\n","        score = cross_val_score(pipeline, X_train, Y_train, cv=model_cv_num, scoring=model_scoring).mean()\n","        trial_time = time.time() - start_time\n","\n","        print(f\"Trial {trial.number} took {trial_time:.2f} seconds\")\n","        return score  # Maximizing accuracy\n","\n","    # Step 1: Estimate time per trial using a few test runs\n","    def estimate_trial_time(objective, n_test_trials=3):\n","        \"\"\"Runs a few dummy trials to estimate average trial time.\"\"\"\n","        start_time = time.time()\n","        for _ in range(n_test_trials):\n","            objective(optuna.trial.FixedTrial({\n","                \"n_estimators\": 200,\n","                \"max_depth\": 6,\n","                \"learning_rate\": 0.1,\n","                \"subsample\": 0.8,\n","                \"colsample_bytree\": 0.8,\n","                \"gamma\": 0.01,\n","                \"reg_alpha\": 0.01,\n","                \"reg_lambda\": 0.01\n","            }))  # Dummy params\n","        return (time.time() - start_time) / n_test_trials\n","\n","    avg_trial_time = estimate_trial_time(objective)\n","    target_trials = 30\n","    n_jobs = 4  # Adjust based on available CPU cores\n","\n","    # Step 2: Compute optimal timeout\n","    optimal_timeout = (avg_trial_time * target_trials) / n_jobs\n","    print(f\"Estimated optimal timeout: {optimal_timeout:.2f} seconds (~{optimal_timeout/60:.2f} minutes)\")\n","\n","    # Run Optuna optimization with dynamic timeout\n","    study = optuna.create_study(direction=\"maximize\")\n","\n","    with tqdm(total=target_trials, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ Time Left: {remaining} ]\") as pbar:\n","        def callback(study, trial):\n","            pbar.update(1)  # Update progress bar per trial\n","\n","        study.optimize(objective, n_trials=target_trials, timeout=optimal_timeout, callbacks=[callback])\n","\n","    # Get best parameters\n","    best_params = study.best_params\n","    print(\"Best Hyperparameters for XGBoost:\", best_params)\n","\n","    # Train final model with best parameters\n","    best_model = XGBClassifier(objective=\"reg:squarederror\", random_state=model_random_state, **best_params)\n","    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", best_model)])\n","    pipeline.fit(X_train, Y_train)\n","\n","    # Save best model\n","    best_estimators_dict[\"XG Boost\"] = pipeline\n","    model_filename = \"XGBoost_Optuna_V2.pkl\"\n","    joblib.dump(pipeline, model_filename)\n","    print(f\"Optimized XGBoost model saved as {model_filename}\")\n","\n","    # Move the model to the specified directory\n","    destination_file = os.path.join(destination_dir, model_filename)\n","    shutil.move(model_filename, destination_file)\n","    print(f\"Model moved to: {destination_file}\")\n","\n","    # Log training duration\n","    model_end_time = time.time()\n","    model_total_time = model_end_time - model_start_time\n","    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","    print(f\"XGBoost Optuna tuning completed in {model_duration:.3f} {model_tag}\")"]},{"cell_type":"code","source":["##################################################################################################################################################################"],"metadata":{"id":"EUigUJbEuGqs"},"id":"EUigUJbEuGqs","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"907ba669","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":814671,"status":"ok","timestamp":1741646989891,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"},"user_tz":-480},"id":"907ba669","outputId":"6d2abd20-dc91-4653-d49c-843c066c1652"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing Random Forest now...\n","Fitting 5 folds for each of 416 candidates, totalling 2080 fits\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n","/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n","/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n","/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Best parameters for Random Forest: {'model__class_weight': 'balanced', 'model__max_depth': 40, 'model__n_estimators': 325}\n","Model saved as Random_Forest.pkl\n","Random Forest has run tuning for 1.635 hr\n"]}],"source":["# Problematic cell\n","import joblib\n","\n","# Train Random Forest\n","if \"Random Forest\" in model_param_dict:\n","    model_start_time = time.time()\n","    print(\"Processing Random Forest now...\")\n","\n","    model = RandomForestClassifier(random_state=model_random_state)\n","    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","    if model_search_method == \"grid\":\n","        search = GridSearchCV(\n","            pipeline,\n","            param_grid=model_param_dict[\"Random Forest\"],\n","            cv=model_cv_num,\n","            scoring=model_scoring,\n","            n_jobs=model_num_jobs,\n","            verbose=3\n","        )\n","    elif model_search_method == \"random\":\n","        search = RandomizedSearchCV(\n","            pipeline,\n","            param_distributions=model_param_dict[\"Random Forest\"],\n","            n_iter=model_num_iter,\n","            cv=model_cv_num,\n","            scoring=model_scoring,\n","            random_state=model_random_state,\n","            n_jobs=model_num_jobs,\n","        )\n","\n","    search.fit(X_train, Y_train)\n","\n","    # Save best model\n","    best_estimators_dict[\"Random Forest\"] = search.best_estimator_\n","    print(\"Best parameters for Random Forest:\", search.best_params_)\n","\n","\t# Save the trained model\n","    model_filename = \"Random_Forest.pkl\"\n","    joblib.dump(search.best_estimator_, model_filename)\n","    print(f\"Model saved as {model_filename}\")\n","\n","    model_end_time = time.time()\n","    model_total_time = model_end_time - model_start_time\n","    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","    print(f\"Random Forest has run tuning for {model_duration:.3f} {model_tag}\")\n"]},{"cell_type":"code","execution_count":null,"id":"St8YlihNkexI","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"elapsed":2019560,"status":"error","timestamp":1741639286020,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"},"user_tz":-480},"id":"St8YlihNkexI","outputId":"2ff6c0cd-101c-456e-e2ba-4b5da3578254"},"outputs":[{"name":"stdout","output_type":"stream","text":["cudf is already installed!\n","Processing GPU Random Forest with RandomizedSearchCV (scikit-learn)\n","Fitting 2 folds for each of 416 candidates, totalling 832 fits\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n"]},{"ename":"TypeError","evalue":"'GridSearchCV' object is not iterable","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-bba6062dc908>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# ------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loky'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mcurrent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlast_log_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'GridSearchCV' object is not iterable"]}],"source":["import joblib\n","from joblib import parallel_backend\n","from joblib import Parallel, parallel_backend\n","\n","# import cudf\n","# from cuml.ensemble import RandomForestClassifier as cuRF\n","\n","# import cudf\n","# import cuml\n","# print(\"cuDF version:\", cudf.__version__)\n","# print(\"cuML version:\", cuml.__version__)\n","\n","# from cudf.utils import dtypes\n","\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from sklearn.pipeline import Pipeline\n","\n","try:\n","    import cudf\n","    print(\"cudf is already installed!\")\n","except ImportError:\n","    print(\"cudf is not installed. Installing now...\")\n","    # You may need to adjust the channel versions depending on your CUDA / rapids version\n","    !conda install -y -c rapidsai -c nvidia -c conda-forge cudf\n","\n","    # Try to import again after installation\n","    try:\n","        import cudf\n","        print(\"Successfully installed cudf!\")\n","    except ImportError:\n","        print(\"Installation attempted, but cudf is still not importable.\")\n","\n","from cuml.ensemble import RandomForestClassifier\n","\n","if \"Random Forest\" in model_param_dict:\n","    model_start_time = time.time()\n","    print(\"Processing GPU Random Forest with RandomizedSearchCV (scikit-learn)\")\n","\n","    # Initialize cuML Random Forest\n","    # gpu_model = cuRF(random_state=model_random_state)\n","    gpu_model = RandomForestClassifier(random_state=model_random_state, n_streams=1)\n","    # ------------------------------------------------\n","    # Instead of converting to NumPy, keep it as a DataFrame:\n","    # ------------------------------------------------\n","    X_train_df = X_train  # Ensure this is already a pandas DataFrame\n","    Y_train_df = Y_train  # pandas Series\n","\n","    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", gpu_model)])\n","\n","    # if model_search_method == \"grid\":\n","    #     search = GridSearchCV(\n","    #         pipeline,\n","    #         param_grid=model_param_dict[\"Random Forest\"],\n","    #         # cv=model_cv_num,\n","    #         cv=2,\n","    #         scoring=model_scoring,\n","    #         # n_jobs=model_num_jobs,\n","    #         n_jobs=4,\n","    #         verbose=3\n","    #     )\n","    # elif model_search_method == \"random\":\n","    #     search = RandomizedSearchCV(\n","    #         pipeline,\n","    #         param_distributions=model_param_dict[\"Random Forest\"],\n","    #         # n_iter=model_num_iter,\n","    #         # cv=model_cv_num,\n","    #         n_iter=10,\n","    #         cv=2,\n","    #         scoring=model_scoring,\n","    #         random_state=model_random_state,\n","    #         # n_jobs=model_num_jobs,\n","    #         n_jobs=4,\n","    #         verbose=3\n","    #     )\n","\n","    if model_search_method == \"grid\":\n","        search = GridSearchCV(\n","            pipeline,\n","            param_grid=model_param_dict[\"Random Forest\"],\n","            cv=2,  # Reduce cross-validation\n","            scoring=model_scoring,\n","            n_jobs=4,  # Limit parallel execution\n","            verbose=3\n","        )\n","    elif model_search_method == \"random\":\n","        search = RandomizedSearchCV(\n","            pipeline,\n","            param_distributions=model_param_dict[\"Random Forest\"],\n","            n_iter=10,  # Reduce number of candidates\n","            cv=2,  # Reduce cross-validation\n","            scoring=model_scoring,\n","            random_state=model_random_state,\n","            n_jobs=4,  # Limit parallel execution\n","            verbose=3\n","        )\n","\n","    # ------------------------------------------------\n","    # Pass the DataFrame/Series to fit, not NumPy arrays\n","    # ------------------------------------------------\n","    with parallel_backend('loky'):\n","        for i, _ in enumerate(search.fit(X_train_df, Y_train_df), start=1):\n","            current_time = time.time()\n","            elapsed_time = current_time - last_log_time\n","\n","            if elapsed_time >= 60:  # Log every 60 seconds\n","                total_elapsed = current_time - start_time\n","                print(f\"[INFO] Model tuning is still running... {total_elapsed:.1f} seconds elapsed.\")\n","                last_log_time = current_time\n","\n","    best_estimators_dict[\"Random Forest\"] = search.best_estimator_\n","    print(\"Best parameters for GPU Random Forest:\", search.best_params_)\n","\n","    model_filename = \"GPU_Random_Forest.pkl\"\n","    joblib.dump(search.best_estimator_, model_filename)\n","    print(f\"Model saved as {model_filename}\")\n","\n","    model_end_time = time.time()\n","    model_total_time = model_end_time - model_start_time\n","    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","    print(f\"GPU Random Forest tuning ran for {model_duration:.3f} {model_tag}\")"]},{"cell_type":"code","execution_count":null,"id":"TS4r8YpWIfsw","metadata":{"id":"TS4r8YpWIfsw"},"outputs":[],"source":["# new version of above\n","import time\n","import threading\n","import joblib\n","from joblib import parallel_backend\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","from sklearn.pipeline import Pipeline\n","from cuml.ensemble import RandomForestClassifier\n","\n","def log_progress():\n","    \"\"\"Logs progress every 60 seconds while GridSearchCV is running.\"\"\"\n","    start_time = time.time()\n","    while not fit_complete:\n","        elapsed_time = time.time() - start_time\n","        print(f\"[INFO] Model tuning is still running... {elapsed_time:.1f} seconds elapsed.\")\n","        time.sleep(60)  # Log every 60 seconds\n","\n","# Train Random Forest\n","if \"Random Forest\" in model_param_dict:\n","    model_start_time = time.time()\n","    print(\"Processing GPU Random Forest with RandomizedSearchCV (scikit-learn)\")\n","\n","    # Initialize cuML Random Forest\n","    gpu_model = RandomForestClassifier(random_state=model_random_state, n_streams=1)\n","\n","    X_train_df = X_train  # Ensure this is already a pandas DataFrame\n","    Y_train_df = Y_train  # pandas Series\n","\n","    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", gpu_model)])\n","\n","    if model_search_method == \"grid\":\n","        search = GridSearchCV(\n","            pipeline,\n","            param_grid=model_param_dict[\"Random Forest\"],\n","            cv=model_cv_num,\n","            scoring=model_scoring,\n","            n_jobs=model_num_jobs,\n","            verbose=3\n","        )\n","    elif model_search_method == \"random\":\n","        search = RandomizedSearchCV(\n","            pipeline,\n","            param_distributions=model_param_dict[\"Random Forest\"],\n","            n_iter=model_num_iter,\n","            cv=model_cv_num,\n","            scoring=model_scoring,\n","            random_state=model_random_state,\n","            n_jobs=model_num_jobs,\n","            verbose=3\n","        )\n","\n","    # Start logging thread\n","    fit_complete = False\n","    progress_thread = threading.Thread(target=log_progress, daemon=True)\n","    progress_thread.start()\n","\n","    # Run the model tuning\n","    with parallel_backend('loky'):\n","        search.fit(X_train_df, Y_train_df)\n","\n","    # Mark training as complete\n","    fit_complete = True\n","    progress_thread.join()\n","\n","    # Save best model\n","    best_estimators_dict[\"Random Forest\"] = search.best_estimator_\n","    print(\"Best parameters for GPU Random Forest:\", search.best_params_)\n","\n","    model_filename = \"GPU_Random_Forest.pkl\"\n","    joblib.dump(search.best_estimator_, model_filename)\n","    print(f\"Model saved as {model_filename}\")\n","\n","    # Log training duration\n","    model_end_time = time.time()\n","    model_total_time = model_end_time - model_start_time\n","    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","    print(f\"GPU Random Forest tuning ran for {model_duration:.3f} {model_tag}\")"]},{"cell_type":"markdown","id":"b1lzX2GnoT-i","metadata":{"id":"b1lzX2GnoT-i"},"source":[]},{"cell_type":"markdown","id":"UH_RkR_-oTz4","metadata":{"id":"UH_RkR_-oTz4"},"source":[]},{"cell_type":"code","execution_count":null,"id":"cjDvCEvfjqG8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30001,"status":"ok","timestamp":1741368573040,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"},"user_tz":-480},"id":"cjDvCEvfjqG8","outputId":"9021cea5-e0d9-4abb-d5b0-2e7705ad68de"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3] END gpu_model__max_depth=8, gpu_model__max_features=0.5, gpu_model__n_estimators=50;, score=0.682 total time=   0.7s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3] END gpu_model__max_depth=8, gpu_model__max_features=0.5, gpu_model__n_estimators=50;, score=0.678 total time=   0.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3] END gpu_model__max_depth=8, gpu_model__max_features=0.5, gpu_model__n_estimators=50;, score=0.573 total time=   0.6s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3] END gpu_model__max_depth=8, gpu_model__max_features=0.5, gpu_model__n_estimators=100;, score=0.684 total time=   0.9s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3] END gpu_model__max_depth=8, gpu_model__max_features=0.5, gpu_model__n_estimators=100;, score=0.683 total time=   0.9s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3] END gpu_model__max_depth=8, gpu_model__max_features=0.5, gpu_model__n_estimators=100;, score=0.579 total time=   0.9s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3] END gpu_model__max_depth=8, gpu_model__max_features=1.0, gpu_model__n_estimators=50;, score=0.688 total time=   0.7s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3] END gpu_model__max_depth=8, gpu_model__max_features=1.0, gpu_model__n_estimators=50;, score=0.686 total time=   0.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3] END gpu_model__max_depth=8, gpu_model__max_features=1.0, gpu_model__n_estimators=50;, score=0.584 total time=   0.9s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3] END gpu_model__max_depth=8, gpu_model__max_features=1.0, gpu_model__n_estimators=100;, score=0.689 total time=   1.3s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3] END gpu_model__max_depth=8, gpu_model__max_features=1.0, gpu_model__n_estimators=100;, score=0.686 total time=   1.3s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3] END gpu_model__max_depth=8, gpu_model__max_features=1.0, gpu_model__n_estimators=100;, score=0.584 total time=   1.2s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3] END gpu_model__max_depth=12, gpu_model__max_features=0.5, gpu_model__n_estimators=50;, score=0.693 total time=   0.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3] END gpu_model__max_depth=12, gpu_model__max_features=0.5, gpu_model__n_estimators=50;, score=0.693 total time=   0.9s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3] END gpu_model__max_depth=12, gpu_model__max_features=0.5, gpu_model__n_estimators=50;, score=0.599 total time=   0.8s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3] END gpu_model__max_depth=12, gpu_model__max_features=0.5, gpu_model__n_estimators=100;, score=0.695 total time=   1.4s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3] END gpu_model__max_depth=12, gpu_model__max_features=0.5, gpu_model__n_estimators=100;, score=0.695 total time=   1.4s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3] END gpu_model__max_depth=12, gpu_model__max_features=0.5, gpu_model__n_estimators=100;, score=0.600 total time=   1.4s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3] END gpu_model__max_depth=12, gpu_model__max_features=1.0, gpu_model__n_estimators=50;, score=0.697 total time=   1.1s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3] END gpu_model__max_depth=12, gpu_model__max_features=1.0, gpu_model__n_estimators=50;, score=0.704 total time=   1.2s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3] END gpu_model__max_depth=12, gpu_model__max_features=1.0, gpu_model__n_estimators=50;, score=0.611 total time=   1.4s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/3] END gpu_model__max_depth=12, gpu_model__max_features=1.0, gpu_model__n_estimators=100;, score=0.698 total time=   2.0s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/3] END gpu_model__max_depth=12, gpu_model__max_features=1.0, gpu_model__n_estimators=100;, score=0.704 total time=   2.0s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["[CV 3/3] END gpu_model__max_depth=12, gpu_model__max_features=1.0, gpu_model__n_estimators=100;, score=0.612 total time=   2.0s\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/cuml/internals/api_decorators.py:368: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n","  return init_func(self, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Best parameters: {'gpu_model__max_depth': 12, 'gpu_model__max_features': 1.0, 'gpu_model__n_estimators': 100}\n","Best CV score: 0.6710\n","Total tuning time: 29.69 seconds\n","Model saved as GPU_RandomForestWrapper.pkl\n","Test Accuracy on X_test: 0.7074\n"]}],"source":["import time\n","import joblib\n","\n","# -----------------------------\n","# 1) Necessary Imports\n","# -----------------------------\n","import cudf\n","from cuml.ensemble import RandomForestClassifier as cuRF\n","\n","# scikit-learn imports\n","from sklearn.base import BaseEstimator, ClassifierMixin\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","# -----------------------------\n","# 2) Custom Wrapper Class\n","# -----------------------------\n","class CuMLRandomForestWrapper(BaseEstimator, ClassifierMixin):\n","    \"\"\"\n","    A scikit-learn-compatible wrapper for cuML's RandomForestClassifier.\n","    This wrapper:\n","      - Accepts CPU-based data (NumPy/pandas) in fit/predict\n","      - Converts data to cuDF\n","      - Trains/predicts using cuML's RandomForestClassifier on GPU\n","      - Optionally converts predictions back to CPU-based NumPy\n","    \"\"\"\n","    def __init__(self,\n","                 random_state=42,\n","                 n_estimators=100,\n","                 max_depth=None,\n","                 max_features=1.0):\n","        self.random_state = random_state\n","        self.n_estimators = n_estimators\n","        self.max_depth = max_depth\n","        self.max_features = max_features\n","        self.model_ = None\n","\n","    def fit(self, X, y):\n","        # Convert to cuDF\n","        X_cudf = cudf.DataFrame(X)\n","        y_cudf = cudf.Series(y)\n","\n","        # Instantiate and fit the GPU model\n","        self.model_ = cuRF(\n","            random_state=self.random_state,\n","            n_estimators=self.n_estimators,\n","            max_depth=self.max_depth,\n","            max_features=self.max_features\n","        )\n","        self.model_.fit(X_cudf, y_cudf)\n","        return self\n","\n","    def predict(self, X):\n","        X_cudf = cudf.DataFrame(X)\n","        y_pred_cudf = self.model_.predict(X_cudf)\n","        # Convert predictions back to CPU numpy\n","        return y_pred_cudf.to_numpy()\n","\n","    def predict_proba(self, X):\n","        X_cudf = cudf.DataFrame(X)\n","        y_proba_cudf = self.model_.predict_proba(X_cudf)\n","        return y_proba_cudf.to_numpy()\n","\n","    # Let GridSearchCV set/get hyperparameters\n","    def set_params(self, **params):\n","        for key, value in params.items():\n","            setattr(self, key, value)\n","        return self\n","\n","    def get_params(self, deep=True):\n","        return {\n","            \"random_state\": self.random_state,\n","            \"n_estimators\": self.n_estimators,\n","            \"max_depth\": self.max_depth,\n","            \"max_features\": self.max_features,\n","        }\n","\n","\n","# -----------------------------\n","# 3) Your Dataset\n","# -----------------------------\n","# We assume you already have:\n","#   X_train, X_test, y_train, y_test\n","# as pandas DataFrames/Series (or NumPy arrays).\n","#\n","# Example:\n","# X_train, y_train = ...\n","# X_test, y_test   = ...\n","\n","# -----------------------------\n","# 4) Define a CPU Preprocessor & Pipeline\n","# -----------------------------\n","preprocessor = StandardScaler()  # Example CPU-based scaler\n","\n","gpu_rf_estimator = CuMLRandomForestWrapper(random_state=42)\n","\n","pipeline = Pipeline(steps=[\n","    (\"preprocessor\", preprocessor),\n","    (\"gpu_model\", gpu_rf_estimator)\n","])\n","\n","\n","# -----------------------------\n","# 5) Hyperparameter Tuning Setup\n","# -----------------------------\n","param_grid = {\n","    \"gpu_model__n_estimators\": [50, 100],\n","    \"gpu_model__max_depth\": [8, 12],\n","    \"gpu_model__max_features\": [0.5, 1.0],\n","}\n","\n","search = GridSearchCV(\n","    estimator=pipeline,\n","    param_grid=param_grid,\n","    cv=3,               # number of CV folds\n","    scoring=\"accuracy\", # or another metric\n","    verbose=3\n",")\n","\n","\n","# -----------------------------\n","# 6) Run Training & Tuning\n","# -----------------------------\n","model_start_time = time.time()\n","\n","search.fit(X_train, Y_train)  # <= CPU data goes in, wrapper handles GPU conversion\n","\n","model_end_time = time.time()\n","model_total_time = model_end_time - model_start_time\n","\n","# Print results\n","print(\"Best parameters:\", search.best_params_)\n","print(f\"Best CV score: {search.best_score_:.4f}\")\n","print(f\"Total tuning time: {model_total_time:.2f} seconds\")\n","\n","\n","# -----------------------------\n","# 7) Save the Best Model\n","# -----------------------------\n","best_pipeline = search.best_estimator_\n","model_filename = \"GPU_RandomForestWrapper.pkl\"\n","joblib.dump(best_pipeline, model_filename)\n","print(f\"Model saved as {model_filename}\")\n","\n","\n","# -----------------------------\n","# 8) Evaluate on Test Data\n","# -----------------------------\n","test_acc = best_pipeline.score(X_test, Y_test)\n","print(f\"Test Accuracy on X_test: {test_acc:.4f}\")"]},{"cell_type":"markdown","id":"8O527z0UklOg","metadata":{"id":"8O527z0UklOg"},"source":[]},{"cell_type":"markdown","id":"311L0LOVkk8g","metadata":{"id":"311L0LOVkk8g"},"source":[]},{"cell_type":"markdown","id":"1_5wIXbTjqa_","metadata":{"id":"1_5wIXbTjqa_"},"source":["TO DO SVC\n"]},{"cell_type":"code","execution_count":null,"id":"8f6db110","metadata":{"id":"8f6db110"},"outputs":[],"source":["# # Prob need to fix this\n","# import joblib\n","\n","# # Train SVC\n","# if \"SVC\" in model_param_dict:\n","#     model_start_time = time.time()\n","#     print(\"Processing SVC now...\")\n","\n","#     model = SVC()\n","#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","#     if model_search_method == \"grid\":\n","#         search = GridSearchCV(\n","#             pipeline,\n","#             param_grid=model_param_dict[\"SVC\"],\n","#             cv=model_cv_num,\n","#             scoring=model_scoring,\n","#             n_jobs=model_num_jobs,\n","#             verbose=10\n","#         )\n","#     elif model_search_method == \"random\":\n","#         search = RandomizedSearchCV(\n","#             pipeline,\n","#             param_distributions=model_param_dict[\"SVC\"],\n","#             n_iter=model_num_iter,\n","#             cv=model_cv_num,\n","#             scoring=model_scoring,\n","#             random_state=model_random_state,\n","#             n_jobs=model_num_jobs,\n","#         )\n","\n","#     search.fit(X_train, Y_train)\n","\n","#     # Save best model\n","#     best_estimators_dict[\"SVC\"] = search.best_estimator_\n","#     print(\"Best parameters for SVC:\", search.best_params_)\n","\n","#     model_filename = \"SVC.pkl\"\n","#     joblib.dump(search.best_estimator_, model_filename)\n","#     print(f\"Model saved as {model_filename}\")\n","\n","#     model_end_time = time.time()\n","#     model_total_time = model_end_time - model_start_time\n","#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","#     print(f\"SVC has run tuning for {model_duration:.3f} {model_tag}\")"]},{"cell_type":"code","execution_count":null,"id":"8035bec9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8035bec9","outputId":"a2500b86-3c2b-4159-fa9d-c9b26547c75a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing MLP now...\n","Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"]}],"source":["# # use the one below this cell\n","# import joblib\n","\n","# # Train MLP\n","# if \"MLP\" in model_param_dict:\n","#     model_start_time = time.time()\n","#     print(\"Processing MLP now...\")\n","\n","#     model = MLPClassifier(random_state=model_random_state)\n","#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","#     if model_search_method == \"grid\":\n","#         search = GridSearchCV(\n","#             pipeline,\n","#             param_grid=model_param_dict[\"MLP\"],\n","#             cv=model_cv_num,\n","#             scoring=model_scoring,\n","#             n_jobs=model_num_jobs,\n","#             verbose=3\n","#         )\n","#     elif model_search_method == \"random\":\n","#         search = RandomizedSearchCV(\n","#             pipeline,\n","#             param_distributions=model_param_dict[\"MLP\"],\n","#             n_iter=model_num_iter,\n","#             cv=model_cv_num,\n","#             scoring=model_scoring,\n","#             random_state=model_random_state,\n","#             n_jobs=model_num_jobs,\n","#         )\n","\n","#     search.fit(X_train, Y_train)\n","\n","#     # Save best model\n","#     best_estimators_dict[\"MLP\"] = search.best_estimator_\n","#     print(\"Best parameters for MLP:\", search.best_params_)\n","\n","# \t# Save the trained model\n","#     model_filename = \"MLP.pkl\"\n","#     joblib.dump(search.best_estimator_, model_filename)\n","#     print(f\"Model saved as {model_filename}\")\n","\n","#     model_end_time = time.time()\n","#     model_total_time = model_end_time - model_start_time\n","#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","#     print(f\"MLP has run tuning for {model_duration:.3f} {model_tag}\")\n","#     print()\n"]},{"cell_type":"code","execution_count":null,"id":"oeLgzuEvGMUm","metadata":{"id":"oeLgzuEvGMUm"},"outputs":[],"source":["#     # this is done# import time\n","# import joblib\n","\n","# # ---------------------------\n","# # NEW IMPORTS FOR GPU MLP\n","# # ---------------------------\n","# import torch\n","# import torch.nn as nn\n","# import torch.nn.functional as F\n","# from torch import optim\n","# from skorch import NeuralNetClassifier\n","# from sklearn.pipeline import Pipeline\n","# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","\n","# # Example param grid (skorch-compatible parameters)\n","# model_param_dict[\"MLP\"] = {\n","#     \"model__module__hidden_units\": [32, 64],\n","#     \"model__lr\": [0.01, 0.001],\n","#     \"model__max_epochs\": [10, 20]\n","# }\n","\n","# # Define a minimal PyTorch MLP module using float32 by default\n","# class MyMLPModule(nn.Module):\n","#     def __init__(self, num_features=10, hidden_units=100, dtype=torch.float32):\n","#         super(MyMLPModule, self).__init__()\n","#         self.dtype = dtype\n","#         self.fc1 = nn.Linear(num_features, hidden_units)\n","#         self.fc2 = nn.Linear(hidden_units, 2)  # e.g. 2 output classes (binary)\n","\n","#     def forward(self, X):\n","#         # Convert input to float32\n","#         X = X.to(self.dtype)\n","#         X = F.relu(self.fc1(X))\n","#         X = self.fc2(X)\n","#         return X\n","\n","# # Train MLP (GPU-based via skorch)\n","# if \"MLP\" in model_param_dict:\n","#     model_start_time = time.time()\n","#     print(\"Processing MLP on GPU...\")\n","\n","#     # Use skorch's NeuralNetClassifier with float32\n","#     model = NeuralNetClassifier(\n","#         module=MyMLPModule,\n","#         module__num_features=X_train.shape[1],  # match your data's feature count\n","#         # No more module__dtype=torch.float64\n","#         device=\"cuda\",               # GPU usage\n","#         optimizer=optim.Adam,\n","#         lr=0.001,                    # can be overridden by param grid\n","#         max_epochs=10,               # can be overridden by param grid\n","#         verbose=0\n","#     )\n","\n","#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor),\n","#                                (\"model\", model)])\n","\n","#     if model_search_method == \"grid\":\n","#         search = GridSearchCV(\n","#             pipeline,\n","#             param_grid=model_param_dict[\"MLP\"],\n","#             cv=model_cv_num,\n","#             scoring=model_scoring,\n","#             n_jobs=model_num_jobs,\n","#             verbose=3,\n","#             error_score=\"raise\"  # so we see real errors if folds fail\n","#         )\n","#     else:  # \"random\"\n","#         search = RandomizedSearchCV(\n","#             pipeline,\n","#             param_distributions=model_param_dict[\"MLP\"],\n","#             n_iter=model_num_iter,\n","#             cv=model_cv_num,\n","#             scoring=model_scoring,\n","#             random_state=model_random_state,\n","#             n_jobs=model_num_jobs,\n","#             verbose=3\n","#         )\n","\n","#     # Convert X_train to float32, Y_train to int64 if needed\n","#     # (only if not already done; ensures consistent dtypes)\n","#     X_train = X_train.astype(\"float32\")\n","#     Y_train = Y_train.astype(\"int64\")  # for classification\n","\n","#     # Fit the pipeline (GPU-based MLP)\n","#     search.fit(X_train, Y_train)\n","\n","#     # Save best model\n","#     best_estimators_dict[\"MLP\"] = search.best_estimator_\n","#     print(\"Best parameters for MLP:\", search.best_params_)\n","\n","#     # Save the trained model\n","#     model_filename = \"MLP_GPU.pkl\"\n","#     joblib.dump(search.best_estimator_, model_filename)\n","#     print(f\"Model saved as {model_filename}\")\n","\n","#     model_end_time = time.time()\n","#     model_total_time = model_end_time - model_start_time\n","#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","#     print(f\"MLP has run tuning for {model_duration:.3f} {model_tag}\")\n","#     print()\n","\n"]},{"cell_type":"markdown","id":"fteXaZYUjN3m","metadata":{"id":"fteXaZYUjN3m"},"source":["Naive Bayes below"]},{"cell_type":"code","execution_count":null,"id":"d71bd351","metadata":{"id":"d71bd351"},"outputs":[],"source":["# # Train Naive Bayes\n","# if \"Naive Bayes\" in model_param_dict:\n","#     model_start_time = time.time()\n","#     print(\"Processing Naive Bayes now...\")\n","\n","#     model = BernoulliNB()\n","#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","#     if model_search_method == \"grid\":\n","#         search = GridSearchCV(\n","#             pipeline,\n","#             param_grid=model_param_dict[\"Naive Bayes\"],\n","#             cv=model_cv_num,\n","#             scoring=model_scoring,\n","#             n_jobs=model_num_jobs,\n","#             verbose=3\n","#         )\n","#     elif model_search_method == \"random\":\n","#         search = RandomizedSearchCV(\n","#             pipeline,\n","#             param_distributions=model_param_dict[\"Naive Bayes\"],\n","#             n_iter=model_num_iter,\n","#             cv=model_cv_num,\n","#             scoring=model_scoring,\n","#             random_state=model_random_state,\n","#             n_jobs=model_num_jobs,\n","#         )\n","\n","#     search.fit(X_train, Y_train)\n","\n","#     # Save best model\n","#     best_estimators_dict[\"Naive Bayes\"] = search.best_estimator_\n","#     print(\"Best parameters for Naive Bayes:\", search.best_params_)\n","\n","#     \t# Save the trained model\n","#     model_filename = \"Naive Bayes.pkl\"\n","#     joblib.dump(search.best_estimator_, model_filename)\n","#     print(f\"Model saved as {model_filename}\")\n","\n","#     model_end_time = time.time()\n","#     model_total_time = model_end_time - model_start_time\n","#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","#     print(f\"Naive Bayes has run tuning for {model_duration:.3f} {model_tag}\")\n","#     print()\n"]},{"cell_type":"code","execution_count":null,"id":"Mn1rNEc_vadw","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":412},"executionInfo":{"elapsed":21,"status":"error","timestamp":1741368696907,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"},"user_tz":-480},"id":"Mn1rNEc_vadw","outputId":"7f1d168a-dd68-42a0-9dc1-039bebe67014"},"outputs":[{"ename":"ImportError","evalue":"cannot import name 'RandomizedSearchCV' from 'cuml.model_selection' (/usr/local/lib/python3.11/dist-packages/cuml/model_selection/__init__.py)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-d0a1667db472>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcupy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcp\u001b[0m  \u001b[0;31m# for GPU arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m  \u001b[0;31m# GPU-accelerated Naive Bayes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m  \u001b[0;31m# GPU-aware model selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'RandomizedSearchCV' from 'cuml.model_selection' (/usr/local/lib/python3.11/dist-packages/cuml/model_selection/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["# Replacement for top\n","import time\n","import joblib\n","import cudf  # RAPIDS cudf for GPU DataFrames\n","import cupy as cp  # for GPU arrays\n","from cuml.naive_bayes import GaussianNB  # GPU-accelerated Naive Bayes\n","from cuml.model_selection import GridSearchCV, RandomizedSearchCV  # GPU-aware model selection\n","from sklearn.pipeline import Pipeline\n","\n","# Assume preprocessor is either GPU-enabled or you have modified it accordingly.\n","# Also assume model_param_dict is updated to reflect hyperparameters for GaussianNB.\n","\n","if \"Naive Bayes\" in model_param_dict:\n","    model_start_time = time.time()\n","    print(\"Processing GPU-accelerated Naive Bayes now...\")\n","\n","    # Create the GPU-enabled model (using GaussianNB as an example)\n","    model = GaussianNB()\n","    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","    # Convert training data to cudf (if they are originally pandas DataFrame/Series)\n","    X_train_gpu = cudf.DataFrame.from_pandas(X_train)\n","    Y_train_gpu = cudf.Series(Y_train)\n","\n","    # Select the hyperparameter search method\n","    if model_search_method == \"grid\":\n","        search = GridSearchCV(\n","            pipeline,\n","            param_grid=model_param_dict[\"Naive Bayes\"],\n","            cv=model_cv_num,\n","            scoring=model_scoring,\n","            # n_jobs parameter might not be as beneficial since GPU operations are handled differently.\n","            verbose=3\n","        )\n","    elif model_search_method == \"random\":\n","        search = RandomizedSearchCV(\n","            pipeline,\n","            param_distributions=model_param_dict[\"Naive Bayes\"],\n","            n_iter=model_num_iter,\n","            cv=model_cv_num,\n","            scoring=model_scoring,\n","            random_state=model_random_state,\n","        )\n","\n","    # Fit the search on the GPU data\n","    search.fit(X_train_gpu, Y_train_gpu)\n","\n","    # Save best model\n","    best_estimators_dict[\"Naive Bayes\"] = search.best_estimator_\n","    print(\"Best parameters for GPU Naive Bayes:\", search.best_params_)\n","\n","    # Save the trained model\n","    model_filename = \"GPU_Naive_Bayes.pkl\"\n","    joblib.dump(search.best_estimator_, model_filename)\n","    print(f\"Model saved as {model_filename}\")\n","\n","    model_end_time = time.time()\n","    model_total_time = model_end_time - model_start_time\n","    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","    print(f\"GPU Naive Bayes tuning ran for {model_duration:.3f} {model_tag}\")\n","    print()"]},{"cell_type":"markdown","id":"QGf3kzMJjHi7","metadata":{"id":"QGf3kzMJjHi7"},"source":["XGB Below"]},{"cell_type":"code","execution_count":null,"id":"65f5b2f1","metadata":{"id":"65f5b2f1"},"outputs":[],"source":["# # Train XG Boost\n","# if \"XG Boost\" in model_param_dict:\n","#     model_start_time = time.time()\n","#     print(\"Processing XG Boost now...\")\n","\n","#     model = XGBClassifier(objective=\"reg:squarederror\", random_state=model_random_state)\n","#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","#     if model_search_method == \"grid\":\n","#         search = GridSearchCV(\n","#             pipeline,\n","#             param_grid=model_param_dict[\"XG Boost\"],\n","#             cv=model_cv_num,\n","#             scoring=model_scoring,\n","#             n_jobs=model_num_jobs,\n","#             verbose=3\n","#         )\n","#     elif model_search_method == \"random\":\n","#         search = RandomizedSearchCV(\n","#             pipeline,\n","#             param_distributions=model_param_dict[\"XG Boost\"],\n","#             n_iter=model_num_iter,\n","#             cv=model_cv_num,\n","#             scoring=model_scoring,\n","#             random_state=model_random_state,\n","#             n_jobs=model_num_jobs,\n","#         )\n","\n","#     search.fit(X_train, Y_train)\n","\n","#     # Save best model\n","#     best_estimators_dict[\"XG Boost\"] = search.best_estimator_\n","#     print(\"Best parameters for XG Boost:\", search.best_params_)\n","\n","# \t# Save the trained model\n","#     model_filename = \"XGBoost.pkl\"\n","#     joblib.dump(search.best_estimator_, model_filename)\n","#     print(f\"Model saved as {model_filename}\")\n","\n","#     model_end_time = time.time()\n","#     model_total_time = model_end_time - model_start_time\n","#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","#     print(f\"XG Boost has run tuning for {model_duration:.3f} {model_tag}\")\n","#     print()\n"]},{"cell_type":"code","execution_count":null,"id":"53FE-VNPvv7x","metadata":{"id":"53FE-VNPvv7x","colab":{"base_uri":"https://localhost:8080/","height":210},"executionInfo":{"status":"error","timestamp":1741669381897,"user_tz":-480,"elapsed":48,"user":{"displayName":"Eddie Seet","userId":"03183823730694872909"}},"outputId":"b2cfb84c-899b-4bfb-9463-eecd6e8506de"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model_param_dict' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-f866defe8782>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# XGB GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;34m\"XG Boost\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_param_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing XG Boost on GPU now...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model_param_dict' is not defined"]}],"source":["# XGB GPU\n","if \"XG Boost\" in model_param_dict:\n","    model_start_time = time.time()\n","    print(\"Processing XG Boost on GPU now...\")\n","\n","    # Initialize XGBoost with GPU parameters.\n","    model = XGBClassifier(\n","        objective=\"reg:squarederror\",  # adjust if your task is classification\n","        tree_method=\"gpu_hist\",         # GPU-accelerated algorithm\n","        predictor=\"gpu_predictor\",      # use GPU for predictions\n","        gpu_id=0,                       # which GPU to use (0 for the first GPU)\n","        random_state=model_random_state\n","    )\n","\n","    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n","\n","    if model_search_method == \"grid\":\n","        search = GridSearchCV(\n","            pipeline,\n","            param_grid=model_param_dict[\"XG Boost\"],\n","            cv=model_cv_num,\n","            scoring=model_scoring,\n","            n_jobs=model_num_jobs,\n","            verbose=3\n","        )\n","    elif model_search_method == \"random\":\n","        search = RandomizedSearchCV(\n","            pipeline,\n","            param_distributions=model_param_dict[\"XG Boost\"],\n","            n_iter=model_num_iter,\n","            cv=model_cv_num,\n","            scoring=model_scoring,\n","            random_state=model_random_state,\n","            n_jobs=model_num_jobs,\n","        )\n","\n","    search.fit(X_train, Y_train)\n","\n","    # Save best model\n","    best_estimators_dict[\"XG Boost\"] = search.best_estimator_\n","    print(\"Best parameters for XG Boost:\", search.best_params_)\n","\n","    # Save the trained model\n","    model_filename = \"XGBoost_GPU.pkl\"\n","    joblib.dump(search.best_estimator_, model_filename)\n","    print(f\"Model saved as {model_filename}\")\n","\n","    model_end_time = time.time()\n","    model_total_time = model_end_time - model_start_time\n","    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n","    print(f\"XG Boost GPU tuning ran for {model_duration:.3f} {model_tag}\")\n","    print()"]},{"cell_type":"code","execution_count":null,"id":"5ebce2eb","metadata":{"id":"5ebce2eb"},"outputs":[],"source":["print(\"Training done!\")"]},{"cell_type":"code","execution_count":null,"id":"87885cd6","metadata":{"id":"87885cd6"},"outputs":[],"source":["part4_time = time.time()\n","part4_duration, part4_tag = duration_cal.duration_cal(part4_time - part3_time)\n","print(f\"Part 4 has run for {part4_duration:.3f} {part4_tag}!\")\n","print()"]},{"cell_type":"code","execution_count":null,"id":"93b8d38a","metadata":{"id":"93b8d38a"},"outputs":[],"source":["# Evaluate pre-selected models to get mean-squared error and r^2 values to determine which model is better for current dataset\n","print(\"5. Evaluating machine learning model...\")\n","model_eval.model_evaluation(X_test, Y_test, best_estimators_dict)\n","print(\"Evaluation done!\")"]},{"cell_type":"code","execution_count":null,"id":"85c775fd","metadata":{"id":"85c775fd"},"outputs":[],"source":["part5_time = time.time()\n","part5_duration, part5_tag = duration_cal.duration_cal(part5_time - part4_time)\n","print(f\"Part 5 has run for {part5_duration:.3f} {part5_tag}!\")\n","print()\n","print()"]},{"cell_type":"code","execution_count":null,"id":"29167f6a","metadata":{"id":"29167f6a"},"outputs":[],"source":["end_time = time.time()\n","final_time = end_time - start_time\n","final_duration, final_tag = duration_cal.duration_cal(final_time)\n","\n","print(\"Script has reached end of line - It will terminate now!\")\n","print(f\"Script has run for {final_duration:.3f} {final_tag}!\")"]},{"cell_type":"code","execution_count":null,"id":"e8204839","metadata":{"id":"e8204839"},"outputs":[],"source":["# Save results to a CSV file\n","results_df = pd.DataFrame(best_estimators_dict).T\n","results_df.to_csv(\"model_results.csv\", index=True)\n","print(\"Results saved to 'model_results.csv'\")"]},{"cell_type":"code","execution_count":null,"id":"CGal47dWGnhM","metadata":{"id":"CGal47dWGnhM"},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":5}