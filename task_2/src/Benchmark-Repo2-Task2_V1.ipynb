{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eed8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "# Import necessary libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"4\"\n",
    "\n",
    "import setup.setup as setup\n",
    "import setup.duration_cal as duration_cal\n",
    "importlib.reload(setup)  # Reload the module to reflect new changes\n",
    "\n",
    "import EDA.eda_step as EDA\n",
    "import model_select.model_select as model_select\n",
    "import model_eval.model_eval as model_eval\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from typing import Dict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6080166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load configuration and setup parameters\n",
    "start_time = time.time()\n",
    "\n",
    "(\n",
    "    db_path,\n",
    "    target_col,\n",
    "    num_map_dict,\n",
    "    standard_list,\n",
    "    one_hot_list,\n",
    "    model_test_size,\n",
    "    model_random_state,\n",
    "    model_search_method,\n",
    "    model_cv_num,\n",
    "    model_scoring,\n",
    "    model_num_iter,\n",
    "    model_num_jobs,\n",
    "    model_param_dict,\n",
    ") = setup.setup_stage_v1()\n",
    "\n",
    "print(\"Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baaa85a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Connecting to SQL database....\n",
      "Connection done!\n"
     ]
    }
   ],
   "source": [
    "# Create connection to SQL database\n",
    "print(\"1. Connecting to SQL database....\")\n",
    "conn = sqlite3.connect(db_path)\n",
    "print(\"Connection done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d75a2b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 has run for 0.021 sec!\n"
     ]
    }
   ],
   "source": [
    "part1_time = time.time()\n",
    "part1_duration, part1_tag = duration_cal.duration_cal(part1_time - start_time)\n",
    "print(f\"Part 1 has run for {part1_duration:.3f} {part1_tag}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b994bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Extract SQL database table as DataFrame...\n",
      "Extraction done!\n"
     ]
    }
   ],
   "source": [
    "# Get data from 'noshow' table\n",
    "print(\"2. Extract SQL database table as DataFrame...\")\n",
    "\n",
    "noshow_data_query = \"SELECT * FROM noshow;\"\n",
    "noshow_data_df = pd.read_sql_query(noshow_data_query, conn)\n",
    "\n",
    "print(\"Extraction done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c16dd7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2 has run for 0.574 sec!\n"
     ]
    }
   ],
   "source": [
    "part2_time = time.time()\n",
    "\n",
    "part2_duration, part2_tag = duration_cal.duration_cal(part2_time - part1_time)\n",
    "\n",
    "print(f\"Part 2 has run for {part2_duration:.3f} {part2_tag}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "202965b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Performing EDA on DataFrame...\n",
      "EDA done!\n"
     ]
    }
   ],
   "source": [
    "# Using analysis from task_1 EDA, perform data preprocessing, feature data standardization and one-hot encoding\n",
    "print(\"3. Performing EDA on DataFrame...\")\n",
    "\n",
    "fil_noshow_data_df, preprocessor, X_train, X_test, Y_train, Y_test = EDA.ml_eda_step(\n",
    "    noshow_data_df,\n",
    "    target_col,\n",
    "    num_map_dict,\n",
    "    standard_list,\n",
    "    one_hot_list,\n",
    "    model_test_size,\n",
    "    model_random_state,\n",
    ")\n",
    "\n",
    "print(\"EDA done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a43d31a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3 has run for 3.438 sec!\n"
     ]
    }
   ],
   "source": [
    "part3_time = time.time()\n",
    "\n",
    "part3_duration, part3_tag = duration_cal.duration_cal(part3_time - part2_time)\n",
    "\n",
    "print(f\"Part 3 has run for {part3_duration:.3f} {part3_tag}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3a7dfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Training machine learning models...\n"
     ]
    }
   ],
   "source": [
    "best_estimators_dict = {}\n",
    "# Pre-select a few models and train models to get best optimized parameters\n",
    "print(\"4. Training machine learning models...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4604647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train Logistic Regression\n",
    "# if \"Logistic Regression\" in model_param_dict:\n",
    "#     model_start_time = time.time()\n",
    "#     print(\"Processing Logistic Regression now...\")\n",
    "    \n",
    "#     model = LogisticRegression(random_state=model_random_state)\n",
    "#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "#     if model_search_method == \"grid\":\n",
    "#         search = GridSearchCV(\n",
    "#             pipeline,\n",
    "#             param_grid=model_param_dict[\"Logistic Regression\"],\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#             verbose=3\n",
    "#         )\n",
    "#     elif model_search_method == \"random\":\n",
    "#         search = RandomizedSearchCV(\n",
    "#             pipeline,\n",
    "#             param_distributions=model_param_dict[\"Logistic Regression\"],\n",
    "#             n_iter=model_num_iter,\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             random_state=model_random_state,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#         )\n",
    "#     with tqdm(total=100, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ time left: {remaining} ]\") as pbar:\n",
    "#         search.fit(X_train, Y_train)\n",
    "#         pbar.update(100)\n",
    "\n",
    "#     # Save best model\n",
    "#     best_estimators_dict[\"Logistic Regression\"] = search.best_estimator_\n",
    "#     print(\"Best parameters for Logistic Regression:\", search.best_params_)\n",
    "\n",
    "#     model_end_time = time.time()\n",
    "#     model_total_time = model_end_time - model_start_time\n",
    "#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "#     print(f\"Logistic Regression has run tuning for {model_duration:.3f} {model_tag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "907ba669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train Random Forest\n",
    "# if \"Random Forest\" in model_param_dict:\n",
    "#     model_start_time = time.time()\n",
    "#     print(\"Processing Random Forest now...\")\n",
    "    \n",
    "#     model = RandomForestClassifier(random_state=model_random_state)\n",
    "#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "#     if model_search_method == \"grid\":\n",
    "#         search = GridSearchCV(\n",
    "#             pipeline,\n",
    "#             param_grid=model_param_dict[\"Random Forest\"],\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#             verbose=3\n",
    "#         )\n",
    "#     elif model_search_method == \"random\":\n",
    "#         search = RandomizedSearchCV(\n",
    "#             pipeline,\n",
    "#             param_distributions=model_param_dict[\"Random Forest\"],\n",
    "#             n_iter=model_num_iter,\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             random_state=model_random_state,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#         )\n",
    "\n",
    "#     search.fit(X_train, Y_train)\n",
    "\n",
    "#     # Save best model\n",
    "#     best_estimators_dict[\"Random Forest\"] = search.best_estimator_\n",
    "#     print(\"Best parameters for Random Forest:\", search.best_params_)\n",
    "\n",
    "#     model_end_time = time.time()\n",
    "#     model_total_time = model_end_time - model_start_time\n",
    "#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "#     print(f\"Random Forest has run tuning for {model_duration:.3f} {model_tag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14040bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       arrival_day  checkout_day  sgd_price  branch_Orchard  \\\n",
      "74942     0.026909      0.341837   0.137234               0   \n",
      "736      -0.884028     -0.378362   1.126124               1   \n",
      "\n",
      "       booking_month_August  booking_month_December  booking_month_February  \\\n",
      "74942                     0                       0                       0   \n",
      "736                       0                       1                       0   \n",
      "\n",
      "       booking_month_January  booking_month_July  booking_month_June  ...  \\\n",
      "74942                      0                   0                   0  ...   \n",
      "736                        0                   0                   0  ...   \n",
      "\n",
      "       country_Japan  country_Malaysia  country_Singapore  first_time_Yes  \\\n",
      "74942              0                 0                  0               1   \n",
      "736                0                 0                  0               1   \n",
      "\n",
      "       room_President Suite  room_Queen  room_Single  platform_Email  \\\n",
      "74942                     0           0            0               0   \n",
      "736                       0           0            0               0   \n",
      "\n",
      "       platform_Phone  platform_Website  \n",
      "74942               0                 0  \n",
      "736                 0                 0  \n",
      "\n",
      "[2 rows x 125 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(type(X_test))\n",
    "print(X_test.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f6db110",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "HalvingGridSearchCV is experimental and the API might change without any deprecation cycle. To use it, you need to explicitly import enable_halving_search_cv:\nfrom sklearn.experimental import enable_halving_search_cv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train SVC\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HalvingGridSearchCV\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVC\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_param_dict:\n\u001b[1;32m      6\u001b[0m     model_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/__init__.py:82\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHalvingGridSearchCV\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHalvingRandomSearchCV\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m---> 82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     83\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is experimental and the API might change without any \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecation cycle. To use it, you need to explicitly import \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_halving_search_cv:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom sklearn.experimental import enable_halving_search_cv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         )\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: HalvingGridSearchCV is experimental and the API might change without any deprecation cycle. To use it, you need to explicitly import enable_halving_search_cv:\nfrom sklearn.experimental import enable_halving_search_cv"
     ]
    }
   ],
   "source": [
    "# Train SVC\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "\n",
    "if \"SVC\" in model_param_dict:\n",
    "    model_start_time = time.time()\n",
    "    print(\"Processing SVC now...\")\n",
    "    \n",
    "    model = SVC()\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "    if model_search_method == \"grid\":\n",
    "        search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=model_param_dict[\"SVC\"],\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            n_jobs=model_num_jobs,\n",
    "            verbose=10\n",
    "        )\n",
    "    elif model_search_method == \"random\":\n",
    "        search = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions=model_param_dict[\"SVC\"],\n",
    "            n_iter=model_num_iter,\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            random_state=model_random_state,\n",
    "            n_jobs=model_num_jobs,\n",
    "        )\n",
    "    else :\n",
    "        search = HalvingGridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=model_param_dict[\"SVC\"],\n",
    "    factor=2,  # Prune half the models at each step\n",
    "    cv=model_cv_num,\n",
    "    scoring=model_scoring,\n",
    "    n_jobs=model_num_jobs,\n",
    "    verbose=10\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    search.fit(X_train, Y_train)\n",
    "\n",
    "    # Save best model\n",
    "    best_estimators_dict[\"SVC\"] = search.best_estimator_\n",
    "    print(\"Best parameters for SVC:\", search.best_params_)\n",
    "\n",
    "    model_end_time = time.time()\n",
    "    model_total_time = model_end_time - model_start_time\n",
    "    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "    print(f\"SVC has run tuning for {model_duration:.3f} {model_tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8035bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train MLP\n",
    "# if \"MLP\" in model_param_dict:\n",
    "#     model_start_time = time.time()\n",
    "#     print(\"Processing MLP now...\")\n",
    "    \n",
    "#     model = MLPClassifier(random_state=model_random_state)\n",
    "#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "#     if model_search_method == \"grid\":\n",
    "#         search = GridSearchCV(\n",
    "#             pipeline,\n",
    "#             param_grid=model_param_dict[\"MLP\"],\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#             verbose=3\n",
    "#         )\n",
    "#     elif model_search_method == \"random\":\n",
    "#         search = RandomizedSearchCV(\n",
    "#             pipeline,\n",
    "#             param_distributions=model_param_dict[\"MLP\"],\n",
    "#             n_iter=model_num_iter,\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             random_state=model_random_state,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#         )\n",
    "\n",
    "#     search.fit(X_train, Y_train)\n",
    "\n",
    "#     # Save best model\n",
    "#     best_estimators_dict[\"MLP\"] = search.best_estimator_\n",
    "#     print(\"Best parameters for MLP:\", search.best_params_)\n",
    "\n",
    "#     model_end_time = time.time()\n",
    "#     model_total_time = model_end_time - model_start_time\n",
    "#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "#     print(f\"MLP has run tuning for {model_duration:.3f} {model_tag}\")\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71bd351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train Naive Bayes\n",
    "# if \"Naive Bayes\" in model_param_dict:\n",
    "#     model_start_time = time.time()\n",
    "#     print(\"Processing Naive Bayes now...\")\n",
    "    \n",
    "#     model = BernoulliNB()\n",
    "#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "#     if model_search_method == \"grid\":\n",
    "#         search = GridSearchCV(\n",
    "#             pipeline,\n",
    "#             param_grid=model_param_dict[\"Naive Bayes\"],\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#             verbose=3\n",
    "#         )\n",
    "#     elif model_search_method == \"random\":\n",
    "#         search = RandomizedSearchCV(\n",
    "#             pipeline,\n",
    "#             param_distributions=model_param_dict[\"Naive Bayes\"],\n",
    "#             n_iter=model_num_iter,\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             random_state=model_random_state,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#         )\n",
    "\n",
    "#     search.fit(X_train, Y_train)\n",
    "\n",
    "#     # Save best model\n",
    "#     best_estimators_dict[\"Naive Bayes\"] = search.best_estimator_\n",
    "#     print(\"Best parameters for Naive Bayes:\", search.best_params_)\n",
    "\n",
    "#     model_end_time = time.time()\n",
    "#     model_total_time = model_end_time - model_start_time\n",
    "#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "#     print(f\"Naive Bayes has run tuning for {model_duration:.3f} {model_tag}\")\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train XG Boost\n",
    "# if \"XG Boost\" in model_param_dict:\n",
    "#     model_start_time = time.time()\n",
    "#     print(\"Processing XG Boost now...\")\n",
    "    \n",
    "#     model = XGBClassifier(objective=\"reg:squarederror\", random_state=model_random_state)\n",
    "#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "#     if model_search_method == \"grid\":\n",
    "#         search = GridSearchCV(\n",
    "#             pipeline,\n",
    "#             param_grid=model_param_dict[\"XG Boost\"],\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#             verbose=3\n",
    "#         )\n",
    "#     elif model_search_method == \"random\":\n",
    "#         search = RandomizedSearchCV(\n",
    "#             pipeline,\n",
    "#             param_distributions=model_param_dict[\"XG Boost\"],\n",
    "#             n_iter=model_num_iter,\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             random_state=model_random_state,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#         )\n",
    "\n",
    "#     search.fit(X_train, Y_train)\n",
    "\n",
    "#     # Save best model\n",
    "#     best_estimators_dict[\"XG Boost\"] = search.best_estimator_\n",
    "#     print(\"Best parameters for XG Boost:\", search.best_params_)\n",
    "\n",
    "#     model_end_time = time.time()\n",
    "#     model_total_time = model_end_time - model_start_time\n",
    "#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "#     print(f\"XG Boost has run tuning for {model_duration:.3f} {model_tag}\")\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebce2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87885cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "part4_time = time.time()\n",
    "part4_duration, part4_tag = duration_cal.duration_cal(part4_time - part3_time)\n",
    "print(f\"Part 4 has run for {part4_duration:.3f} {part4_tag}!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b8d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate pre-selected models to get mean-squared error and r^2 values to determine which model is better for current dataset\n",
    "print(\"5. Evaluating machine learning model...\")\n",
    "model_eval.model_evaluation(X_test, Y_test, best_estimators_dict)\n",
    "print(\"Evaluation done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c775fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "part5_time = time.time()\n",
    "part5_duration, part5_tag = duration_cal.duration_cal(part5_time - part4_time)\n",
    "print(f\"Part 5 has run for {part5_duration:.3f} {part5_tag}!\")\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29167f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "final_time = end_time - start_time\n",
    "final_duration, final_tag = duration_cal.duration_cal(final_time)\n",
    "\n",
    "print(\"Script has reached end of line - It will terminate now!\")\n",
    "print(f\"Script has run for {final_duration:.3f} {final_tag}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8204839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a CSV file\n",
    "results_df = pd.DataFrame(best_estimators_dict).T\n",
    "results_df.to_csv(\"model_results.csv\", index=True)\n",
    "print(\"Results saved to 'model_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
