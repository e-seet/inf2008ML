{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Step 1: Setup env, SQL connection and analyze SQL database data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries when needed and establish connection to SQL database (noshow.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries that are currently needed\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set path to SQL database\n",
    "db_path = \"../data/noshow.db\"\n",
    "\n",
    "# Create connection to SQL database\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Set pandas options for better readbility\n",
    "pd.set_option('display.max_columns', None) # Display all columns in DataFrame\n",
    "pd.set_option('display.max_rows', 100) # Limit number of rows displayed\n",
    "\n",
    "# Setup matplotlib and seaborn for inline visualization\n",
    "%matplotlib inline\n",
    "sns.set(style = \"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore database structure by listing all available tables before further actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to list all tables in database\n",
    "query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql(query, conn)\n",
    "\n",
    "# Display list of tables\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is only 'noshow' table in the database, the first few rows can be previewed to understand its structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview first few rows of 'noshow' table\n",
    "noshow_query = \"SELECT * FROM noshow LIMIT 10;\"\n",
    "df_noshow = pd.read_sql(noshow_query, conn)\n",
    "\n",
    "# Display first 10 rows of table\n",
    "df_noshow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of 'noshow' table consists of following columns:\n",
    "- booking_id (Unique value)\n",
    "- no_show\n",
    "- branch\n",
    "- booking_month\n",
    "- arrival_month\n",
    "- arrival_day\n",
    "- checkout_month\n",
    "- checkout_day\n",
    "- country\n",
    "- first_time\n",
    "- room (Drop missing values)\n",
    "- price (Drop missing values)\n",
    "- platform\n",
    "- num_adults\n",
    "- num_children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema of 'noshow' table is retrieved to understand the columns and their data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get schema of 'noshow' table\n",
    "schema_query = \"PRAGMA table_info(noshow);\"\n",
    "schema_df = pd.read_sql(schema_query, conn)\n",
    "\n",
    "# Display schema information\n",
    "schema_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the schema, some columns can be seen to have TEXT type data so they will have to be converted to REAL type using one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Perform Exploratory Data Analysis (EDA) on 'noshow' table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the data into a DataFrame to start data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all data from 'noshow' table\n",
    "noshow_data_query = \"SELECT * FROM noshow;\"\n",
    "noshow_data_df = pd.read_sql_query(noshow_data_query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use booking_id to eliminate duplicate data as each row should be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noshow_data_df = noshow_data_df.drop_duplicates(subset = \"booking_id\", keep = \"first\")\n",
    "noshow_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop booking_id column after removing duplicates as each row is now unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col_noshow_data_df = noshow_data_df.drop(columns = \"booking_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean-up rows with missing cell info <br>\n",
    "Example: If cell in row has missing value, then row should be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, check which columns have missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of rows that have missing data\n",
    "missing_data = drop_col_noshow_data_df.isnull().sum()\n",
    "\n",
    "# Display number of affected rows\n",
    "print(\"Missing values in each column: \")\n",
    "print(missing_data[missing_data > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Next, drop all rows that have missing values~~ <br>\n",
    "Use median/mode to replace missing values <br>\n",
    "Only drop row if all values are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows if there are any missing values\n",
    "#cleaned_noshow_data_df = drop_col_noshow_data_df.dropna()\n",
    "\n",
    "# Drop rows if all cells in that row have missing values\n",
    "cleaned_noshow_data_df = drop_col_noshow_data_df.dropna(how=\"all\")\n",
    "\n",
    "# Use median/mode to replace missing values\n",
    "cleaned_noshow_data_df[\"room\"] = cleaned_noshow_data_df[\"room\"].fillna(\"Unknown\")\n",
    "\n",
    "# Verify if all missing values are dropped\n",
    "print(\"Missing values after dropping rows: \")\n",
    "print(cleaned_noshow_data_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do manual data conversion for price and num_adults\n",
    "- price (Convert all price to SGD$ and remove SGD$)\n",
    "- num_adults (Convert string value to its integer value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume USD$ to SGD$ conversion rate is 1:1.34\n",
    "# Remove all USD$/SGD$ tags and create a new column called sgd_price\n",
    "def convert_price(price):\n",
    "    if isinstance(price, str):\n",
    "        # Check if price is in USD/SGD\n",
    "        if \"USD$\" in price:\n",
    "            value = float(price.replace(\"USD$ \", \"\").strip())\n",
    "            # Convert USD to SGD by multiplying by 1.34\n",
    "            value = value * 1.34\n",
    "        else:\n",
    "            # Extract number after SGD$ and convert to float\n",
    "            value = float(price.replace(\"SGD$ \", \"\").strip())\n",
    "        return value\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply function to 'price' column and create new column with converted values named 'sgd_price'\n",
    "cleaned_noshow_data_df[\"sgd_price\"] = cleaned_noshow_data_df[\"price\"].apply(convert_price)\n",
    "cleaned_noshow_data_df[\"sgd_price\"] = cleaned_noshow_data_df[\"sgd_price\"].fillna(cleaned_noshow_data_df[\"sgd_price\"].median())\n",
    "\n",
    "# Drop 'price' column\n",
    "cleaned_noshow_data_df = cleaned_noshow_data_df.drop(columns=\"price\")\n",
    "\n",
    "# Display DataFrame for post price conversion\n",
    "cleaned_noshow_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string value in num_adults to float value\n",
    "# Perform manual mapping after checking number of string values to replace\n",
    "print(\"Unique values in 'num_adults' column - \")\n",
    "print(cleaned_noshow_data_df[\"num_adults\"].unique())\n",
    "\n",
    "# There are only 'one' and 'two' string values in the column\n",
    "number_mapping = {\n",
    "    'one': \"1\",\n",
    "    'two': \"2\"\n",
    "}\n",
    "\n",
    "# Apply mapping to 'num_adults' column\n",
    "cleaned_noshow_data_df[\"num_adults\"] = cleaned_noshow_data_df[\"num_adults\"].replace(number_mapping)\n",
    "\n",
    "# Display DataFrame post mapping\n",
    "cleaned_noshow_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do extra mapping to factor in seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_mapping = {\n",
    "    \"december\": \"winter\", \"january\": \"winter\", \"february\": \"winter\", \"march\": \"spring\", \"april\": \"spring\",\n",
    "    \"may\": \"spring\", \"june\": \"summer\", \"july\": \"summer\", \"august\": \"summer\", \"september\": \"autumn\", \"october\": \"autumn\", \"november\": \"autumn\"\n",
    "}\n",
    "\n",
    "cleaned_noshow_data_df[\"arrival_month\"] = cleaned_noshow_data_df[\"arrival_month\"].str.lower()\n",
    "cleaned_noshow_data_df[\"checkout_month\"] = cleaned_noshow_data_df[\"checkout_month\"].str.lower()\n",
    "\n",
    "cleaned_noshow_data_df[\"trip_season\"] = cleaned_noshow_data_df[\"arrival_month\"].map(season_mapping)\n",
    "\n",
    "cleaned_noshow_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do extra mapping to convert arrival_month, arrival_day, checkout_month and checkout_day to number_of_days_stayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_mapping = {\n",
    "    \"january\": 1, \"february\": 2, \"march\": 3, \"april\": 4, \"may\": 5, \"june\": 6,\n",
    "    \"july\": 7, \"august\": 8, \"september\": 9, \"october\": 10, \"november\": 11, \"december\": 12\n",
    "}\n",
    "\n",
    "cleaned_noshow_data_df[\"arrival_month_num\"] = cleaned_noshow_data_df[\"arrival_month\"].map(month_mapping)\n",
    "cleaned_noshow_data_df[\"checkout_month_num\"] = cleaned_noshow_data_df[\"checkout_month\"].map(month_mapping)\n",
    "\n",
    "cleaned_noshow_data_df[\"arrival_year\"] = 2024\n",
    "cleaned_noshow_data_df[\"checkout_year\"] = cleaned_noshow_data_df.apply(\n",
    "    lambda row: row[\"arrival_year\"] + 1 if row[\"checkout_month_num\"] < row[\"arrival_month_num\"] else row[\"arrival_year\"], axis=1\n",
    ")\n",
    "\n",
    "cleaned_noshow_data_df[\"arrival_date\"] = pd.to_datetime(cleaned_noshow_data_df.apply(lambda row: f'{int(abs(row[\"arrival_day\"]))}-{int(row[\"arrival_month_num\"])}-{(row[\"arrival_year\"])}', axis=1), format='%d-%m-%Y')\n",
    "cleaned_noshow_data_df[\"checkout_date\"] = pd.to_datetime(cleaned_noshow_data_df.apply(lambda row: f'{int(abs(row[\"checkout_day\"]))}-{int(row[\"checkout_month_num\"])}-{(row[\"checkout_year\"])}', axis=1), format='%d-%m-%Y')\n",
    "\n",
    "cleaned_noshow_data_df[\"stayed_num_days\"] = (cleaned_noshow_data_df[\"checkout_date\"] - cleaned_noshow_data_df[\"arrival_date\"]).dt.days\n",
    "\n",
    "drop_date_col_list = [\"arrival_month\", \"arrival_day\", \"arrival_month_num\", \"arrival_date\", \"arrival_year\", \"checkout_month\", \"checkout_day\", \"checkout_month_num\", \"checkout_date\", \"checkout_year\"]\n",
    "cleaned_noshow_data_df = cleaned_noshow_data_df.drop(columns=drop_date_col_list)\n",
    "\n",
    "cleaned_noshow_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze distribution of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_list = [\"branch\", \"country\", \"first_time\", \"room\", \"platform\"]\n",
    "\n",
    "for col in cat_col_list:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.countplot(x=col, data=cleaned_noshow_data_df)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze distribution and relationship of numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col_list = [\"sgd_price\", \"num_adults\", \"num_children\"]\n",
    "\n",
    "for col in num_col_list:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.histplot(cleaned_noshow_data_df[col].dropna(), kde=True)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform label categorization to make all columns have categorical values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "standard_list = [\"sgd_price\", \"stayed_num_days\"]\n",
    "one_hot_list = [\"branch\", \"booking_month\", \"country\", \"first_time\", \"room\", \"platform\", \"trip_season\", \"num_adults\", \"num_children\"]\n",
    "\n",
    "lab_enc = LabelEncoder()\n",
    "cleaned_noshow_data_df[\"no_show\"] = lab_enc.fit_transform(cleaned_noshow_data_df[\"no_show\"])\n",
    "\n",
    "# Standardize data-set\n",
    "scaler = StandardScaler()\n",
    "cleaned_noshow_data_df[standard_list] = scaler.fit_transform(cleaned_noshow_data_df[standard_list])\n",
    "\n",
    "# Perform one-hot encoding on categorical variables\n",
    "encoded_noshow_data_df = pd.get_dummies(cleaned_noshow_data_df, columns = one_hot_list, drop_first=True)\n",
    "bool_col = encoded_noshow_data_df.select_dtypes(include=[\"bool\"]).columns\n",
    "encoded_noshow_data_df[bool_col] = encoded_noshow_data_df[bool_col].astype(int)\n",
    "encoded_noshow_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can now be used to generate summary statistics to check on mean, median, 25%, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics from 'noshow' DataFrame\n",
    "summary_stats = encoded_noshow_data_df.describe()\n",
    "\n",
    "# Display summary statistics\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Analyze the patterns and distributions in 'noshow' DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot heatmap for dimension reduction visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "corr_matrix = encoded_noshow_data_df.corr()\n",
    "\n",
    "# Create heatmap of correlation matrix\n",
    "plt.figure(figsize = (10, 8)) # Adjust size as needed\n",
    "sns.heatmap(corr_matrix, annot = True, cmap = \"coolwarm\", fmt = \".2f\", linewidths=0.5)\n",
    "\n",
    "# Show plot\n",
    "plt.title(\"Correlation matrix heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "no_show_corr = corr_matrix[\"no_show\"]\n",
    "\n",
    "# Sort correlations by absolute value (if strong correlations should be prioritized)\n",
    "sorted_corr = no_show_corr.abs().sort_values(ascending=False)\n",
    "\n",
    "# Print numerical correlation values\n",
    "print(\"Correlation with 'no_show': \")\n",
    "print(sorted_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop features with correlation value < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = sorted_corr[sorted_corr < 0.05].index\n",
    "\n",
    "final_noshow_data_df = encoded_noshow_data_df.drop(columns = drop_cols, axis = 1)\n",
    "final_noshow_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check correlation matrix again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "final_corr_matrix = final_noshow_data_df.corr()\n",
    "\n",
    "# Create heatmap of correlation matrix\n",
    "plt.figure(figsize = (10, 8)) # Adjust size as needed\n",
    "sns.heatmap(final_corr_matrix, annot = True, cmap = \"coolwarm\", fmt = \".2f\", linewidths=0.5)\n",
    "\n",
    "# Show plot\n",
    "plt.title(\"Final correlation matrix heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "final_no_show_corr = final_corr_matrix[\"no_show\"]\n",
    "\n",
    "# Sort correlations by absolute value (if strong correlations should be prioritized)\n",
    "final_sorted_corr = final_no_show_corr.abs().sort_values(ascending=False)\n",
    "\n",
    "# Print numerical correlation values\n",
    "print(\"Correlation with 'no_show': \")\n",
    "print(final_sorted_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing ML for chosen features in final_noshow_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_noshow_data_df.drop([\"no_show\"], axis = 1)\n",
    "Y = final_noshow_data_df[\"no_show\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into test and train (20/80 split)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check original class distribution in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original class distribution in training set:\")\n",
    "print(pd.Series(Y_train).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply SMOTE (Syntheetic Minority Over-sampling Technique) to balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy=\"auto\", random_state=42)\n",
    "resampled_X_train, resampled_Y_train = smote.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check new class distribution after SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class distribution after SMOTE:\")\n",
    "print(pd.Series(resampled_Y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lab_enc = LabelEncoder()\n",
    "\n",
    "resampled_Y_train = lab_enc.fit_transform(resampled_Y_train)\n",
    "Y_test = lab_enc.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(resampled_X_train, resampled_Y_train)\n",
    "log_Y_predict = log_model.predict(X_test)\n",
    "\n",
    "log_confuse_matrix = confusion_matrix(Y_test, log_Y_predict)\n",
    "log_class_rpt = classification_report(Y_test, log_Y_predict)\n",
    "\n",
    "print(\"Pre-tuned Logistic Regression - \")\n",
    "print(f\"Confusion Matrix: \\n{log_confuse_matrix}\")\n",
    "print(f\"Classification Report: \\n{log_class_rpt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune Logistic Regression for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_n_eval_log_regression(X_train, Y_train, X_test, Y_test, search_method = \"grid\", param_grid = None, param_dist = None, random_iter = 50, cv = 5, num_jobs = 4):\n",
    "    \"\"\"\n",
    "    Automates the tuning and evaluation of a Random Forest Regressor model.\n",
    "\n",
    "    Parameters:\n",
    "        X: Features (DataFrame or array).\n",
    "        y: Target variable (Series or array).\n",
    "        search_method: 'grid' for GridSearchCV, 'random' for RandomizedSearchCV.\n",
    "        param_grid: Dictionary of hyperparameter ranges for GridSearchCV.\n",
    "        param_dist: Dictionary of hyperparameter distributions for RandomizedSearchCV.\n",
    "        random_iter: Number of iterations for RandomizedSearchCV.\n",
    "        cv: Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        best_model: The tuned Random Forest Regressor model.\n",
    "        best_params: The best hyperparameters found.\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "    import random\n",
    "\n",
    "    # Initialize parameters\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            \"solver\": [\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\"], # sag omitted due to non-convergence at current max_iter values\n",
    "            \"max_iter\": [50, 75, 100, 125],\n",
    "            \"C\": [0.1, 1, 5, 10],\n",
    "            \"class_weight\": [\"balanced\", {0: 1, 1: 1.7}, {0: 1, 1: 5}]\n",
    "        }\n",
    "    if param_dist is None:\n",
    "        from scipy.stats import randint\n",
    "        param_dist = {\n",
    "            \"solver\": [\"lbfgs\", \"liblinear\", \"sag\", \"newton-cg\", \"newton-cholesky\"],\n",
    "            \"max_iter\": randint(50, 200),\n",
    "            \"C\": [round(random.uniform(0, 20), 1) for _ in range(5)],\n",
    "            \"class_weight\": [\"balanced\", {0: 1, 1: 1.7}, {0: 1, 1: 5}]\n",
    "        }\n",
    "\n",
    "    if search_method == \"grid\":\n",
    "        search = GridSearchCV(\n",
    "            LogisticRegression(random_state = 42),\n",
    "            param_grid = param_grid,\n",
    "            cv = cv,\n",
    "            scoring = \"neg_mean_squared_error\",\n",
    "            n_jobs = num_jobs\n",
    "        )\n",
    "    elif search_method == \"random\":\n",
    "        search = RandomizedSearchCV(\n",
    "            LogisticRegression(random_state = 42),\n",
    "            param_distributions = param_dist,\n",
    "            n_iter = random_iter,\n",
    "            cv = cv,\n",
    "            scoring = \"neg_mean_squared_error\",\n",
    "            random_state = 42,\n",
    "            n_jobs = num_jobs\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"search_method must be either 'grid' or ' random'\")\n",
    "    \n",
    "    # Fit the search\n",
    "    print(f\"Running {search_method.capitalize()} Search...\")\n",
    "    search.fit(X_train, Y_train)\n",
    "\n",
    "    # Best model and parameters\n",
    "    best_model = search.best_estimator_\n",
    "    best_params = search.best_params_\n",
    "    print(f\"\\nBest Parameters: {best_params}\")\n",
    "\n",
    "    # Test set evaluation\n",
    "    tuned_log_Y_predict = best_model.predict(X_test)\n",
    "    tuned_log_confuse_matrix = confusion_matrix(Y_test, tuned_log_Y_predict)\n",
    "    tuned_log_class_rpt = classification_report(Y_test, tuned_log_Y_predict)\n",
    "    print(\"Tuned Logistic Regression -\")\n",
    "    print(f\"Tuned Set Confusion Matrix: \\n{tuned_log_confuse_matrix}\")\n",
    "    print(f\"Tuned Set Classification Report: \\n{tuned_log_class_rpt}\")\n",
    "\n",
    "    # Plot Confusion Matrix of actual vs predicted\n",
    "    conf_matrix = confusion_matrix(Y_test, log_Y_predict)\n",
    "\n",
    "    ConfusionMatrixDisplay(conf_matrix, display_labels=[\"No_Show\", \"Show\"]).plot(cmap=\"Blues\")\n",
    "    plt.show()\n",
    "\n",
    "    return best_model, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Grid Search\n",
    "grid_log_best_model, grid_log_best_param = tune_n_eval_log_regression(\n",
    "    resampled_X_train,\n",
    "    resampled_Y_train,\n",
    "    X_test,\n",
    "    Y_test,\n",
    "    search_method = \"grid\",\n",
    "    num_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Random Search\n",
    "rand_log_best_model, rand_log_best_param = tune_n_eval_log_regression(\n",
    "    resampled_X_train,\n",
    "    resampled_Y_train,\n",
    "    X_test,\n",
    "    Y_test,\n",
    "    search_method = \"random\",\n",
    "    num_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, try with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rand_for_model = RandomForestClassifier()\n",
    "rand_for_model.fit(resampled_X_train, resampled_Y_train)\n",
    "rand_for_Y_predict = rand_for_model.predict(X_test)\n",
    "\n",
    "rand_for_confuse_matrix = confusion_matrix(Y_test, rand_for_Y_predict)\n",
    "rand_for_class_rpt = classification_report(Y_test, rand_for_Y_predict)\n",
    "\n",
    "print(\"Pre-tuning Random Forest Classifier - \")\n",
    "print(f\"Confusion Matrix: \\n{rand_for_confuse_matrix}\")\n",
    "print(f\"Classification Report: \\n{rand_for_class_rpt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune Random Forest for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_n_eval_forest_classifier(X_train, Y_train, X_test, Y_test, search_method = \"grid\", param_grid = None, param_dist = None, random_iter = 50, cv = 5, num_jobs = 4):\n",
    "    \"\"\"\n",
    "    Automates the tuning and evaluation of a Random Forest Regressor model.\n",
    "\n",
    "    Parameters:\n",
    "        X: Features (DataFrame or array).\n",
    "        y: Target variable (Series or array).\n",
    "        search_method: 'grid' for GridSearchCV, 'random' for RandomizedSearchCV.\n",
    "        param_grid: Dictionary of hyperparameter ranges for GridSearchCV.\n",
    "        param_dist: Dictionary of hyperparameter distributions for RandomizedSearchCV.\n",
    "        random_iter: Number of iterations for RandomizedSearchCV.\n",
    "        cv: Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "        best_model: The tuned Random Forest Regressor model.\n",
    "        best_params: The best hyperparameters found.\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "    # Initialize parameters\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            \"n_estimators\": [50, 100, 150, 200],\n",
    "            \"max_depth\": [None, 5, 10],\n",
    "            \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 2, 4],\n",
    "            \"class_weight\": [\"balanced\", {0: 1, 1: 1.7}, {0: 1, 1: 5}]\n",
    "        }\n",
    "    if param_dist is None:\n",
    "        from scipy.stats import randint\n",
    "        param_dist = {\n",
    "            \"n_estimators\": randint(100, 500),\n",
    "            \"max_depth\": [None, 5, 10, 15],\n",
    "            \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "            \"min_samples_split\": randint(2, 20),\n",
    "            \"min_samples_leaf\": randint(1, 20)\n",
    "        }\n",
    "\n",
    "    if search_method == \"grid\":\n",
    "        search = GridSearchCV(\n",
    "            RandomForestClassifier(random_state = 42),\n",
    "            param_grid = param_grid,\n",
    "            cv = cv,\n",
    "            scoring = \"neg_mean_squared_error\",\n",
    "            n_jobs = num_jobs\n",
    "        )\n",
    "    elif search_method == \"random\":\n",
    "        search = RandomizedSearchCV(\n",
    "            RandomForestClassifier(random_state = 42),\n",
    "            param_distributions = param_dist,\n",
    "            n_iter = random_iter,\n",
    "            cv = cv,\n",
    "            scoring = \"neg_mean_squared_error\",\n",
    "            random_state = 42,\n",
    "            n_jobs = num_jobs\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"search_method must be either 'grid' or ' random'\")\n",
    "    \n",
    "    # Fit the search\n",
    "    print(f\"Running {search_method.capitalize()} Search...\")\n",
    "    search.fit(X_train, Y_train)\n",
    "\n",
    "    # Best model and parameters\n",
    "    best_model = search.best_estimator_\n",
    "    best_params = search.best_params_\n",
    "    print(f\"\\nBest Parameters: {best_params}\")\n",
    "\n",
    "    # Test set evaluation\n",
    "    tuned_rand_for_Y_predict = best_model.predict(X_test)\n",
    "    tuned_rand_for_confuse_matrix = confusion_matrix(Y_test, tuned_rand_for_Y_predict)\n",
    "    tuned_rand_for_class_rpt = classification_report(Y_test, tuned_rand_for_Y_predict)\n",
    "    print(\"Tuned Random Forest Classification -\")\n",
    "    print(f\"Tuned Set Confusion Matrix: \\n{tuned_rand_for_confuse_matrix}\")\n",
    "    print(f\"Tuned Set Classification Report: \\n{tuned_rand_for_class_rpt}\")\n",
    "\n",
    "    # Plot Confusion Matrix of actual vs predicted\n",
    "    conf_matrix = confusion_matrix(Y_test, log_Y_predict)\n",
    "\n",
    "    ConfusionMatrixDisplay(conf_matrix, display_labels=[\"No_Show\", \"Show\"]).plot(cmap=\"Blues\")\n",
    "    plt.show()\n",
    "\n",
    "    return best_model, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call tuning and evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp removed due to long run time\n",
    "## Using Grid Search\n",
    "#grid_rand_for_best_model, grid_rand_for_best_param = tune_n_eval_forest_classifier(\n",
    "#    resampled_X_train,\n",
    "#    resampled_Y_train,\n",
    "#    X_test,\n",
    "#    Y_test,\n",
    "#    search_method = \"grid\",\n",
    "#    num_jobs = -1\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Random Search\n",
    "rand_rand_for_best_model, rand_rand_for_best_param = tune_n_eval_forest_classifier(\n",
    "    resampled_X_train,\n",
    "    resampled_Y_train,\n",
    "    X_test,\n",
    "    Y_test,\n",
    "    search_method = \"random\",\n",
    "    num_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use XGBoost for variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(resampled_X_train, resampled_Y_train)\n",
    "xgb_Y_predict = xgb_model.predict(X_test)\n",
    "\n",
    "xgb_confuse_matrix = confusion_matrix(Y_test, xgb_Y_predict)\n",
    "xgb_class_rpt = classification_report(Y_test, xgb_Y_predict)\n",
    "\n",
    "print(\"XGBoost - \")\n",
    "print(f\"Confusion Matrix: \\n{xgb_confuse_matrix}\")\n",
    "print(f\"Classification Report: \\n{xgb_class_rpt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot XGBoost's Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "xgb_conf_matrix = confusion_matrix(Y_test, log_Y_predict)\n",
    "\n",
    "ConfusionMatrixDisplay(xgb_conf_matrix, display_labels=[\"No_Show\", \"Show\"]).plot(cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check variance and range of target variable - no_show <br>\n",
    "(Skipped for classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate variance of target variable\n",
    "#variance_no_show = Y_test.var() # Variance of actual target values\n",
    "#print(f\"Variance of 'no_show': {variance_no_show:.3f}\")\n",
    "#\n",
    "## Calculate range of target variable\n",
    "#range_no_show = Y_test.max() - Y_test.min()\n",
    "#print(f\"Range of 'no_show': {range_no_show:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform ML with PCA (95% variance) features <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "pca = PCA(n_components = 0.95) # Keep 95% of variance\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "print(\"Explained variance ratio: \", pca.explained_variance_ratio_)\n",
    "print(\"Cumulative explained variance: \", np.cumsum(pca.explained_variance_ratio_))\n",
    "\n",
    "pca_X_train, pca_X_test, pca_Y_train, pca_Y_test = train_test_split(X_pca, Y, test_size = 0.2, random_state = 42)\n",
    "resampled_pca_X_train, resampled_pca_Y_train = smote.fit_resample(pca_X_train, pca_Y_train)\n",
    "\n",
    "pca_model = RandomForestClassifier()\n",
    "pca_model.fit(resampled_pca_X_train, resampled_pca_Y_train)\n",
    "\n",
    "pca_Y_predict = pca_model.predict(pca_X_test)\n",
    "pca_confuse_matrix = confusion_matrix(Y_test, pca_Y_predict)\n",
    "pca_class_rpt = classification_report(Y_test, pca_Y_predict)\n",
    "\n",
    "print(\"PCA Random Forest Classifier - \")\n",
    "print(f\"Confusion Matrix: \\n{pca_confuse_matrix}\")\n",
    "print(f\"Classification Report: \\n{pca_class_rpt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cross-validation with PCA feature <br>\n",
    "(Skipped for classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_val_score\n",
    "#x_valid_model = RandomForestClassifier(random_state = 42)\n",
    "#\n",
    "## Perform 5-fold cross validation\n",
    "#scores = cross_val_score(x_valid_model, X, Y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "#\n",
    "#print(f\"Cross-validation Mean Mean Squared Error: {-scores.mean():.4f}\")\n",
    "#print(f\"Cross-validation STD Mean Squared Error: {-scores.std():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
