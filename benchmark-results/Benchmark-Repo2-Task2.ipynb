{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7eed8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"4\"\n",
    "\n",
    "import setup.setup as setup\n",
    "import setup.duration_cal as duration_cal\n",
    "import EDA.eda_step as EDA\n",
    "import model_select.model_select as model_select\n",
    "import model_eval.model_eval as model_eval\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from typing import Dict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6080166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load configuration and setup parameters\n",
    "start_time = time.time()\n",
    "\n",
    "(\n",
    "    db_path,\n",
    "    target_col,\n",
    "    num_map_dict,\n",
    "    standard_list,\n",
    "    one_hot_list,\n",
    "    model_test_size,\n",
    "    model_random_state,\n",
    "    model_search_method,\n",
    "    model_cv_num,\n",
    "    model_scoring,\n",
    "    model_num_iter,\n",
    "    model_num_jobs,\n",
    "    model_param_dict,\n",
    ") = setup.setup_stage()\n",
    "\n",
    "print(\"Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "baaa85a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Connecting to SQL database....\n",
      "Connection done!\n"
     ]
    }
   ],
   "source": [
    "# Create connection to SQL database\n",
    "print(\"1. Connecting to SQL database....\")\n",
    "conn = sqlite3.connect(db_path)\n",
    "print(\"Connection done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d75a2b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 has run for 0.017 sec!\n"
     ]
    }
   ],
   "source": [
    "part1_time = time.time()\n",
    "part1_duration, part1_tag = duration_cal.duration_cal(part1_time - start_time)\n",
    "print(f\"Part 1 has run for {part1_duration:.3f} {part1_tag}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4b994bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Extract SQL database table as DataFrame...\n",
      "Extraction done!\n"
     ]
    }
   ],
   "source": [
    "# Get data from 'noshow' table\n",
    "print(\"2. Extract SQL database table as DataFrame...\")\n",
    "\n",
    "noshow_data_query = \"SELECT * FROM noshow;\"\n",
    "noshow_data_df = pd.read_sql_query(noshow_data_query, conn)\n",
    "\n",
    "print(\"Extraction done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c16dd7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2 has run for 0.344 sec!\n"
     ]
    }
   ],
   "source": [
    "part2_time = time.time()\n",
    "\n",
    "part2_duration, part2_tag = duration_cal.duration_cal(part2_time - part1_time)\n",
    "\n",
    "print(f\"Part 2 has run for {part2_duration:.3f} {part2_tag}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "202965b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Performing EDA on DataFrame...\n",
      "EDA done!\n"
     ]
    }
   ],
   "source": [
    "# Using analysis from task_1 EDA, perform data preprocessing, feature data standardization and one-hot encoding\n",
    "print(\"3. Performing EDA on DataFrame...\")\n",
    "\n",
    "fil_noshow_data_df, preprocessor, X_train, X_test, Y_train, Y_test = EDA.ml_eda_step(\n",
    "    noshow_data_df,\n",
    "    target_col,\n",
    "    num_map_dict,\n",
    "    standard_list,\n",
    "    one_hot_list,\n",
    "    model_test_size,\n",
    "    model_random_state,\n",
    ")\n",
    "\n",
    "print(\"EDA done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a43d31a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3 has run for 0.823 sec!\n"
     ]
    }
   ],
   "source": [
    "part3_time = time.time()\n",
    "\n",
    "part3_duration, part3_tag = duration_cal.duration_cal(part3_time - part2_time)\n",
    "\n",
    "print(f\"Part 3 has run for {part3_duration:.3f} {part3_tag}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3a7dfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Training machine learning models...\n"
     ]
    }
   ],
   "source": [
    "best_estimators_dict = {}\n",
    "# Pre-select a few models and train models to get best optimized parameters\n",
    "print(\"4. Training machine learning models...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4604647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Logistic Regression now...\n",
      "Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n",
      "Best parameters for Logistic Regression: {'model__C': 0.1, 'model__class_weight': 'balanced', 'model__max_iter': 100, 'model__solver': 'lbfgs'}\n",
      "Logistic Regression has run tuning for 24.084 min!\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "if \"Logistic Regression\" in model_param_dict:\n",
    "    model_start_time = time.time()\n",
    "    print(\"Processing Logistic Regression now...\")\n",
    "    \n",
    "    model = LogisticRegression(random_state=model_random_state)\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "    if model_search_method == \"grid\":\n",
    "        search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=model_param_dict[\"Logistic Regression\"],\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            n_jobs=model_num_jobs,\n",
    "            verbose=3\n",
    "        )\n",
    "    elif model_search_method == \"random\":\n",
    "        search = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions=model_param_dict[\"Logistic Regression\"],\n",
    "            n_iter=model_num_iter,\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            random_state=model_random_state,\n",
    "            n_jobs=model_num_jobs,\n",
    "        )\n",
    "    with tqdm(total=100, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ time left: {remaining} ]\") as pbar:\n",
    "        search.fit(X_train, Y_train)\n",
    "        pbar.update(100)\n",
    "\n",
    "    # Save best model\n",
    "    best_estimators_dict[\"Logistic Regression\"] = search.best_estimator_\n",
    "    print(\"Best parameters for Logistic Regression:\", search.best_params_)\n",
    "\n",
    "    model_end_time = time.time()\n",
    "    model_total_time = model_end_time - model_start_time\n",
    "    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "    print(f\"Logistic Regression has run tuning for {model_duration:.3f} {model_tag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "907ba669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Random Forest now...\n",
      "Fitting 5 folds for each of 416 candidates, totalling 2080 fits\n",
      "Best parameters for Random Forest: {'model__class_weight': 'balanced', 'model__max_depth': 40, 'model__n_estimators': 400}\n",
      "Random Forest has run tuning for 2.044 hr!\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest\n",
    "if \"Random Forest\" in model_param_dict:\n",
    "    model_start_time = time.time()\n",
    "    print(\"Processing Random Forest now...\")\n",
    "    \n",
    "    model = RandomForestClassifier(random_state=model_random_state)\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "    if model_search_method == \"grid\":\n",
    "        search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=model_param_dict[\"Random Forest\"],\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            n_jobs=model_num_jobs,\n",
    "            verbose=3\n",
    "        )\n",
    "    elif model_search_method == \"random\":\n",
    "        search = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions=model_param_dict[\"Random Forest\"],\n",
    "            n_iter=model_num_iter,\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            random_state=model_random_state,\n",
    "            n_jobs=model_num_jobs,\n",
    "        )\n",
    "\n",
    "    search.fit(X_train, Y_train)\n",
    "\n",
    "    # Save best model\n",
    "    best_estimators_dict[\"Random Forest\"] = search.best_estimator_\n",
    "    print(\"Best parameters for Random Forest:\", search.best_params_)\n",
    "\n",
    "    model_end_time = time.time()\n",
    "    model_total_time = model_end_time - model_start_time\n",
    "    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "    print(f\"Random Forest has run tuning for {model_duration:.3f} {model_tag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6db110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVC\n",
    "if \"SVC\" in model_param_dict:\n",
    "    model_start_time = time.time()\n",
    "    print(\"Processing SVC now...\")\n",
    "    \n",
    "    model = SVC()\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "    if model_search_method == \"grid\":\n",
    "        search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=model_param_dict[\"SVC\"],\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            n_jobs=model_num_jobs,\n",
    "            verbose=10\n",
    "        )\n",
    "    elif model_search_method == \"random\":\n",
    "        search = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions=model_param_dict[\"SVC\"],\n",
    "            n_iter=model_num_iter,\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            random_state=model_random_state,\n",
    "            n_jobs=model_num_jobs,\n",
    "        )\n",
    "\n",
    "    search.fit(X_train, Y_train)\n",
    "\n",
    "    # Save best model\n",
    "    best_estimators_dict[\"SVC\"] = search.best_estimator_\n",
    "    print(\"Best parameters for SVC:\", search.best_params_)\n",
    "\n",
    "    model_end_time = time.time()\n",
    "    model_total_time = model_end_time - model_start_time\n",
    "    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "    print(f\"SVC has run tuning for {model_duration:.3f} {model_tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8035bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MLP\n",
    "if \"MLP\" in model_param_dict:\n",
    "    model_start_time = time.time()\n",
    "    print(\"Processing MLP now...\")\n",
    "    \n",
    "    model = MLPClassifier(random_state=model_random_state)\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "    if model_search_method == \"grid\":\n",
    "        search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=model_param_dict[\"MLP\"],\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            n_jobs=model_num_jobs,\n",
    "            verbose=3\n",
    "        )\n",
    "    elif model_search_method == \"random\":\n",
    "        search = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions=model_param_dict[\"MLP\"],\n",
    "            n_iter=model_num_iter,\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            random_state=model_random_state,\n",
    "            n_jobs=model_num_jobs,\n",
    "        )\n",
    "\n",
    "    search.fit(X_train, Y_train)\n",
    "\n",
    "    # Save best model\n",
    "    best_estimators_dict[\"MLP\"] = search.best_estimator_\n",
    "    print(\"Best parameters for MLP:\", search.best_params_)\n",
    "\n",
    "    model_end_time = time.time()\n",
    "    model_total_time = model_end_time - model_start_time\n",
    "    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "    print(f\"MLP has run tuning for {model_duration:.3f} {model_tag}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d71bd351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Naive Bayes now...\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best parameters for Naive Bayes: {'model__alpha': 3.0}\n",
      "Naive Bayes has run tuning for 6.195 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes\n",
    "if \"Naive Bayes\" in model_param_dict:\n",
    "    model_start_time = time.time()\n",
    "    print(\"Processing Naive Bayes now...\")\n",
    "    \n",
    "    model = BernoulliNB()\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "    if model_search_method == \"grid\":\n",
    "        search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=model_param_dict[\"Naive Bayes\"],\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            n_jobs=model_num_jobs,\n",
    "            verbose=3\n",
    "        )\n",
    "    elif model_search_method == \"random\":\n",
    "        search = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions=model_param_dict[\"Naive Bayes\"],\n",
    "            n_iter=model_num_iter,\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            random_state=model_random_state,\n",
    "            n_jobs=model_num_jobs,\n",
    "        )\n",
    "\n",
    "    search.fit(X_train, Y_train)\n",
    "\n",
    "    # Save best model\n",
    "    best_estimators_dict[\"Naive Bayes\"] = search.best_estimator_\n",
    "    print(\"Best parameters for Naive Bayes:\", search.best_params_)\n",
    "\n",
    "    model_end_time = time.time()\n",
    "    model_total_time = model_end_time - model_start_time\n",
    "    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "    print(f\"Naive Bayes has run tuning for {model_duration:.3f} {model_tag}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65f5b2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing XG Boost now...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters for XG Boost: {'model__learning_rate': 0.1, 'model__max_depth': 10, 'model__subsample': 0.8}\n",
      "XG Boost has run tuning for 1.411 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train XG Boost\n",
    "if \"XG Boost\" in model_param_dict:\n",
    "    model_start_time = time.time()\n",
    "    print(\"Processing XG Boost now...\")\n",
    "    \n",
    "    model = XGBClassifier(objective=\"reg:squarederror\", random_state=model_random_state)\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "    if model_search_method == \"grid\":\n",
    "        search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=model_param_dict[\"XG Boost\"],\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            n_jobs=model_num_jobs,\n",
    "            verbose=3\n",
    "        )\n",
    "    elif model_search_method == \"random\":\n",
    "        search = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions=model_param_dict[\"XG Boost\"],\n",
    "            n_iter=model_num_iter,\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            random_state=model_random_state,\n",
    "            n_jobs=model_num_jobs,\n",
    "        )\n",
    "\n",
    "    search.fit(X_train, Y_train)\n",
    "\n",
    "    # Save best model\n",
    "    best_estimators_dict[\"XG Boost\"] = search.best_estimator_\n",
    "    print(\"Best parameters for XG Boost:\", search.best_params_)\n",
    "\n",
    "    model_end_time = time.time()\n",
    "    model_total_time = model_end_time - model_start_time\n",
    "    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "    print(f\"XG Boost has run tuning for {model_duration:.3f} {model_tag}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebce2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87885cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "part4_time = time.time()\n",
    "part4_duration, part4_tag = duration_cal.duration_cal(part4_time - part3_time)\n",
    "print(f\"Part 4 has run for {part4_duration:.3f} {part4_tag}!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b8d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate pre-selected models to get mean-squared error and r^2 values to determine which model is better for current dataset\n",
    "print(\"5. Evaluating machine learning model...\")\n",
    "model_eval.model_evaluation(X_test, Y_test, best_estimators_dict)\n",
    "print(\"Evaluation done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c775fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "part5_time = time.time()\n",
    "part5_duration, part5_tag = duration_cal.duration_cal(part5_time - part4_time)\n",
    "print(f\"Part 5 has run for {part5_duration:.3f} {part5_tag}!\")\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29167f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "final_time = end_time - start_time\n",
    "final_duration, final_tag = duration_cal.duration_cal(final_time)\n",
    "\n",
    "print(\"Script has reached end of line - It will terminate now!\")\n",
    "print(f\"Script has run for {final_duration:.3f} {final_tag}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8204839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a CSV file\n",
    "results_df = pd.DataFrame(best_estimators_dict).T\n",
    "results_df.to_csv(\"model_results.csv\", index=True)\n",
    "print(\"Results saved to 'model_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
